{
    "Recommendation": {
        "2509.21317": {
            "title": "Interactive Recommendation Agent with Active User Commands",
            "authors": "Jiakai Tang, Yujie Luo, Xunke Xi, Fei Sun, Xueyang Feng, Sunhao Dai, Chao Yi, Dian Chen, Zhujin Gao, Yang Li, Xu Chen, Wen Chen, Jian Wu, Yuning Jiang, Bo Zheng",
            "first_author": "Jiakai Tang",
            "url": "http://arxiv.org/abs/2509.21317v2",
            "pdf_url": "http://arxiv.org/abs/2509.21317",
            "publish_date": "2025-09-25",
            "abstract": "Traditional recommender systems rely on passive feedback mechanisms that limit users to simple choices such as like and dislike. However, these coarse-grained signals fail to capture users' nuanced behavior motivations and intentions. In turn, current systems cannot also distinguish which specific item attributes drive user satisfaction or dissatisfaction, resulting in inaccurate preference modeling. These fundamental limitations create a persistent gap between user intentions and system interpretations, ultimately undermining user satisfaction and harming system effectiveness.   To address these limitations, we introduce the Interactive Recommendation Feed (IRF), a pioneering paradigm that enables natural language commands within mainstream recommendation feeds. Unlike traditional systems that confine users to passive implicit behavioral influence, IRF empowers active explicit control over recommendation policies through real-time linguistic commands. To support this paradigm, we develop RecBot, a dual-agent architecture where a Parser Agent transforms linguistic expressions into structured preferences and a Planner Agent dynamically orchestrates adaptive tool chains for on-the-fly policy adjustment. To enable practical deployment, we employ simulation-augmented knowledge distillation to achieve efficient performance while maintaining strong reasoning capabilities. Through extensive offline and long-term online experiments, RecBot shows significant improvements in both user satisfaction and business outcomes.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2509.21179": {
            "title": "IntSR: An Integrated Generative Framework for Search and Recommendation",
            "authors": "Huimin Yan, Longfei Xu, Junjie Sun, Ni Ou, Wei Luo, Xing Tan, Ran Cheng, Kaikui Liu, Xiangxiang Chu",
            "first_author": "Huimin Yan",
            "url": "http://arxiv.org/abs/2509.21179v2",
            "pdf_url": "http://arxiv.org/abs/2509.21179",
            "publish_date": "2025-09-25",
            "abstract": "Generative recommendation has emerged as a promising paradigm, demonstrating remarkable results in both academic benchmarks and industrial applications. However, existing systems predominantly focus on unifying retrieval and ranking while neglecting the integration of search and recommendation (S&R) tasks. What makes search and recommendation different is how queries are formed: search uses explicit user requests, while recommendation relies on implicit user interests. As for retrieval versus ranking, the distinction comes down to whether the queries are the target items themselves. Recognizing the query as central element, we propose IntSR, an integrated generative framework for S&R. IntSR integrates these disparate tasks using distinct query modalities. It also addresses the increased computational complexity associated with integrated S&R behaviors and the erroneous pattern learning introduced by a dynamically changing corpus. IntSR has been successfully deployed across various scenarios in Amap, leading to substantial improvements in digital asset's GMV(+9.34%), POI recommendation's CTR(+2.76%), and travel mode suggestion's ACC(+7.04%).",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2509.20883": {
            "title": "RecIS: Sparse to Dense, A Unified Training Framework for Recommendation Models",
            "authors": "Hua Zong, Qingtao Zeng, Zhengxiong Zhou, Zhihua Han, Zhensong Yan, Mingjie Liu, Hechen Sun, Jiawei Liu, Yiwen Hu, Qi Wang, YiHan Xian, Wenjie Guo, Houyuan Xiang, Zhiyuan Zeng, Xiangrong Sheng, Bencheng Yan, Nan Hu, Yuheng Huang, Jinqing Lian, Ziru Xu, Yan Zhang, Ju Huang, Siran Yang, Huimin Yi, Jiamang Wang, Pengjie Wang, Han Zhu, Jian Wu, Dan Ou, Jian Xu, Haihong Tang, Yuning Jiang, Bo Zheng, Lin Qu",
            "first_author": "Hua Zong",
            "url": "http://arxiv.org/abs/2509.20883v1",
            "pdf_url": "http://arxiv.org/abs/2509.20883",
            "publish_date": "2025-09-25",
            "abstract": "In this paper, we propose RecIS, a unified Sparse-Dense training framework designed to achieve two primary goals: 1. Unified Framework To create a Unified sparse-dense training framework based on the PyTorch ecosystem that meets the training needs of industrial-grade recommendation models that integrated with large models. 2.System Optimization To optimize the sparse component, offering superior efficiency over the TensorFlow-based recommendation models. The dense component, meanwhile, leverages existing optimization technologies within the PyTorch ecosystem. Currently, RecIS is being used in Alibaba for numerous large-model enhanced recommendation training tasks, and some traditional sparse models have also begun training in it.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2509.20225": {
            "title": "Multimodal Representation-disentangled Information Bottleneck for Multimodal Recommendation",
            "authors": "Hui Wang, Jinghui Qin, Wushao Wen, Qingling Li, Shanshan Zhong, Zhongzhan Huang",
            "first_author": "Hui Wang",
            "url": "http://arxiv.org/abs/2509.20225v1",
            "pdf_url": "http://arxiv.org/abs/2509.20225",
            "publish_date": "2025-09-24",
            "abstract": "Multimodal data has significantly advanced recommendation systems by integrating diverse information sources to model user preferences and item characteristics. However, these systems often struggle with redundant and irrelevant information, which can degrade performance. Most existing methods either fuse multimodal information directly or use rigid architectural separation for disentanglement, failing to adequately filter noise and model the complex interplay between modalities. To address these challenges, we propose a novel framework, the Multimodal Representation-disentangled Information Bottleneck (MRdIB). Concretely, we first employ a Multimodal Information Bottleneck to compress the input representations, effectively filtering out task-irrelevant noise while preserving rich semantic information. Then, we decompose the information based on its relationship with the recommendation target into unique, redundant, and synergistic components. We achieve this decomposition with a series of constraints: a unique information learning objective to preserve modality-unique signals, a redundant information learning objective to minimize overlap, and a synergistic information learning objective to capture emergent information. By optimizing these objectives, MRdIB guides a model to learn more powerful and disentangled representations. Extensive experiments on several competitive models and three benchmark datasets demonstrate the effectiveness and versatility of our MRdIB in enhancing multimodal recommendation.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2509.19955": {
            "title": "Multimodal-enhanced Federated Recommendation: A Group-wise Fusion Approach",
            "authors": "Chunxu Zhang, Weipeng Zhang, Guodong Long, Zhiheng Xue, Riting Xia, Bo Yang",
            "first_author": "Chunxu Zhang",
            "url": "http://arxiv.org/abs/2509.19955v1",
            "pdf_url": "http://arxiv.org/abs/2509.19955",
            "publish_date": "2025-09-24",
            "abstract": "Federated Recommendation (FR) is a new learning paradigm to tackle the learn-to-rank problem in a privacy-preservation manner. How to integrate multi-modality features into federated recommendation is still an open challenge in terms of efficiency, distribution heterogeneity, and fine-grained alignment. To address these challenges, we propose a novel multimodal fusion mechanism in federated recommendation settings (GFMFR). Specifically, it offloads multimodal representation learning to the server, which stores item content and employs a high-capacity encoder to generate expressive representations, alleviating client-side overhead. Moreover, a group-aware item representation fusion approach enables fine-grained knowledge sharing among similar users while retaining individual preferences. The proposed fusion loss could be simply plugged into any existing federated recommender systems empowering their capability by adding multi-modality features. Extensive experiments on five public benchmark datasets demonstrate that GFMFR consistently outperforms state-of-the-art multimodal FR baselines.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2509.19469": {
            "title": "MusiCRS: Benchmarking Audio-Centric Conversational Recommendation",
            "authors": "Rohan Surana, Amit Namburi, Gagan Mundada, Abhay Lal, Zachary Novack, Julian McAuley, Junda Wu",
            "first_author": "Rohan Surana",
            "url": "http://arxiv.org/abs/2509.19469v1",
            "pdf_url": "http://arxiv.org/abs/2509.19469",
            "publish_date": "2025-09-23",
            "abstract": "Conversational recommendation has advanced rapidly with large language models (LLMs), yet music remains a uniquely challenging domain where effective recommendations require reasoning over audio content beyond what text or metadata can capture. We present MusiCRS, the first benchmark for audio-centric conversational recommendation that links authentic user conversations from Reddit with corresponding audio tracks. MusiCRS contains 477 high-quality conversations spanning diverse genres (classical, hip-hop, electronic, metal, pop, indie, jazz) with 3,589 unique musical entities and audio grounding via YouTube links. MusiCRS enables evaluation across three input modality configurations: audio-only, query-only, and audio+query (multimodal), allowing systematic comparison of audio-LLMs, retrieval models, and traditional approaches. Our experiments reveal that current systems rely heavily on textual signals and struggle with nuanced audio reasoning. This exposes fundamental limitations in cross-modal knowledge integration where models excel at dialogue semantics but cannot effectively ground abstract musical concepts in actual audio content. To facilitate progress, we release the MusiCRS dataset (https://huggingface.co/datasets/rohan2810/MusiCRS), evaluation code (https://github.com/rohan2810/musiCRS), and comprehensive baselines.",
            "primary_category": "cs.SD",
            "code_url": "null"
        },
        "2509.18807": {
            "title": "Single-Branch Network Architectures to Close the Modality Gap in Multimodal Recommendation",
            "authors": "Christian Ganh\u00f6r, Marta Moscati, Anna Hausberger, Shah Nawaz, Markus Schedl",
            "first_author": "Christian Ganh\u00f6r",
            "url": "http://arxiv.org/abs/2509.18807v1",
            "pdf_url": "http://arxiv.org/abs/2509.18807",
            "publish_date": "2025-09-23",
            "abstract": "Traditional recommender systems rely on collaborative filtering, using past user-item interactions to help users discover new items in a vast collection. In cold start, i.e., when interaction histories of users or items are not available, content-based recommender systems use side information instead. Hybrid recommender systems (HRSs) often employ multimodal learning to combine collaborative and side information, which we jointly refer to as modalities. Though HRSs can provide recommendations when some modalities are missing, their quality degrades. In this work, we utilize single-branch neural networks equipped with weight sharing, modality sampling, and contrastive loss to provide accurate recommendations even in missing modality scenarios by narrowing the modality gap. We compare these networks with multi-branch alternatives and conduct extensive experiments on three datasets. Six accuracy-based and four beyond-accuracy-based metrics help assess the recommendation quality for the different training paradigms and their hyperparameters in warm-start and missing modality scenarios. We quantitatively and qualitatively study the effects of these different aspects on bridging the modality gap. Our results show that single-branch networks achieve competitive performance in warm-start scenarios and are significantly better in missing modality settings. Moreover, our approach leads to closer proximity of an item's modalities in the embedding space. Our full experimental setup is available at https://github.com/hcai-mms/single-branch-networks.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2509.17945": {
            "title": "Improving Neutrino-Nuclei Interaction Models: Recommendations and Case Studies on Peelle's Pertinent Puzzle",
            "authors": "S. Abe, L. Aliaga-Soplin, J. Barrow, L. Bathe-Peters, B. Bogart, L. Cooper-Troendle, R. Diurba, S. Dytman, S. Gardiner, L. Hagaman, M. S. Ismail, J. Issacson, J. Kim, L. Liu, J. McKean, N. Nayak, A. Papadopoulou, L. Pickering, X. Qian, K. Skwarczynski, J. Tena Vidal, J. Wolfs",
            "first_author": "S. Abe",
            "url": "http://arxiv.org/abs/2509.17945v1",
            "pdf_url": "http://arxiv.org/abs/2509.17945",
            "publish_date": "2025-09-22",
            "abstract": "Improving the modeling of neutrino-nuclei interactions using data-driven methods is crucial for high-precision neutrino oscillation experiments. This paper investigates Peelle's Pertinent Puzzle (PPP) in the context of neutrino measurements, a longstanding challenge to fitting theoretical models to experimental data. Inconsistencies in data-model comparisons hinder efforts to enhance the accuracy and reliability of model predictions. We analyze various sources contributing to these inconsistencies and propose strategies to address them, supported by practical case studies. We advocate for incorporating model fitting exercises as a standard practice in cross section publications to enhance the robustness of results. We use a common analysis framework to explore PPP-related challenges with MicroBooNE and T2K data in an unified manner. Our findings offer valuable insights for improving the accuracy and reliability of neutrino-nuclei interaction models, particularly by systematically tuning models using data.",
            "primary_category": "hep-ex",
            "code_url": "null"
        },
        "2509.18226": {
            "title": "From \"What to Eat?\" to Perfect Recipe: ChefMind's Chain-of-Exploration for Ambiguous User Intent in Recipe Recommendation",
            "authors": "Yu Fu, Linyue Cai, Ruoyu Wu, Yong Zhao",
            "first_author": "Yu Fu",
            "url": "http://arxiv.org/abs/2509.18226v1",
            "pdf_url": "http://arxiv.org/abs/2509.18226",
            "publish_date": "2025-09-22",
            "abstract": "Personalized recipe recommendation faces challenges in handling fuzzy user intent, ensuring semantic accuracy, and providing sufficient detail coverage. We propose ChefMind, a hybrid architecture combining Chain of Exploration (CoE), Knowledge Graph (KG), Retrieval-Augmented Generation (RAG), and a Large Language Model (LLM). CoE refines ambiguous queries into structured conditions, KG offers semantic reasoning and interpretability, RAG supplements contextual culinary details, and LLM integrates outputs into coherent recommendations. We evaluate ChefMind on the Xiachufang dataset and manually annotated queries, comparing it with LLM-only, KG-only, and RAG-only baselines. Results show that ChefMind achieves superior performance in accuracy, relevance, completeness, and clarity, with an average score of 8.7 versus 6.4-6.7 for ablation models. Moreover, it reduces unprocessed queries to 1.6%, demonstrating robustness in handling fuzzy demands.",
            "primary_category": "cs.AI",
            "code_url": "null"
        },
        "2509.17361": {
            "title": "SeqUDA-Rec: Sequential User Behavior Enhanced Recommendation via Global Unsupervised Data Augmentation for Personalized Content Marketing",
            "authors": "Ruihan Luo, Xuanjing Chen, Ziyang Ding",
            "first_author": "Ruihan Luo",
            "url": "http://arxiv.org/abs/2509.17361v1",
            "pdf_url": "http://arxiv.org/abs/2509.17361",
            "publish_date": "2025-09-22",
            "abstract": "Personalized content marketing has become a crucial strategy for digital platforms, aiming to deliver tailored advertisements and recommendations that match user preferences. Traditional recommendation systems often suffer from two limitations: (1) reliance on limited supervised signals derived from explicit user feedback, and (2) vulnerability to noisy or unintentional interactions. To address these challenges, we propose SeqUDA-Rec, a novel deep learning framework that integrates user behavior sequences with global unsupervised data augmentation to enhance recommendation accuracy and robustness. Our approach first constructs a Global User-Item Interaction Graph (GUIG) from all user behavior sequences, capturing both local and global item associations. Then, a graph contrastive learning module is applied to generate robust embeddings, while a sequential Transformer-based encoder models users' evolving preferences. To further enhance diversity and counteract sparse supervised labels, we employ a GAN-based augmentation strategy, generating plausible interaction patterns and supplementing training data. Extensive experiments on two real-world marketing datasets (Amazon Ads and TikTok Ad Clicks) demonstrate that SeqUDA-Rec significantly outperforms state-of-the-art baselines such as SASRec, BERT4Rec, and GCL4SR. Our model achieves a 6.7% improvement in NDCG@10 and 11.3% improvement in HR@10, proving its effectiveness in personalized advertising and intelligent content recommendation.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2509.17265": {
            "title": "Identifying and Upweighting Power-Niche Users to Mitigate Popularity Bias in Recommendations",
            "authors": "David Liu, Erik Weis, Moritz Laber, Tina Eliassi-Rad, Brennan Klein",
            "first_author": "David Liu",
            "url": "http://arxiv.org/abs/2509.17265v1",
            "pdf_url": "http://arxiv.org/abs/2509.17265",
            "publish_date": "2025-09-21",
            "abstract": "Recommender systems have been shown to exhibit popularity bias by over-recommending popular items and under-recommending relevant niche items. We seek to understand interactions with niche items in benchmark recommendation datasets as a step toward mitigating popularity bias. We find that, compared to mainstream users, niche-preferring users exhibit a longer-tailed activity-level distribution, indicating the existence of users who both prefer niche items and exhibit high activity levels. We partition users along two axes: (1) activity level (\"power\" vs. \"light\") and (2) item-popularity preference (\"mainstream\" vs. \"niche\"), and show that in several benchmark datasets, the number of power-niche users (high activity and niche preference) is statistically significantly larger than expected under a null configuration model. Motivated by this observation, we propose a framework for reweighting the Bayesian Personalized Ranking (BPR) loss that simultaneously reweights based on user activity level and item popularity. Our method introduces two interpretable parameters: one controlling the significance of user activity level, and the other of item popularity. Experiments on benchmark datasets show that upweighting power-niche users reduces popularity bias and can increase overall performance. In contrast to previous work that only considers user activity level or item popularity in isolation, our results suggest that considering their interaction leads to Pareto-dominant performance.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2509.17066": {
            "title": "RALLM-POI: Retrieval-Augmented LLM for Zero-shot Next POI Recommendation with Geographical Reranking",
            "authors": "Kunrong Li, Kwan Hui Lim",
            "first_author": "Kunrong Li",
            "url": "http://arxiv.org/abs/2509.17066v1",
            "pdf_url": "http://arxiv.org/abs/2509.17066",
            "publish_date": "2025-09-21",
            "abstract": "Next point-of-interest (POI) recommendation predicts a user's next destination from historical movements. Traditional models require intensive training, while LLMs offer flexible and generalizable zero-shot solutions but often generate generic or geographically irrelevant results due to missing trajectory and spatial context. To address these issues, we propose RALLM-POI, a framework that couples LLMs with retrieval-augmented generation and self-rectification. We first propose a Historical Trajectory Retriever (HTR) that retrieves relevant past trajectories to serve as contextual references, which are then reranked by a Geographical Distance Reranker (GDR) for prioritizing spatially relevant trajectories. Lastly, an Agentic LLM Rectifier (ALR) is designed to refine outputs through self-reflection. Without additional training, RALLM-POI achieves substantial accuracy gains across three real-world Foursquare datasets, outperforming both conventional and LLM-based baselines. Code is released at https://github.com/LKRcrocodile/RALLM-POI.",
            "primary_category": "cs.AI",
            "code_url": "null"
        },
        "2509.20381": {
            "title": "USB-Rec: An Effective Framework for Improving Conversational Recommendation Capability of Large Language Model",
            "authors": "Jianyu Wen, Jingyun Wang, Cilin Yan, Jiayin Cai, Xiaolong Jiang, Ying Zhang",
            "first_author": "Jianyu Wen",
            "url": "http://arxiv.org/abs/2509.20381v1",
            "pdf_url": "http://arxiv.org/abs/2509.20381",
            "publish_date": "2025-09-20",
            "abstract": "Recently, Large Language Models (LLMs) have been widely employed in Conversational Recommender Systems (CRSs). Unlike traditional language model approaches that focus on training, all existing LLMs-based approaches are mainly centered around how to leverage the summarization and analysis capabilities of LLMs while ignoring the issue of training. Therefore, in this work, we propose an integrated training-inference framework, User-Simulator-Based framework (USB-Rec), for improving the performance of LLMs in conversational recommendation at the model level. Firstly, we design a LLM-based Preference Optimization (PO) dataset construction strategy for RL training, which helps the LLMs understand the strategies and methods in conversational recommendation. Secondly, we propose a Self-Enhancement Strategy (SES) at the inference stage to further exploit the conversational recommendation potential obtained from RL training. Extensive experiments on various datasets demonstrate that our method consistently outperforms previous state-of-the-art methods.",
            "primary_category": "cs.CL",
            "code_url": "null"
        },
        "2509.16446": {
            "title": "Purely Semantic Indexing for LLM-based Generative Recommendation and Retrieval",
            "authors": "Ruohan Zhang, Jiacheng Li, Julian McAuley, Yupeng Hou",
            "first_author": "Ruohan Zhang",
            "url": "http://arxiv.org/abs/2509.16446v1",
            "pdf_url": "http://arxiv.org/abs/2509.16446",
            "publish_date": "2025-09-19",
            "abstract": "Semantic identifiers (IDs) have proven effective in adapting large language models for generative recommendation and retrieval. However, existing methods often suffer from semantic ID conflicts, where semantically similar documents (or items) are assigned identical IDs. A common strategy to avoid conflicts is to append a non-semantic token to distinguish them, which introduces randomness and expands the search space, therefore hurting performance. In this paper, we propose purely semantic indexing to generate unique, semantic-preserving IDs without appending non-semantic tokens. We enable unique ID assignment by relaxing the strict nearest-centroid selection and introduce two model-agnostic algorithms: exhaustive candidate matching (ECM) and recursive residual searching (RRS). Extensive experiments on sequential recommendation, product search, and document retrieval tasks demonstrate that our methods improve both overall and cold-start performance, highlighting the effectiveness of ensuring ID uniqueness.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2509.13957": {
            "title": "Enhancing Time Awareness in Generative Recommendation",
            "authors": "Sunkyung Lee, Seongmin Park, Jonghyo Kim, Mincheol Yoon, Jongwuk Lee",
            "first_author": "Sunkyung Lee",
            "url": "http://arxiv.org/abs/2509.13957v1",
            "pdf_url": "http://arxiv.org/abs/2509.13957",
            "publish_date": "2025-09-17",
            "abstract": "Generative recommendation has emerged as a promising paradigm that formulates the recommendations into a text-to-text generation task, harnessing the vast knowledge of large language models. However, existing studies focus on considering the sequential order of items and neglect to handle the temporal dynamics across items, which can imply evolving user preferences. To address this limitation, we propose a novel model, Generative Recommender Using Time awareness (GRUT), effectively capturing hidden user preferences via various temporal signals. We first introduce Time-aware Prompting, consisting of two key contexts. The user-level temporal context models personalized temporal patterns across timestamps and time intervals, while the item-level transition context provides transition patterns across users. We also devise Trend-aware Inference, a training-free method that enhances rankings by incorporating trend information about items with generation likelihood. Extensive experiments demonstrate that GRUT outperforms state-of-the-art models, with gains of up to 15.4% and 14.3% in Recall@5 and NDCG@5 across four benchmark datasets. The source code is available at https://github.com/skleee/GRUT.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2509.13773": {
            "title": "MIRA: Empowering One-Touch AI Services on Smartphones with MLLM-based Instruction Recommendation",
            "authors": "Zhipeng Bian, Jieming Zhu, Xuyang Xie, Quanyu Dai, Zhou Zhao, Zhenhua Dong",
            "first_author": "Zhipeng Bian",
            "url": "http://arxiv.org/abs/2509.13773v1",
            "pdf_url": "http://arxiv.org/abs/2509.13773",
            "publish_date": "2025-09-17",
            "abstract": "The rapid advancement of generative AI technologies is driving the integration of diverse AI-powered services into smartphones, transforming how users interact with their devices. To simplify access to predefined AI services, this paper introduces MIRA, a pioneering framework for task instruction recommendation that enables intuitive one-touch AI tasking on smartphones. With MIRA, users can long-press on images or text objects to receive contextually relevant instruction recommendations for executing AI tasks. Our work introduces three key innovations: 1) A multimodal large language model (MLLM)-based recommendation pipeline with structured reasoning to extract key entities, infer user intent, and generate precise instructions; 2) A template-augmented reasoning mechanism that integrates high-level reasoning templates, enhancing task inference accuracy; 3) A prefix-tree-based constrained decoding strategy that restricts outputs to predefined instruction candidates, ensuring coherent and intent-aligned suggestions. Through evaluation using a real-world annotated datasets and a user study, MIRA has demonstrated substantial improvements in the accuracy of instruction recommendation. The encouraging results highlight MIRA's potential to revolutionize the way users engage with AI services on their smartphones, offering a more seamless and efficient experience.",
            "primary_category": "cs.AI",
            "code_url": "null"
        },
        "2509.13648": {
            "title": "Sequential Data Augmentation for Generative Recommendation",
            "authors": "Geon Lee, Bhuvesh Kumar, Clark Mingxuan Ju, Tong Zhao, Kijung Shin, Neil Shah, Liam Collins",
            "first_author": "Geon Lee",
            "url": "http://arxiv.org/abs/2509.13648v1",
            "pdf_url": "http://arxiv.org/abs/2509.13648",
            "publish_date": "2025-09-17",
            "abstract": "Generative recommendation plays a crucial role in personalized systems, predicting users' future interactions from their historical behavior sequences. A critical yet underexplored factor in training these models is data augmentation, the process of constructing training data from user interaction histories. By shaping the training distribution, data augmentation directly and often substantially affects model generalization and performance. Nevertheless, in much of the existing work, this process is simplified, applied inconsistently, or treated as a minor design choice, without a systematic and principled understanding of its effects.   Motivated by our empirical finding that different augmentation strategies can yield large performance disparities, we conduct an in-depth analysis of how they reshape training distributions and influence alignment with future targets and generalization to unseen inputs. To systematize this design space, we propose GenPAS, a generalized and principled framework that models augmentation as a stochastic sampling process over input-target pairs with three bias-controlled steps: sequence sampling, target sampling, and input sampling. This formulation unifies widely used strategies as special cases and enables flexible control of the resulting training distribution. Our extensive experiments on benchmark and industrial datasets demonstrate that GenPAS yields superior accuracy, data efficiency, and parameter efficiency compared to existing strategies, providing practical guidance for principled training data construction in generative recommendation.",
            "primary_category": "cs.LG",
            "code_url": "null"
        },
        "2509.13462": {
            "title": "Strategic Pricing and Ranking in Recommendation Systems with Seller Competition",
            "authors": "Tushar Shankar Walunj, Veeraruna Kavitha, Jayakrishnan Nair, Priyank Agarwal",
            "first_author": "Tushar Shankar Walunj",
            "url": "http://arxiv.org/abs/2509.13462v2",
            "pdf_url": "http://arxiv.org/abs/2509.13462",
            "publish_date": "2025-09-16",
            "abstract": "We study a recommendation system where sellers compete for visibility by strategically offering commissions to a platform that optimally curates a ranked menu of items and their respective prices for each customer. Customers interact sequentially with the menu following a cascade click model, and their purchase decisions are influenced by price sensitivity and positions of various items in the menu. We model the seller-platform interaction as a Stackelberg game with sellers as leaders and consider two different games depending on whether the prices are set by the platform or prefixed by the sellers. It is complicated to find the optimal policy of the platform in complete generality; hence, we solve the problem in an important asymptotic regime.   The core contribution of this paper lies in characterizing the equilibrium structure of the limit game. We show that when sellers are of different strengths, the standard Nash equilibrium does not exist due to discontinuities in utilities. We instead establish the existence of a novel equilibrium solution, namely `$\\mu$-connected equilibrium cycle' ($\\mu$-EC), which captures oscillatory strategic responses at the equilibrium. Unlike the (pure) Nash equilibrium, which defines a fixed point of mutual best responses, this is a set-valued solution concept of connected components. This novel equilibrium concept identifies a Cartesian product set of connected action profiles in the continuous action space that satisfies four important properties: stability against external deviations, no external chains, instability against internal deviations, and minimality. We extend a recently introduced solution concept equilibrium cycle to include stability against measure-zero violations and, by avoiding topological difficulties to propose $\\mu$-EC.",
            "primary_category": "econ.TH",
            "code_url": "null"
        },
        "2509.13179": {
            "title": "Efficient Cold-Start Recommendation via BPE Token-Level Embedding Initialization with LLM",
            "authors": "Yushang Zhao, Xinyue Han, Qian Leng, Qianyi Sun, Haotian Lyu, Chengrui Zhou",
            "first_author": "Yushang Zhao",
            "url": "http://arxiv.org/abs/2509.13179v1",
            "pdf_url": "http://arxiv.org/abs/2509.13179",
            "publish_date": "2025-09-16",
            "abstract": "The cold-start issue is the challenge when we talk about recommender systems, especially in the case when we do not have the past interaction data of new users or new items. Content-based features or hybrid solutions are common as conventional solutions, but they can only work in a sparse metadata environment with shallow patterns. In this paper, the efficient cold-start recommendation strategy is presented, which is based on the sub word-level representations by applying Byte Pair Encoding (BPE) tokenization and pre-trained Large Language Model (LLM) embedding in the initialization procedure. We obtain fine-grained token-level vectors that are aligned with the BPE vocabulary as opposed to using coarse-grained sentence embeddings. Together, these token embeddings can be used as dense semantic priors on unseen entities, making immediate recommendation performance possible without user-item interaction history. Our mechanism can be compared to collaborative filtering systems and tested over benchmark datasets with stringent cold-start assumptions. Experimental findings show that the given BPE-LLM method achieves higher Recall@k, NDCG@k, and Hit Rate measurements compared to the standard baseline and displays the same capability of sufficient computational performance. Furthermore, we demonstrate that using subword-aware embeddings yields better generalizability and is more interpretable, especially within a multilingual and sparse input setting. The practical application of token-level semantic initialization as a lightweight, but nevertheless effective extension to modern recommender systems in the zero-shot setting is indicated within this work.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2509.12382": {
            "title": "LLM-as-a-Judge: Rapid Evaluation of Legal Document Recommendation for Retrieval-Augmented Generation",
            "authors": "Anu Pradhan, Alexandra Ortan, Apurv Verma, Madhavan Seshadri",
            "first_author": "Anu Pradhan",
            "url": "http://arxiv.org/abs/2509.12382v1",
            "pdf_url": "http://arxiv.org/abs/2509.12382",
            "publish_date": "2025-09-15",
            "abstract": "The evaluation bottleneck in recommendation systems has become particularly acute with the rise of Generative AI, where traditional metrics fall short of capturing nuanced quality dimensions that matter in specialized domains like legal research. Can we trust Large Language Models to serve as reliable judges of their own kind? This paper investigates LLM-as-a-Judge as a principled approach to evaluating Retrieval-Augmented Generation systems in legal contexts, where the stakes of recommendation quality are exceptionally high.   We tackle two fundamental questions that determine practical viability: which inter-rater reliability metrics best capture the alignment between LLM and human assessments, and how do we conduct statistically sound comparisons between competing systems? Through systematic experimentation, we discover that traditional agreement metrics like Krippendorff's alpha can be misleading in the skewed distributions typical of AI system evaluations. Instead, Gwet's AC2 and rank correlation coefficients emerge as more robust indicators for judge selection, while the Wilcoxon Signed-Rank Test with Benjamini-Hochberg corrections provides the statistical rigor needed for reliable system comparisons.   Our findings suggest a path toward scalable, cost-effective evaluation that maintains the precision demanded by legal applications, transforming what was once a human-intensive bottleneck into an automated, yet statistically principled, evaluation framework.",
            "primary_category": "cs.CL",
            "code_url": "null"
        },
        "2509.12361": {
            "title": "What News Recommendation Research Did (But Mostly Didn't) Teach Us About Building A News Recommender",
            "authors": "Karl Higley, Robin Burke, Michael D. Ekstrand, Bart P. Knijnenburg",
            "first_author": "Karl Higley",
            "url": "http://arxiv.org/abs/2509.12361v1",
            "pdf_url": "http://arxiv.org/abs/2509.12361",
            "publish_date": "2025-09-15",
            "abstract": "One of the goals of recommender systems research is to provide insights and methods that can be used by practitioners to build real-world systems that deliver high-quality recommendations to actual people grounded in their genuine interests and needs. We report on our experience trying to apply the news recommendation literature to build POPROX, a live platform for news recommendation research, and reflect on the extent to which the current state of research supports system-building efforts. Our experience highlights several unexpected challenges encountered in building personalization features that are commonly found in products from news aggregators and publishers, and shows how those difficulties are connected to surprising gaps in the literature. Finally, we offer a set of lessons learned from building a live system with a persistent user base and highlight opportunities to make future news recommendation research more applicable and impactful in practice.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2509.12350": {
            "title": "Knowledge Graph Tokenization for Behavior-Aware Generative Next POI Recommendation",
            "authors": "Ke Sun, Mayi Xu",
            "first_author": "Ke Sun",
            "url": "http://arxiv.org/abs/2509.12350v1",
            "pdf_url": "http://arxiv.org/abs/2509.12350",
            "publish_date": "2025-09-15",
            "abstract": "Generative paradigm, especially powered by Large Language Models (LLMs), has emerged as a new solution to the next point-of-interest (POI) recommendation. Pioneering studies usually adopt a two-stage pipeline, starting with a tokenizer converting POIs into discrete identifiers that can be processed by LLMs, followed by POI behavior prediction tasks to instruction-tune LLM for next POI recommendation. Despite of remarkable progress, they still face two limitations: (1) existing tokenizers struggle to encode heterogeneous signals in the recommendation data, suffering from information loss issue, and (2) previous instruction-tuning tasks only focus on users' POI visit behavior while ignore other behavior types, resulting in insufficient understanding of mobility. To address these limitations, we propose KGTB (Knowledge Graph Tokenization for Behavior-aware generative next POI recommendation). Specifically, KGTB organizes the recommendation data in a knowledge graph (KG) format, of which the structure can seamlessly preserve the heterogeneous information. Then, a KG-based tokenizer is developed to quantize each node into an individual structural ID. This process is supervised by the KG's structure, thus reducing the loss of heterogeneous information. Using generated IDs, KGTB proposes multi-behavior learning that introduces multiple behavior-specific prediction tasks for LLM fine-tuning, e.g., POI, category, and region visit behaviors. Learning on these behavior tasks provides LLMs with comprehensive insights on the target POI visit behavior. Experiments on four real-world city datasets demonstrate the superior performance of KGTB.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2509.11524": {
            "title": "Decoding in Latent Spaces for Efficient Inference in LLM-based Recommendation",
            "authors": "Chengbing Wang, Yang Zhang, Zhicheng Wang, Tianhao Shi, Keqin Bao, Fuli Feng, Tat-Seng Chua",
            "first_author": "Chengbing Wang",
            "url": "http://arxiv.org/abs/2509.11524v1",
            "pdf_url": "http://arxiv.org/abs/2509.11524",
            "publish_date": "2025-09-15",
            "abstract": "Fine-tuning large language models (LLMs) for recommendation in a generative manner has delivered promising results, but encounters significant inference overhead due to autoregressive decoding in the language space. This work explores bypassing language-space decoding by directly matching candidate items with the LLM's internal thought representations in the latent space, eliminating the time-consuming autoregressive process to reduce computational costs. Towards this, we introduce Light Latent-space Decoding (L2D), an effective and efficient latent-space decoding method. L2D represents user-preferred items by using the hidden states of test sequences reflecting the LLM's internal thought, and obtains candidate item representations from the hidden states of training sequences labeled with the corresponding candidate items. It then matches the two types of representations to decode items, achieving latent-space decoding. In this way, it enables efficient decoding without altering the LLM's generative tuning paradigm, thereby preserving performance. Extensive empirical results demonstrate that L2D is more than 10x faster than language-space decoding while maintaining or enhancing performance.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2509.11139": {
            "title": "Understanding the Information Cocoon: A Multidimensional Assessment and Analysis of News Recommendation Systems",
            "authors": "Xin Wang, Xiaowen Huang, Jitao Sang",
            "first_author": "Xin Wang",
            "url": "http://arxiv.org/abs/2509.11139v1",
            "pdf_url": "http://arxiv.org/abs/2509.11139",
            "publish_date": "2025-09-14",
            "abstract": "Personalized news recommendation systems inadvertently create information cocoons--homogeneous information bubbles that reinforce user biases and amplify societal polarization. To address the lack of comprehensive assessment frameworks in prior research, we propose a multidimensional analysis that evaluates cocoons through dual perspectives: (1) Individual homogenization via topic diversity (including the number of topic categories and category information entropy) and click repetition; (2) Group polarization via network density and community openness. Through multi-round experiments on real-world datasets, we benchmark seven algorithms and reveal critical insights. Furthermore, we design five lightweight mitigation strategies. This work establishes the first unified metric framework for information cocoons and delivers deployable solutions for ethical recommendation systems.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2509.11094": {
            "title": "SPARK: Adaptive Low-Rank Knowledge Graph Modeling in Hybrid Geometric Spaces for Recommendation",
            "authors": "Binhao Wang, Yutian Xiao, Maolin Wang, Zhiqi Li, Tianshuo Wei, Ruocheng Guo, Xiangyu Zhao",
            "first_author": "Binhao Wang",
            "url": "http://arxiv.org/abs/2509.11094v1",
            "pdf_url": "http://arxiv.org/abs/2509.11094",
            "publish_date": "2025-09-14",
            "abstract": "Knowledge Graphs (KGs) enhance recommender systems but face challenges from inherent noise, sparsity, and Euclidean geometry's inadequacy for complex relational structures, critically impairing representation learning, especially for long-tail entities. Existing methods also often lack adaptive multi-source signal fusion tailored to item popularity. This paper introduces SPARK, a novel multi-stage framework systematically tackling these issues. SPARK first employs Tucker low-rank decomposition to denoise KGs and generate robust entity representations. Subsequently, an SVD-initialized hybrid geometric GNN concurrently learns representations in Euclidean and Hyperbolic spaces; the latter is strategically leveraged for its aptitude in modeling hierarchical structures, effectively capturing semantic features of sparse, long-tail items. A core contribution is an item popularity-aware adaptive fusion strategy that dynamically weights signals from collaborative filtering, refined KG embeddings, and diverse geometric spaces for precise modeling of both mainstream and long-tail items. Finally, contrastive learning aligns these multi-source representations. Extensive experiments demonstrate SPARK's significant superiority over state-of-the-art methods, particularly in improving long-tail item recommendation, offering a robust, principled approach to knowledge-enhanced recommendation. Implementation code is available at https://github.com/Applied-Machine-Learning-Lab/SPARK.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2509.10392": {
            "title": "Diversified recommendations of cultural activities with personalized determinantal point processes",
            "authors": "Carole Ibrahim, Hiba Bederina, Daniel Cuesta, Laurent Montier, Cyrille Delabre, Jill-J\u00eann Vie",
            "first_author": "Carole Ibrahim",
            "url": "http://arxiv.org/abs/2509.10392v1",
            "pdf_url": "http://arxiv.org/abs/2509.10392",
            "publish_date": "2025-09-12",
            "abstract": "While optimizing recommendation systems for user engagement is a well-established practice, effectively diversifying recommendations without negatively impacting core business metrics remains a significant industry challenge. In line with our initiative to broaden our audience's cultural practices, this study investigates using personalized Determinantal Point Processes (DPPs) to sample diverse and relevant recommendations. We rely on a well-known quality-diversity decomposition of the similarity kernel to give more weight to user preferences. In this paper, we present our implementations of the personalized DPP sampling, evaluate the trade-offs between relevance and diversity through both offline and online metrics, and give insights for practitioners on their use in a production environment. For the sake of reproducibility, we release the full code for our platform and experiments on GitHub.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2509.09877": {
            "title": "How to Fight Fraudulent Publishing in the Mathematical Sciences: Joint Recommendations of the IMU and the ICIAM",
            "authors": "Ilka Agricola, Lynn Heller, Wil Schilders, Moritz Schubotz, Peter Taylor, Luis Vega",
            "first_author": "Ilka Agricola",
            "url": "http://arxiv.org/abs/2509.09877v1",
            "pdf_url": "http://arxiv.org/abs/2509.09877",
            "publish_date": "2025-09-11",
            "abstract": "These recommendations were formulated by the authors in close collaboration with the IMU Committee on Publishing (chaired by Ilka Agricola) and have been endorsed by the Executive Committee of the IMU and the Board of the ICIAM in May/June 2025.",
            "primary_category": "math.HO",
            "code_url": "null"
        },
        "2509.09583": {
            "title": "Personality-Enhanced Social Recommendations in SAMI: Exploring the Role of Personality Detection in Matchmaking",
            "authors": "Brittany Harbison, Samuel Taubman, Travis Taylor, Ashok. K. Goel",
            "first_author": "Brittany Harbison",
            "url": "http://arxiv.org/abs/2509.09583v1",
            "pdf_url": "http://arxiv.org/abs/2509.09583",
            "publish_date": "2025-09-11",
            "abstract": "Social connection is a vital part of learning, yet online course environments present barriers to the organic formation of social groups. SAMI offers one solution by facilitating student connections, but its effectiveness is constrained by an incomplete Theory of Mind, limiting its ability to create an effective mental model of a student. One facet of this is its inability to intuit personality, which may influence the relevance of its recommendations. To explore this, we propose a personality detection model utilizing GPTs zero-shot capability to infer Big-Five personality traits from forum introduction posts, often encouraged in online courses. We benchmark its performance against established models, demonstrating its efficacy in this task. Furthermore, we integrate this model into SAMIs entity-based matchmaking system, enabling personality-informed social recommendations. Initial integration suggests personality traits can complement existing matching factors, though additional evaluation is required to determine their full impact on student engagement and match quality.",
            "primary_category": "cs.CL",
            "code_url": "null"
        },
        "2509.09342": {
            "title": "CESRec: Constructing Pseudo Interactions for Sequential Recommendation via Conversational Feedback",
            "authors": "Yifan Wang, Shen Gao, Jiabao Fang, Rui Yan, Billy Chiu, Shuo Shang",
            "first_author": "Yifan Wang",
            "url": "http://arxiv.org/abs/2509.09342v1",
            "pdf_url": "http://arxiv.org/abs/2509.09342",
            "publish_date": "2025-09-11",
            "abstract": "Sequential Recommendation Systems (SRS) have become essential in many real-world applications. However, existing SRS methods often rely on collaborative filtering signals and fail to capture real-time user preferences, while Conversational Recommendation Systems (CRS) excel at eliciting immediate interests through natural language interactions but neglect historical behavior. To bridge this gap, we propose CESRec, a novel framework that integrates the long-term preference modeling of SRS with the real-time preference elicitation of CRS. We introduce semantic-based pseudo interaction construction, which dynamically updates users'historical interaction sequences by analyzing conversational feedback, generating a pseudo-interaction sequence that seamlessly combines long-term and real-time preferences. Additionally, we reduce the impact of outliers in historical items that deviate from users'core preferences by proposing dual alignment outlier items masking, which identifies and masks such items using semantic-collaborative aligned representations. Extensive experiments demonstrate that CESRec achieves state-of-the-art performance by boosting strong SRS models, validating its effectiveness in integrating conversational feedback into SRS.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2509.09146": {
            "title": "Peering Partner Recommendation for ISPs using Machine Learning",
            "authors": "Md Ibrahim Ibne Alam, Ankur Senapati, Anindo Mahmood, Murat Yuksel, Koushik Kar",
            "first_author": "Md Ibrahim Ibne Alam",
            "url": "http://arxiv.org/abs/2509.09146v1",
            "pdf_url": "http://arxiv.org/abs/2509.09146",
            "publish_date": "2025-09-11",
            "abstract": "Internet service providers (ISPs) need to connect with other ISPs to provide global connectivity services to their users. To ensure global connectivity, ISPs can either use transit service(s) or establish direct peering relationships between themselves via Internet exchange points (IXPs). Peering offers more room for ISP-specific optimizations and is preferred, but it often involves a lengthy and complex process. Automating peering partner selection can enhance efficiency in the global Internet ecosystem. We explore the use of publicly available data on ISPs to develop a machine learning (ML) model that can predict whether an ISP pair should peer or not. At first, we explore public databases, e.g., PeeringDB, CAIDA, etc., to gather data on ISPs. Then, we evaluate the performance of three broad types of ML models for predicting peering relationships: tree-based, neural network-based, and transformer-based. Among these, we observe that tree-based models achieve the highest accuracy and efficiency in our experiments. The XGBoost model trained with publicly available data showed promising performance, with a 98% accuracy rate in predicting peering partners. In addition, the model demonstrated great resilience to variations in time, space, and missing data. We envision that ISPs can adopt our method to fully automate the peering partner selection process, thus transitioning to a more efficient and optimized Internet ecosystem.",
            "primary_category": "cs.LG",
            "code_url": "null"
        },
        "2509.09114": {
            "title": "Modality Alignment with Multi-scale Bilateral Attention for Multimodal Recommendation",
            "authors": "Kelin Ren, Chan-Yang Ju, Dong-Ho Lee",
            "first_author": "Kelin Ren",
            "url": "http://arxiv.org/abs/2509.09114v1",
            "pdf_url": "http://arxiv.org/abs/2509.09114",
            "publish_date": "2025-09-11",
            "abstract": "Multimodal recommendation systems are increasingly becoming foundational technologies for e-commerce and content platforms, enabling personalized services by jointly modeling users' historical behaviors and the multimodal features of items (e.g., visual and textual). However, most existing methods rely on either static fusion strategies or graph-based local interaction modeling, facing two critical limitations: (1) insufficient ability to model fine-grained cross-modal associations, leading to suboptimal fusion quality; and (2) a lack of global distribution-level consistency, causing representational bias. To address these, we propose MambaRec, a novel framework that integrates local feature alignment and global distribution regularization via attention-guided learning. At its core, we introduce the Dilated Refinement Attention Module (DREAM), which uses multi-scale dilated convolutions with channel-wise and spatial attention to align fine-grained semantic patterns between visual and textual modalities. This module captures hierarchical relationships and context-aware associations, improving cross-modal semantic modeling. Additionally, we apply Maximum Mean Discrepancy (MMD) and contrastive loss functions to constrain global modality alignment, enhancing semantic consistency. This dual regularization reduces mode-specific deviations and boosts robustness. To improve scalability, MambaRec employs a dimensionality reduction strategy to lower the computational cost of high-dimensional multimodal features. Extensive experiments on real-world e-commerce datasets show that MambaRec outperforms existing methods in fusion quality, generalization, and efficiency. Our code has been made publicly available at https://github.com/rkl71/MambaRec.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2509.09066": {
            "title": "Instructional Prompt Optimization for Few-Shot LLM-Based Recommendations on Cold-Start Users",
            "authors": "Haowei Yang, Yushang Zhao, Sitao Min, Bo Su, Chao Yao, Wei Xu",
            "first_author": "Haowei Yang",
            "url": "http://arxiv.org/abs/2509.09066v1",
            "pdf_url": "http://arxiv.org/abs/2509.09066",
            "publish_date": "2025-09-11",
            "abstract": "The cold-start user issue further compromises the effectiveness of recommender systems in limiting access to the historical behavioral information. It is an effective pipeline to optimize instructional prompts on a few-shot large language model (LLM) used in recommender tasks. We introduce a context-conditioned prompt formulation method P(u,\\ Ds)\\ \\rightarrow\\ R\\widehat, where u is a cold-start user profile, Ds is a curated support set, and R\\widehat is the predicted ranked list of items. Based on systematic experimentation with transformer-based autoregressive LLMs (BioGPT, LLaMA-2, GPT-4), we provide empirical evidence that optimal exemplar injection and instruction structuring can significantly improve the precision@k and NDCG scores of such models in low-data settings. The pipeline uses token-level alignments and embedding space regularization with a greater semantic fidelity. Our findings not only show that timely composition is not merely syntactic but also functional as it is in direct control of attention scales and decoder conduct through inference. This paper shows that prompt-based adaptation may be considered one of the ways to address cold-start recommendation issues in LLM-based pipelines.",
            "primary_category": "cs.AI",
            "code_url": "null"
        },
        "2509.09037": {
            "title": "Envy-Free but Still Unfair: Envy-Freeness Up To One Item (EF-1) in Personalized Recommendation",
            "authors": "Amanda Aird, Ben Armstrong, Nicholas Mattei, Robin Burke",
            "first_author": "Amanda Aird",
            "url": "http://arxiv.org/abs/2509.09037v1",
            "pdf_url": "http://arxiv.org/abs/2509.09037",
            "publish_date": "2025-09-10",
            "abstract": "Envy-freeness and the relaxation to Envy-freeness up to one item (EF-1) have been used as fairness concepts in the economics, game theory, and social choice literatures since the 1960s, and have recently gained popularity within the recommendation systems communities. In this short position paper we will give an overview of envy-freeness and its use in economics and recommendation systems; and illustrate why envy is not appropriate to measure fairness for use in settings where personalization plays a role.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2509.08231": {
            "title": "Deploying Robust Decision Support Systems for Transit Headway Control: Rider Impacts, Human Factors and Recommendations for Scalability",
            "authors": "Joseph Rodriguez, Haris N. Koutsopoulos, Jinhua Zhao",
            "first_author": "Joseph Rodriguez",
            "url": "http://arxiv.org/abs/2509.08231v1",
            "pdf_url": "http://arxiv.org/abs/2509.08231",
            "publish_date": "2025-09-10",
            "abstract": "Service reliability is critical to transit service delivery. This paper describes headway control pilots conducted in two high-ridership Chicago bus routes between 2022 and 2023. A decision support system was developed for a bus holding strategy based on a reinforcement learning approach. For the pilots, a user interface enabled supervisors to monitor service and record applied actions. The first pilot tested terminal-based holding on a route affected by missed trips from absenteeism. The analysis found improvements in reliability, and the application of control was shown to outperform days with more service. The second pilot applied en-route holding in a high-ridership bus route in Chicago. The evaluation showed wait time improvements with rippled benefits to stops downstream, and a reduction in transfer times from connecting bus and rail lines. Compliance analysis based on the supervisor logs on the app revealed mixed compliance levels from drivers, which were related to the mentality of schedule adherence and seniority. Recommendations are provided for practitioners to scale similar efforts.",
            "primary_category": "stat.AP",
            "code_url": "null"
        },
        "2509.07319": {
            "title": "MEGG: Replay via Maximally Extreme GGscore in Incremental Learning for Neural Recommendation Models",
            "authors": "Yunxiao Shi, Shuo Yang, Haimin Zhang, Li Wang, Yongze Wang, Qiang Wu, Min Xu",
            "first_author": "Yunxiao Shi",
            "url": "http://arxiv.org/abs/2509.07319v1",
            "pdf_url": "http://arxiv.org/abs/2509.07319",
            "publish_date": "2025-09-09",
            "abstract": "Neural Collaborative Filtering models are widely used in recommender systems but are typically trained under static settings, assuming fixed data distributions. This limits their applicability in dynamic environments where user preferences evolve. Incremental learning offers a promising solution, yet conventional methods from computer vision or NLP face challenges in recommendation tasks due to data sparsity and distinct task paradigms. Existing approaches for neural recommenders remain limited and often lack generalizability. To address this, we propose MEGG, Replay Samples with Maximally Extreme GGscore, an experience replay based incremental learning framework. MEGG introduces GGscore, a novel metric that quantifies sample influence, enabling the selective replay of highly influential samples to mitigate catastrophic forgetting. Being model-agnostic, MEGG integrates seamlessly across architectures and frameworks. Experiments on three neural models and four benchmark datasets show superior performance over state-of-the-art baselines, with strong scalability, efficiency, and robustness. Implementation will be released publicly upon acceptance.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2509.07269": {
            "title": "Datasets for Navigating Sensitive Topics in Recommendation Systems",
            "authors": "Amelia Kovacs, Jerry Chee, Kimia Kazemian, Sarah Dean",
            "first_author": "Amelia Kovacs",
            "url": "http://arxiv.org/abs/2509.07269v1",
            "pdf_url": "http://arxiv.org/abs/2509.07269",
            "publish_date": "2025-09-08",
            "abstract": "Personalized AI systems, from recommendation systems to chatbots, are a prevalent method for distributing content to users based on their learned preferences. However, there is growing concern about the adverse effects of these systems, including their potential tendency to expose users to sensitive or harmful material, negatively impacting overall well-being. To address this concern quantitatively, it is necessary to create datasets with relevant sensitivity labels for content, enabling researchers to evaluate personalized systems beyond mere engagement metrics. To this end, we introduce two novel datasets that include a taxonomy of sensitivity labels alongside user-content ratings: one that integrates MovieLens rating data with content warnings from the Does the Dog Die? community ratings website, and another that combines fan-fiction interaction data and user-generated warnings from Archive of Our Own.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2509.07133": {
            "title": "Avoiding Over-Personalization with Rule-Guided Knowledge Graph Adaptation for LLM Recommendations",
            "authors": "Fernando Spadea, Oshani Seneviratne",
            "first_author": "Fernando Spadea",
            "url": "http://arxiv.org/abs/2509.07133v1",
            "pdf_url": "http://arxiv.org/abs/2509.07133",
            "publish_date": "2025-09-08",
            "abstract": "We present a lightweight neuro-symbolic framework to mitigate over-personalization in LLM-based recommender systems by adapting user-side Knowledge Graphs (KGs) at inference time. Instead of retraining models or relying on opaque heuristics, our method restructures a user's Personalized Knowledge Graph (PKG) to suppress feature co-occurrence patterns that reinforce Personalized Information Environments (PIEs), i.e., algorithmically induced filter bubbles that constrain content diversity. These adapted PKGs are used to construct structured prompts that steer the language model toward more diverse, Out-PIE recommendations while preserving topical relevance. We introduce a family of symbolic adaptation strategies, including soft reweighting, hard inversion, and targeted removal of biased triples, and a client-side learning algorithm that optimizes their application per user. Experiments on a recipe recommendation benchmark show that personalized PKG adaptations significantly increase content novelty while maintaining recommendation quality, outperforming global adaptation and naive prompt-based methods.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2509.06286": {
            "title": "RecMind: LLM-Enhanced Graph Neural Networks for Personalized Consumer Recommendations",
            "authors": "Chang Xue, Youwei Lu, Chen Yang, Jinming Xing",
            "first_author": "Chang Xue",
            "url": "http://arxiv.org/abs/2509.06286v1",
            "pdf_url": "http://arxiv.org/abs/2509.06286",
            "publish_date": "2025-09-08",
            "abstract": "Personalization is a core capability across consumer technologies, streaming, shopping, wearables, and voice, yet it remains challenged by sparse interactions, fast content churn, and heterogeneous textual signals. We present RecMind, an LLM-enhanced graph recommender that treats the language model as a preference prior rather than a monolithic ranker. A frozen LLM equipped with lightweight adapters produces text-conditioned user/item embeddings from titles, attributes, and reviews; a LightGCN backbone learns collaborative embeddings from the user-item graph. We align the two views with a symmetric contrastive objective and fuse them via intra-layer gating, allowing language to dominate in cold/long-tail regimes and graph structure to stabilize rankings elsewhere. On Yelp and Amazon-Electronics, RecMind attains the best results on all eight reported metrics, with relative improvements up to +4.53\\% (Recall@40) and +4.01\\% (NDCG@40) over strong baselines. Ablations confirm both the necessity of cross-view alignment and the advantage of gating over late fusion and LLM-only variants.",
            "primary_category": "cs.LG",
            "code_url": "null"
        },
        "2509.06269": {
            "title": "REMI: A Novel Causal Schema Memory Architecture for Personalized Lifestyle Recommendation Agents",
            "authors": "Vishal Raman, Vijai Aravindh R, Abhijith Ragav",
            "first_author": "Vishal Raman",
            "url": "http://arxiv.org/abs/2509.06269v1",
            "pdf_url": "http://arxiv.org/abs/2509.06269",
            "publish_date": "2025-09-08",
            "abstract": "Personalized AI assistants often struggle to incorporate complex personal data and causal knowledge, leading to generic advice that lacks explanatory power. We propose REMI, a Causal Schema Memory architecture for a multimodal lifestyle agent that integrates a personal causal knowledge graph, a causal reasoning engine, and a schema based planning module. The idea is to deliver explainable, personalized recommendations in domains like fashion, personal wellness, and lifestyle planning. Our architecture uses a personal causal graph of the user's life events and habits, performs goal directed causal traversals enriched with external knowledge and hypothetical reasoning, and retrieves adaptable plan schemas to generate tailored action plans. A Large Language Model orchestrates these components, producing answers with transparent causal explanations. We outline the CSM system design and introduce new evaluation metrics for personalization and explainability, including Personalization Salience Score and Causal Reasoning Accuracy, to rigorously assess its performance. Results indicate that CSM based agents can provide more context aware, user aligned recommendations compared to baseline LLM agents. This work demonstrates a novel approach to memory augmented, causal reasoning in personalized agents, advancing the development of transparent and trustworthy AI lifestyle assistants.",
            "primary_category": "cs.AI",
            "code_url": "null"
        },
        "2509.06060": {
            "title": "ARIES: Relation Assessment and Model Recommendation for Deep Time Series Forecasting",
            "authors": "Fei Wang, Yujie Li, Zezhi Shao, Chengqing Yu, Yisong Fu, Zhulin An, Yongjun Xu, Xueqi Cheng",
            "first_author": "Fei Wang",
            "url": "http://arxiv.org/abs/2509.06060v1",
            "pdf_url": "http://arxiv.org/abs/2509.06060",
            "publish_date": "2025-09-07",
            "abstract": "Recent advancements in deep learning models for time series forecasting have been significant. These models often leverage fundamental time series properties such as seasonality and non-stationarity, which may suggest an intrinsic link between model performance and data properties. However, existing benchmark datasets fail to offer diverse and well-defined temporal patterns, restricting the systematic evaluation of such connections. Additionally, there is no effective model recommendation approach, leading to high time and cost expenditures when testing different architectures across different downstream applications. For those reasons, we propose ARIES, a framework for assessing relation between time series properties and modeling strategies, and for recommending deep forcasting models for realistic time series. First, we construct a synthetic dataset with multiple distinct patterns, and design a comprehensive system to compute the properties of time series. Next, we conduct an extensive benchmarking of over 50 forecasting models, and establish the relationship between time series properties and modeling strategies. Our experimental results reveal a clear correlation. Based on these findings, we propose the first deep forecasting model recommender, capable of providing interpretable suggestions for real-world time series. In summary, ARIES is the first study to establish the relations between the properties of time series data and modeling strategies, while also implementing a model recommendation system. The code is available at: https://github.com/blisky-li/ARIES.",
            "primary_category": "cs.LG",
            "code_url": "null"
        },
        "2509.05564": {
            "title": "Knowledge-Augmented Relation Learning for Complementary Recommendation with Large Language Models",
            "authors": "Chihiro Yamasaki, Kai Sugahara, Kazushi Okamoto",
            "first_author": "Chihiro Yamasaki",
            "url": "http://arxiv.org/abs/2509.05564v1",
            "pdf_url": "http://arxiv.org/abs/2509.05564",
            "publish_date": "2025-09-06",
            "abstract": "Complementary recommendations play a crucial role in e-commerce by enhancing user experience through suggestions of compatible items. Accurate classification of complementary item relationships requires reliable labels, but their creation presents a dilemma. Behavior-based labels are widely used because they can be easily generated from interaction logs; however, they often contain significant noise and lack reliability. While function-based labels (FBLs) provide high-quality definitions of complementary relationships by carefully articulating them based on item functions, their reliance on costly manual annotation severely limits a model's ability to generalize to diverse items. To resolve this trade-off, we propose Knowledge-Augmented Relation Learning (KARL), a framework that strategically fuses active learning with large language models (LLMs). KARL efficiently expands a high-quality FBL dataset at a low cost by selectively sampling data points that the classifier finds the most difficult and uses the label extension of the LLM. Our experiments showed that in out-of-distribution (OOD) settings, an unexplored item feature space, KARL improved the baseline accuracy by up to 37%. In contrast, in in-distribution (ID) settings, the learned item feature space, the improvement was less than 0.5%, with prolonged learning could degrade accuracy. These contrasting results are due to the data diversity driven by KARL's knowledge expansion, suggesting the need for a dynamic sampling strategy that adjusts diversity based on the prediction context (ID or OOD).",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2509.05460": {
            "title": "Calibrated Recommendations with Contextual Bandits",
            "authors": "Diego Feijer, Himan Abdollahpouri, Sanket Gupta, Alexander Clare, Yuxiao Wen, Todd Wasson, Maria Dimakopoulou, Zahra Nazari, Kyle Kretschman, Mounia Lalmas",
            "first_author": "Diego Feijer",
            "url": "http://arxiv.org/abs/2509.05460v1",
            "pdf_url": "http://arxiv.org/abs/2509.05460",
            "publish_date": "2025-09-05",
            "abstract": "Spotify's Home page features a variety of content types, including music, podcasts, and audiobooks. However, historical data is heavily skewed toward music, making it challenging to deliver a balanced and personalized content mix. Moreover, users' preference towards different content types may vary depending on the time of day, the day of week, or even the device they use. We propose a calibration method that leverages contextual bandits to dynamically learn each user's optimal content type distribution based on their context and preferences. Unlike traditional calibration methods that rely on historical averages, our approach boosts engagement by adapting to how users interests in different content types varies across contexts. Both offline and online results demonstrate improved precision and user engagement with the Spotify Home page, in particular with under-represented content types such as podcasts.",
            "primary_category": "cs.LG",
            "code_url": "null"
        },
        "2509.05115": {
            "title": "Hybrid Matrix Factorization Based Graph Contrastive Learning for Recommendation System",
            "authors": "Hao Chen, Wenming Ma, Zihao Chu, Mingqi Li",
            "first_author": "Hao Chen",
            "url": "http://arxiv.org/abs/2509.05115v1",
            "pdf_url": "http://arxiv.org/abs/2509.05115",
            "publish_date": "2025-09-05",
            "abstract": "In recent years, methods that combine contrastive learning with graph neural networks have emerged to address the challenges of recommendation systems, demonstrating powerful performance and playing a significant role in this domain. Contrastive learning primarily tackles the issue of data sparsity by employing data augmentation strategies, effectively alleviating this problem and showing promising results. Although existing research has achieved favorable outcomes, most current graph contrastive learning methods are based on two types of data augmentation strategies: the first involves perturbing the graph structure, such as by randomly adding or removing edges; and the second applies clustering techniques. We believe that the interactive information obtained through these two strategies does not fully capture the user-item interactions. In this paper, we propose a novel method called HMFGCL (Hybrid Matrix Factorization Based Graph Contrastive Learning), which integrates two distinct matrix factorization techniques-low-rank matrix factorization (MF) and singular value decomposition (SVD)-to complementarily acquire global collaborative information, thereby constructing enhanced views. Experimental results on multiple public datasets demonstrate that our model outperforms existing baselines, particularly on small-scale datasets.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2509.04810": {
            "title": "Code Review Without Borders: Evaluating Synthetic vs. Real Data for Review Recommendation",
            "authors": "Yogev Cohen, Dudi Ohayon, Romy Somkin, Yehudit Aperstein, Alexander Apartsin",
            "first_author": "Yogev Cohen",
            "url": "http://arxiv.org/abs/2509.04810v1",
            "pdf_url": "http://arxiv.org/abs/2509.04810",
            "publish_date": "2025-09-05",
            "abstract": "Automating the decision of whether a code change requires manual review is vital for maintaining software quality in modern development workflows. However, the emergence of new programming languages and frameworks creates a critical bottleneck: while large volumes of unlabelled code are readily available, there is an insufficient amount of labelled data to train supervised models for review classification. We address this challenge by leveraging Large Language Models (LLMs) to translate code changes from well-resourced languages into equivalent changes in underrepresented or emerging languages, generating synthetic training data where labelled examples are scarce. We assume that although LLMs have learned the syntax and semantics of new languages from available unlabelled code, they have yet to fully grasp which code changes are considered significant or review-worthy within these emerging ecosystems. To overcome this, we use LLMs to generate synthetic change examples and train supervised classifiers on them. We systematically compare the performance of these classifiers against models trained on real labelled data. Our experiments across multiple GitHub repositories and language pairs demonstrate that LLM-generated synthetic data can effectively bootstrap review recommendation systems, narrowing the performance gap even in low-resource settings. This approach provides a scalable pathway to extend automated code review capabilities to rapidly evolving technology stacks, even in the absence of annotated data.",
            "primary_category": "cs.SE",
            "code_url": "null"
        },
        "2509.04404": {
            "title": "No Thoughts Just AI: Biased LLM Hiring Recommendations Alter Human Decision Making and Limit Human Autonomy",
            "authors": "Kyra Wilson, Mattea Sim, Anna-Maria Gueorguieva, Aylin Caliskan",
            "first_author": "Kyra Wilson",
            "url": "http://arxiv.org/abs/2509.04404v2",
            "pdf_url": "http://arxiv.org/abs/2509.04404",
            "publish_date": "2025-09-04",
            "abstract": "In this study, we conduct a resume-screening experiment (N=528) where people collaborate with simulated AI models exhibiting race-based preferences (bias) to evaluate candidates for 16 high and low status occupations. Simulated AI bias approximates factual and counterfactual estimates of racial bias in real-world AI systems. We investigate people's preferences for White, Black, Hispanic, and Asian candidates (represented through names and affinity groups on quality-controlled resumes) across 1,526 scenarios and measure their unconscious associations between race and status using implicit association tests (IATs), which predict discriminatory hiring decisions but have not been investigated in human-AI collaboration. When making decisions without AI or with AI that exhibits no race-based preferences, people select all candidates at equal rates. However, when interacting with AI favoring a particular group, people also favor those candidates up to 90% of the time, indicating a significant behavioral shift. The likelihood of selecting candidates whose identities do not align with common race-status stereotypes can increase by 13% if people complete an IAT before conducting resume screening. Finally, even if people think AI recommendations are low quality or not important, their decisions are still vulnerable to AI bias under certain circumstances. This work has implications for people's autonomy in AI-HITL scenarios, AI and work, design and evaluation of AI hiring systems, and strategies for mitigating bias in collaborative decision-making tasks. In particular, organizational and regulatory policy should acknowledge the complex nature of AI-HITL decision making when implementing these systems, educating people who use them, and determining which are subject to oversight.",
            "primary_category": "cs.CY",
            "code_url": "null"
        },
        "2509.04534": {
            "title": "Quantized Large Language Models in Biomedical Natural Language Processing: Evaluation and Recommendation",
            "authors": "Zaifu Zhan, Shuang Zhou, Min Zeng, Kai Yu, Meijia Song, Xiaoyi Chen, Jun Wang, Yu Hou, Rui Zhang",
            "first_author": "Zaifu Zhan",
            "url": "http://arxiv.org/abs/2509.04534v1",
            "pdf_url": "http://arxiv.org/abs/2509.04534",
            "publish_date": "2025-09-04",
            "abstract": "Large language models have demonstrated remarkable capabilities in biomedical natural language processing, yet their rapid growth in size and computational requirements present a major barrier to adoption in healthcare settings where data privacy precludes cloud deployment and resources are limited. In this study, we systematically evaluated the impact of quantization on 12 state-of-the-art large language models, including both general-purpose and biomedical-specific models, across eight benchmark datasets covering four key tasks: named entity recognition, relation extraction, multi-label classification, and question answering. We show that quantization substantially reduces GPU memory requirements-by up to 75%-while preserving model performance across diverse tasks, enabling the deployment of 70B-parameter models on 40GB consumer-grade GPUs. In addition, domain-specific knowledge and responsiveness to advanced prompting methods are largely maintained. These findings provide significant practical and guiding value, highlighting quantization as a practical and effective strategy for enabling the secure, local deployment of large yet high-capacity language models in biomedical contexts, bridging the gap between technical advances in AI and real-world clinical translation.",
            "primary_category": "cs.CL",
            "code_url": "null"
        },
        "2509.03746": {
            "title": "Efficient Item ID Generation for Large-Scale LLM-based Recommendation",
            "authors": "Anushya Subbiah, Vikram Aggarwal, James Pine, Steffen Rendle, Krishna Sayana, Kun Su",
            "first_author": "Anushya Subbiah",
            "url": "http://arxiv.org/abs/2509.03746v1",
            "pdf_url": "http://arxiv.org/abs/2509.03746",
            "publish_date": "2025-09-03",
            "abstract": "Integrating product catalogs and user behavior into LLMs can enhance recommendations with broad world knowledge, but the scale of real-world item catalogs, often containing millions of discrete item identifiers (Item IDs), poses a significant challenge. This contrasts with the smaller, tokenized text vocabularies typically used in LLMs. The predominant view within the LLM-based recommendation literature is that it is infeasible to treat item ids as a first class citizen in the LLM and instead some sort of tokenization of an item into multiple tokens is required. However, this creates a key practical bottleneck in serving these models for real-time low-latency applications.   Our paper challenges this predominant practice and integrates item ids as first class citizens into the LLM. We provide simple, yet highly effective, novel training and inference modifications that enable single-token representations of items and single-step decoding. Our method shows improvements in recommendation quality (Recall and NDCG) over existing techniques on the Amazon shopping datasets while significantly improving inference efficiency by 5x-14x. Our work offers an efficiency perspective distinct from that of other popular approaches within LLM-based recommendation, potentially inspiring further research and opening up a new direction for integrating IDs into LLMs. Our code is available here https://drive.google.com/file/d/1cUMj37rV0Z1bCWMdhQ6i4q4eTRQLURtC",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2509.03187": {
            "title": "Enhancing Interpretability and Effectiveness in Recommendation with Numerical Features via Learning to Contrast the Counterfactual samples",
            "authors": "Xiaoxiao Xu, Hao Wu, Wenhui Yu, Lantao Hu, Peng Jiang, Kun Gai",
            "first_author": "Xiaoxiao Xu",
            "url": "http://arxiv.org/abs/2509.03187v1",
            "pdf_url": "http://arxiv.org/abs/2509.03187",
            "publish_date": "2025-09-03",
            "abstract": "We propose a general model-agnostic Contrastive learning framework with Counterfactual Samples Synthesizing (CCSS) for modeling the monotonicity between the neural network output and numerical features which is critical for interpretability and effectiveness of recommender systems. CCSS models the monotonicity via a two-stage process: synthesizing counterfactual samples and contrasting the counterfactual samples. The two techniques are naturally integrated into a model-agnostic framework, forming an end-to-end training process. Abundant empirical tests are conducted on a publicly available dataset and a real industrial dataset, and the results well demonstrate the effectiveness of our proposed CCSS. Besides, CCSS has been deployed in our real large-scale industrial recommender, successfully serving over hundreds of millions users.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2509.03131": {
            "title": "RecBase: Generative Foundation Model Pretraining for Zero-Shot Recommendation",
            "authors": "Sashuai Zhou, Weinan Gan, Qijiong Liu, Ke Lei, Jieming Zhu, Hai Huang, Yan Xia, Ruiming Tang, Zhenhua Dong, Zhou Zhao",
            "first_author": "Sashuai Zhou",
            "url": "http://arxiv.org/abs/2509.03131v1",
            "pdf_url": "http://arxiv.org/abs/2509.03131",
            "publish_date": "2025-09-03",
            "abstract": "Recent advances in LLM-based recommendation have shown promise, yet their cross-domain generalization is hindered by a fundamental mismatch between language-centric pretraining and the recommendation task. Existing methods, relying on language-level knowledge, fail to capture dynamic, item-level user interests across domains. To bridge this gap, we propose RecBase, a domain-agnostic foundational model pretrained with a recommendation-oriented objective. RecBase leverages a large-scale, heterogeneous, cross-domain corpus with unified textual representations and feature mappings to enhance cross-domain generalization. To further align item semantics across domains, we introduce a unified item tokenizer that encodes items into hierarchical concept identifiers, enabling structured representation and efficient vocabulary sharing. The model is trained using an autoregressive objective to capture complex item-level sequential patterns. On eight real-world datasets, our 1.5B-parameter model matches or surpasses the performance of LLM baselines up to 7B parameters in zero-shot and cross-domain recommendation tasks.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2509.03130": {
            "title": "A Plug-and-play Model-agnostic Embedding Enhancement Approach for Explainable Recommendation",
            "authors": "Yunqi Mi, Boyang Yan, Guoshuai Zhao, Jialie Shen, Xueming Qian",
            "first_author": "Yunqi Mi",
            "url": "http://arxiv.org/abs/2509.03130v1",
            "pdf_url": "http://arxiv.org/abs/2509.03130",
            "publish_date": "2025-09-03",
            "abstract": "Existing multimedia recommender systems provide users with suggestions of media by evaluating the similarities, such as games and movies. To enhance the semantics and explainability of embeddings, it is a consensus to apply additional information (e.g., interactions, contexts, popularity). However, without systematic consideration of representativeness and value, the utility and explainability of embedding drops drastically. Hence, we introduce RVRec, a plug-and-play model-agnostic embedding enhancement approach that can improve both personality and explainability of existing systems. Specifically, we propose a probability-based embedding optimization method that uses a contrastive loss based on negative 2-Wasserstein distance to learn to enhance the representativeness of the embeddings. In addtion, we introduce a reweighing method based on multivariate Shapley values strategy to evaluate and explore the value of interactions and embeddings. Extensive experiments on multiple backbone recommenders and real-world datasets show that RVRec can improve the personalization and explainability of existing recommenders, outperforming state-of-the-art baselines.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2509.03024": {
            "title": "Efficient Privacy-Preserving Recommendation on Sparse Data using Fully Homomorphic Encryption",
            "authors": "Moontaha Nishat Chowdhury, Andr\u00e9 Bauer, Minxuan Zhou",
            "first_author": "Moontaha Nishat Chowdhury",
            "url": "http://arxiv.org/abs/2509.03024v1",
            "pdf_url": "http://arxiv.org/abs/2509.03024",
            "publish_date": "2025-09-03",
            "abstract": "In today's data-driven world, recommendation systems personalize user experiences across industries but rely on sensitive data, raising privacy concerns. Fully homomorphic encryption (FHE) can secure these systems, but a significant challenge in applying FHE to recommendation systems is efficiently handling the inherently large and sparse user-item rating matrices. FHE operations are computationally intensive, and naively processing various sparse matrices in recommendation systems would be prohibitively expensive. Additionally, the communication overhead between parties remains a critical concern in encrypted domains. We propose a novel approach combining Compressed Sparse Row (CSR) representation with FHE-based matrix factorization that efficiently handles matrix sparsity in the encrypted domain while minimizing communication costs. Our experimental results demonstrate high recommendation accuracy with encrypted data while achieving the lowest communication costs, effectively preserving user privacy.",
            "primary_category": "cs.CR",
            "code_url": "null"
        },
        "2509.02943": {
            "title": "Knowledge graph-based personalized multimodal recommendation fusion framework",
            "authors": "Yu Fang",
            "first_author": "Yu Fang",
            "url": "http://arxiv.org/abs/2509.02943v1",
            "pdf_url": "http://arxiv.org/abs/2509.02943",
            "publish_date": "2025-09-03",
            "abstract": "In the contemporary age characterized by information abundance, rapid advancements in artificial intelligence have rendered recommendation systems indispensable. Conventional recommendation methodologies based on collaborative filtering or individual attributes encounter deficiencies in capturing nuanced user interests. Knowledge graphs and multimodal data integration offer enhanced representations of users and items with greater richness and precision. This paper reviews existing multimodal knowledge graph recommendation frameworks, identifying shortcomings in modal interaction and higher-order dependency modeling. We propose the Cross-Graph Cross-Modal Mutual Information-Driven Unified Knowledge Graph Learning and Recommendation Framework (CrossGMMI-DUKGLR), which employs pre-trained visual-text alignment models for feature extraction, achieves fine-grained modality fusion through multi-head cross-attention, and propagates higher-order adjacency information via graph attention networks.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2509.02942": {
            "title": "RankGraph: Unified Heterogeneous Graph Learning for Cross-Domain Recommendation",
            "authors": "Renzhi Wu, Junjie Yang, Li Chen, Hong Li, Li Yu, Hong Yan",
            "first_author": "Renzhi Wu",
            "url": "http://arxiv.org/abs/2509.02942v1",
            "pdf_url": "http://arxiv.org/abs/2509.02942",
            "publish_date": "2025-09-03",
            "abstract": "Cross-domain recommendation systems face the challenge of integrating fine-grained user and item relationships across various product domains. To address this, we introduce RankGraph, a scalable graph learning framework designed to serve as a core component in recommendation foundation models (FMs). By constructing and leveraging graphs composed of heterogeneous nodes and edges across multiple products, RankGraph enables the integration of complex relationships between users, posts, ads, and other entities. Our framework employs a GPU-accelerated Graph Neural Network and contrastive learning, allowing for dynamic extraction of subgraphs such as item-item and user-user graphs to support similarity-based retrieval and real-time clustering. Furthermore, RankGraph integrates graph-based pretrained representations as contextual tokens into FM sequence models, enriching them with structured relational knowledge. RankGraph has demonstrated improvements in click (+0.92%) and conversion rates (+2.82%) in online A/B tests, showcasing its effectiveness in cross-domain recommendation scenarios.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2509.02543": {
            "title": "A Keyframe-Based Approach for Auditing Bias in YouTube Shorts Recommendations",
            "authors": "Mert Can Cakmak, Nitin Agarwal",
            "first_author": "Mert Can Cakmak",
            "url": "http://arxiv.org/abs/2509.02543v1",
            "pdf_url": "http://arxiv.org/abs/2509.02543",
            "publish_date": "2025-09-02",
            "abstract": "YouTube Shorts and other short-form video platforms now influence how billions engage with content, yet their recommendation systems remain largely opaque. Small shifts in promoted content can significantly impact user exposure, especially for politically sensitive topics. In this work, we propose a keyframe-based method to audit bias and drift in short-form video recommendations. Rather than analyzing full videos or relying on metadata, we extract perceptually salient keyframes, generate captions, and embed both into a shared content space. Using visual mapping across recommendation chains, we observe consistent shifts and clustering patterns that indicate topic drift and potential filtering. Comparing politically sensitive topics with general YouTube categories, we find notable differences in recommendation behavior. Our findings show that keyframes provide an efficient and interpretable lens for understanding bias in short-form video algorithms.",
            "primary_category": "cs.SI",
            "code_url": "null"
        },
        "2509.02266": {
            "title": "Leveraging Media Frames to Improve Normative Diversity in News Recommendations",
            "authors": "Sourabh Dattawad, Agnese Daffara, Tanise Ceron",
            "first_author": "Sourabh Dattawad",
            "url": "http://arxiv.org/abs/2509.02266v1",
            "pdf_url": "http://arxiv.org/abs/2509.02266",
            "publish_date": "2025-09-02",
            "abstract": "Click-based news recommender systems suggest users content that aligns with their existing history, limiting the diversity of articles they encounter. Recent advances in aspect-based diversification -- adding features such as sentiments or news categories (e.g. world, politics) -- have made progress toward diversifying recommendations in terms of perspectives. However, these approaches often overlook the role of news framing, which shapes how stories are told by emphasizing specific angles or interpretations. In this paper, we treat media frames as a controllable aspect within the recommendation pipeline. By selecting articles based on a diversity of frames, our approach emphasizes varied narrative angles and broadens the interpretive space recommended to users. In addition to introducing frame-based diversification method, our work is the first to assess the impact of a news recommender system that integrates frame diversity using normative diversity metrics: representation, calibration, and activation. Our experiments based on media frame diversification show an improvement in exposure to previously unclicked frames up to 50%. This is important because repeated exposure to the same frames can reinforce existing biases or narrow interpretations, whereas introducing novel frames broadens users' understanding of issues and perspectives. The method also enhances diversification across categorical and sentiment levels, thereby demonstrating that framing acts as a strong control lever for enhancing normative diversity.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2509.02220": {
            "title": "Towards Multi-Aspect Diversification of News Recommendations Using Neuro-Symbolic AI for Individual and Societal Benefit",
            "authors": "Markus Reiter-Haas, Elisabeth Lex",
            "first_author": "Markus Reiter-Haas",
            "url": "http://arxiv.org/abs/2509.02220v1",
            "pdf_url": "http://arxiv.org/abs/2509.02220",
            "publish_date": "2025-09-02",
            "abstract": "News recommendations are complex, with diversity playing a vital role. So far, existing literature predominantly focuses on specific aspects of news diversity, such as viewpoints. In this paper, we introduce multi-aspect diversification in four distinct recommendation modes and outline the nuanced challenges in diversifying lists, sequences, summaries, and interactions. Our proposed research direction combines symbolic and subsymbolic artificial intelligence, leveraging both knowledge graphs and rule learning. We plan to evaluate our models using user studies to not only capture behavior but also their perceived experience. Our vision to balance news consumption points to other positive effects for users (e.g., increased serendipity) and society (e.g., decreased polarization).",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2509.02017": {
            "title": "Empowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic IDs",
            "authors": "Yuhao Wang, Junwei Pan, Xinhang Li, Maolin Wang, Yuan Wang, Yue Liu, Dapeng Liu, Jie Jiang, Xiangyu Zhao",
            "first_author": "Yuhao Wang",
            "url": "http://arxiv.org/abs/2509.02017v1",
            "pdf_url": "http://arxiv.org/abs/2509.02017",
            "publish_date": "2025-09-02",
            "abstract": "Sequential recommendation (SR) aims to capture users' dynamic interests and sequential patterns based on their historical interactions. Recently, the powerful capabilities of large language models (LLMs) have driven their adoption in SR. However, we identify two critical challenges in existing LLM-based SR methods: 1) embedding collapse when incorporating pre-trained collaborative embeddings and 2) catastrophic forgetting of quantized embeddings when utilizing semantic IDs. These issues dampen the model scalability and lead to suboptimal recommendation performance. Therefore, based on LLMs like Llama3-8B-instruct, we introduce a novel SR framework named MME-SID, which integrates multimodal embeddings and quantized embeddings to mitigate embedding collapse. Additionally, we propose a Multimodal Residual Quantized Variational Autoencoder (MM-RQ-VAE) with maximum mean discrepancy as the reconstruction loss and contrastive learning for alignment, which effectively preserve intra-modal distance information and capture inter-modal correlations, respectively. To further alleviate catastrophic forgetting, we initialize the model with the trained multimodal code embeddings. Finally, we fine-tune the LLM efficiently using LoRA in a multimodal frequency-aware fusion manner. Extensive experiments on three public datasets validate the superior performance of MME-SID thanks to its capability to mitigate embedding collapse and catastrophic forgetting. The implementation code and datasets are publicly available for reproduction: https://github.com/Applied-Machine-Learning-Lab/MME-SID.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2509.04498": {
            "title": "Where Should I Study? Biased Language Models Decide! Evaluating Fairness in LMs for Academic Recommendations",
            "authors": "Krithi Shailya, Akhilesh Kumar Mishra, Gokul S Krishnan, Balaraman Ravindran",
            "first_author": "Krithi Shailya",
            "url": "http://arxiv.org/abs/2509.04498v1",
            "pdf_url": "http://arxiv.org/abs/2509.04498",
            "publish_date": "2025-09-01",
            "abstract": "Large Language Models (LLMs) are increasingly used as daily recommendation systems for tasks like education planning, yet their recommendations risk perpetuating societal biases. This paper empirically examines geographic, demographic, and economic biases in university and program suggestions from three open-source LLMs: LLaMA-3.1-8B, Gemma-7B, and Mistral-7B. Using 360 simulated user profiles varying by gender, nationality, and economic status, we analyze over 25,000 recommendations. Results show strong biases: institutions in the Global North are disproportionately favored, recommendations often reinforce gender stereotypes, and institutional repetition is prevalent. While LLaMA-3.1 achieves the highest diversity, recommending 481 unique universities across 58 countries, systemic disparities persist. To quantify these issues, we propose a novel, multi-dimensional evaluation framework that goes beyond accuracy by measuring demographic and geographic representation. Our findings highlight the urgent need for bias consideration in educational LMs to ensure equitable global access to higher education.",
            "primary_category": "cs.CL",
            "code_url": "null"
        },
        "2509.01551": {
            "title": "Cloud-Device Collaborative Agents for Sequential Recommendation",
            "authors": "Jing Long, Sirui Huang, Huan Huo, Tong Chen, Hongzhi Yin, Guandong Xu",
            "first_author": "Jing Long",
            "url": "http://arxiv.org/abs/2509.01551v1",
            "pdf_url": "http://arxiv.org/abs/2509.01551",
            "publish_date": "2025-09-01",
            "abstract": "Recent advances in large language models (LLMs) have enabled agent-based recommendation systems with strong semantic understanding and flexible reasoning capabilities. While LLM-based agents deployed in the cloud offer powerful personalization, they often suffer from privacy concerns, limited access to real-time signals, and scalability bottlenecks. Conversely, on-device agents ensure privacy and responsiveness but lack the computational power for global modeling and large-scale retrieval. To bridge these complementary limitations, we propose CDA4Rec, a novel Cloud-Device collaborative framework for sequential Recommendation, powered by dual agents: a cloud-side LLM and a device-side small language model (SLM). CDA4Rec tackles the core challenge of cloud-device coordination by decomposing the recommendation task into modular sub-tasks including semantic modeling, candidate retrieval, structured user modeling, and final ranking, which are allocated to cloud or device based on computational demands and privacy sensitivity. A strategy planning mechanism leverages the cloud agent's reasoning ability to generate personalized execution plans, enabling context-aware task assignment and partial parallel execution across agents. This design ensures real-time responsiveness, improved efficiency, and fine-grained personalization, even under diverse user states and behavioral sparsity. Extensive experiments across multiple real-world datasets demonstrate that CDA4Rec consistently outperforms competitive baselines in both accuracy and efficiency, validating its effectiveness in heterogeneous and resource-constrained environments.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2509.01549": {
            "title": "Ultra Fast Warm Start Solution for Graph Recommendations",
            "authors": "Viacheslav Yusupov, Maxim Rakhuba, Evgeny Frolov",
            "first_author": "Viacheslav Yusupov",
            "url": "http://arxiv.org/abs/2509.01549v1",
            "pdf_url": "http://arxiv.org/abs/2509.01549",
            "publish_date": "2025-09-01",
            "abstract": "In this work, we present a fast and effective Linear approach for updating recommendations in a scalable graph-based recommender system UltraGCN. Solving this task is extremely important to maintain the relevance of the recommendations under the conditions of a large amount of new data and changing user preferences. To address this issue, we adapt the simple yet effective low-rank approximation approach to the graph-based model. Our method delivers instantaneous recommendations that are up to 30 times faster than conventional methods, with gains in recommendation quality, and demonstrates high scalability even on the large catalogue datasets.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2509.01344": {
            "title": "AgroSense: An Integrated Deep Learning System for Crop Recommendation via Soil Image Analysis and Nutrient Profiling",
            "authors": "Vishal Pandey, Ranjita Das, Debasmita Biswas",
            "first_author": "Vishal Pandey",
            "url": "http://arxiv.org/abs/2509.01344v1",
            "pdf_url": "http://arxiv.org/abs/2509.01344",
            "publish_date": "2025-09-01",
            "abstract": "Meeting the increasing global demand for food security and sustainable farming requires intelligent crop recommendation systems that operate in real time. Traditional soil analysis techniques are often slow, labor-intensive, and not suitable for on-field decision-making. To address these limitations, we introduce AgroSense, a deep-learning framework that integrates soil image classification and nutrient profiling to produce accurate and contextually relevant crop recommendations. AgroSense comprises two main components: a Soil Classification Module, which leverages ResNet-18, EfficientNet-B0, and Vision Transformer architectures to categorize soil types from images; and a Crop Recommendation Module, which employs a Multi-Layer Perceptron, XGBoost, LightGBM, and TabNet to analyze structured soil data, including nutrient levels, pH, and rainfall. We curated a multimodal dataset of 10,000 paired samples drawn from publicly available Kaggle repositories, approximately 50,000 soil images across seven classes, and 25,000 nutrient profiles for experimental evaluation. The fused model achieves 98.0% accuracy, with a precision of 97.8%, a recall of 97.7%, and an F1-score of 96.75%, while RMSE and MAE drop to 0.32 and 0.27, respectively. Ablation studies underscore the critical role of multimodal coupling, and statistical validation via t-tests and ANOVA confirms the significance of our improvements. AgroSense offers a practical, scalable solution for real-time decision support in precision agriculture and paves the way for future lightweight multimodal AI systems in resource-constrained environments.",
            "primary_category": "cs.CV",
            "code_url": "null"
        },
        "2509.00802": {
            "title": "XAI-Driven Machine Learning System for Driving Style Recognition and Personalized Recommendations",
            "authors": "Feriel Amel Sellal, Ahmed Ayoub Bellachia, Meryem Malak Dif, Enguerrand De Rautlin De La Roy, Mouhamed Amine Bouchiha, Yacine Ghamri-Doudane",
            "first_author": "Feriel Amel Sellal",
            "url": "http://arxiv.org/abs/2509.00802v1",
            "pdf_url": "http://arxiv.org/abs/2509.00802",
            "publish_date": "2025-08-31",
            "abstract": "Artificial intelligence (AI) is increasingly used in the automotive industry for applications such as driving style classification, which aims to improve road safety, efficiency, and personalize user experiences. While deep learning (DL) models, such as Long Short-Term Memory (LSTM) networks, excel at this task, their black-box nature limits interpretability and trust. This paper proposes a machine learning (ML)-based method that balances high accuracy with interpretability. We introduce a high-quality dataset, CARLA-Drive, and leverage ML techniques like Random Forest (RF), Gradient Boosting (XGBoost), and Support Vector Machine (SVM), which are efficient, lightweight, and interpretable. In addition, we apply the SHAP (Shapley Additive Explanations) explainability technique to provide personalized recommendations for safer driving. Achieving an accuracy of 0.92 on a three-class classification task with both RF and XGBoost classifiers, our approach matches DL models in performance while offering transparency and practicality for real-world deployment in intelligent transportation systems.",
            "primary_category": "cs.LG",
            "code_url": "null"
        },
        "2509.00698": {
            "title": "Learning to Shop Like Humans: A Review-driven Retrieval-Augmented Recommendation Framework with LLMs",
            "authors": "Kaiwen Wei, Jinpeng Gao, Jiang Zhong, Yuming Yang, Fengmao Lv, Zhenyang Li",
            "first_author": "Kaiwen Wei",
            "url": "http://arxiv.org/abs/2509.00698v1",
            "pdf_url": "http://arxiv.org/abs/2509.00698",
            "publish_date": "2025-08-31",
            "abstract": "Large language models (LLMs) have shown strong potential in recommendation tasks due to their strengths in language understanding, reasoning and knowledge integration. These capabilities are especially beneficial for review-based recommendation, which relies on semantically rich user-generated texts to reveal fine-grained user preferences and item attributes. However, effectively incorporating reviews into LLM-based recommendation remains challenging due to (1) inefficient to dynamically utilize user reviews under LLMs' constrained context windows, and (2) lacking effective mechanisms to prioritize reviews most relevant to the user's current decision context. To address these challenges, we propose RevBrowse, a review-driven recommendation framework inspired by the \"browse-then-decide\" decision process commonly observed in online user behavior. RevBrowse integrates user reviews into the LLM-based reranking process to enhance its ability to distinguish between candidate items. To improve the relevance and efficiency of review usage, we introduce PrefRAG, a retrieval-augmented module that disentangles user and item representations into structured forms and adaptively retrieves preference-relevant content conditioned on the target item. Extensive experiments on four Amazon review datasets demonstrate that RevBrowse achieves consistent and significant improvements over strong baselines, highlighting its generalizability and effectiveness in modeling dynamic user preferences. Furthermore, since the retrieval-augmented process is transparent, RevBrowse offers a certain level of interpretability by making visible which reviews influence the final recommendation.",
            "primary_category": "cs.CL",
            "code_url": "null"
        },
        "2509.00528": {
            "title": "Game Theoretic Resilience Recommendation Framework for CyberPhysical Microgrids Using Hypergraph MetaLearning",
            "authors": "S Krishna Niketh, Prasanta K Panigrahi, V Vignesh, Mayukha Pal",
            "first_author": "S Krishna Niketh",
            "url": "http://arxiv.org/abs/2509.00528v1",
            "pdf_url": "http://arxiv.org/abs/2509.00528",
            "publish_date": "2025-08-30",
            "abstract": "This paper presents a physics-aware cyberphysical resilience framework for radial microgrids under coordinated cyberattacks. The proposed approach models the attacker through a hypergraph neural network (HGNN) enhanced with model agnostic metalearning (MAML) to rapidly adapt to evolving defense strategies and predict high-impact contingencies. The defender is modeled via a bi-level Stackelberg game, where the upper level selects optimal tie-line switching and distributed energy resource (DER) dispatch using an Alternating Direction Method of Multipliers (ADMM) coordinator embedded within the Non-dominated Sorting Genetic Algorithm II (NSGA-II). The framework simultaneously optimizes load served, operational cost, and voltage stability, ensuring all post-defense states satisfy network physics constraints. The methodology is first validated on the IEEE 69-bus distribution test system with 12 DERs, 8 critical loads, and 5 tie-lines, and then extended to higher bus systems including the IEEE 123-bus feeder and a synthetic 300-bus distribution system. Results show that the proposed defense strategy restores nearly full service for 90% of top-ranked attacks, mitigates voltage violations, and identifies Feeder 2 as the principal vulnerability corridor. Actionable operating rules are derived, recommending pre-arming of specific tie-lines to enhance resilience, while higher bus system studies confirm scalability of the framework on the IEEE 123-bus and 300-bus systems.",
            "primary_category": "eess.SY",
            "code_url": "null"
        },
        "2509.00389": {
            "title": "Beyond Negative Transfer: Disentangled Preference-Guided Diffusion for Cross-Domain Sequential Recommendation",
            "authors": "Xiaoxin Ye, Chengkai Huang, Hongtao Huang, Lina Yao",
            "first_author": "Xiaoxin Ye",
            "url": "http://arxiv.org/abs/2509.00389v1",
            "pdf_url": "http://arxiv.org/abs/2509.00389",
            "publish_date": "2025-08-30",
            "abstract": "Cross-Domain Sequential Recommendation (CDSR) leverages user behaviors across domains to enhance recommendation quality. However, naive aggregation of sequential signals can introduce conflicting domain-specific preferences, leading to negative transfer. While Sequential Recommendation (SR) already suffers from noisy behaviors such as misclicks and impulsive actions, CDSR further amplifies this issue due to domain heterogeneity arising from diverse item types and user intents. The core challenge is disentangling three intertwined signals: domain-invariant preferences, domain-specific preferences, and noise. Diffusion Models (DMs) offer a generative denoising framework well-suited for disentangling complex user preferences and enhancing robustness to noise. Their iterative refinement process enables gradual denoising, making them effective at capturing subtle preference signals. However, existing applications in recommendation face notable limitations: sequential DMs often conflate shared and domain-specific preferences, while cross-domain collaborative filtering DMs neglect temporal dynamics, limiting their ability to model evolving user preferences. To bridge these gaps, we propose \\textbf{DPG-Diff}, a novel Disentangled Preference-Guided Diffusion Model, the first diffusion-based approach tailored for CDSR, to or best knowledge. DPG-Diff decomposes user preferences into domain-invariant and domain-specific components, which jointly guide the reverse diffusion process. This disentangled guidance enables robust cross-domain knowledge transfer, mitigates negative transfer, and filters sequential noise. Extensive experiments on real-world datasets demonstrate that DPG-Diff consistently outperforms state-of-the-art baselines across multiple metrics.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2509.00199": {
            "title": "Algorithm Adaptation Bias in Recommendation System Online Experiments",
            "authors": "Chen Zheng, Zhenyu Zhao",
            "first_author": "Chen Zheng",
            "url": "http://arxiv.org/abs/2509.00199v1",
            "pdf_url": "http://arxiv.org/abs/2509.00199",
            "publish_date": "2025-08-29",
            "abstract": "Online experiments (A/B tests) are widely regarded as the gold standard for evaluating recommender system variants and guiding launch decisions. However, a variety of biases can distort the results of the experiment and mislead decision-making. An underexplored but critical bias is algorithm adaptation effect. This bias arises from the flywheel dynamics among production models, user data, and training pipelines: new models are evaluated on user data whose distributions are shaped by the incumbent system or tested only in a small treatment group. As a result, the measured effect of a new product change in modeling and user experience in this constrained experimental setting can diverge substantially from its true impact in full deployment. In practice, the experiment results often favor the production variant with large traffic while underestimating the performance of the test variant with small traffic, which leads to missing opportunities to launch a true winning arm or underestimating the impact. This paper aims to raise awareness of algorithm adaptation bias, situate it within the broader landscape of RecSys evaluation biases, and motivate discussion of solutions that span experiment design, measurement, and adjustment. We detail the mechanisms of this bias, present empirical evidence from real-world experiments, and discuss potential methods for a more robust online evaluation.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2508.21801": {
            "title": "DMGIN: How Multimodal LLMs Enhance Large Recommendation Models for Lifelong User Post-click Behaviors",
            "authors": "Zhuoxing Wei, Qingchen Xie, Qi Liu",
            "first_author": "Zhuoxing Wei",
            "url": "http://arxiv.org/abs/2508.21801v1",
            "pdf_url": "http://arxiv.org/abs/2508.21801",
            "publish_date": "2025-08-29",
            "abstract": "Modeling user interest based on lifelong user behavior sequences is crucial for enhancing Click-Through Rate (CTR) prediction. However, long post-click behavior sequences themselves pose severe performance issues: the sheer volume of data leads to high computational costs and inefficiencies in model training and inference. Traditional methods address this by introducing two-stage approaches, but this compromises model effectiveness due to incomplete utilization of the full sequence context. More importantly, integrating multimodal embeddings into existing large recommendation models (LRM) presents significant challenges: These embeddings often exacerbate computational burdens and mismatch with LRM architectures. To address these issues and enhance the model's efficiency and accuracy, we introduce Deep Multimodal Group Interest Network (DMGIN). Given the observation that user post-click behavior sequences contain a large number of repeated items with varying behaviors and timestamps, DMGIN employs Multimodal LLMs(MLLM) for grouping to reorganize complete lifelong post-click behavior sequences more effectively, with almost no additional computational overhead, as opposed to directly introducing multimodal embeddings. To mitigate the potential information loss from grouping, we have implemented two key strategies. First, we analyze behaviors within each group using both interest statistics and intra-group transformers to capture group traits. Second, apply inter-group transformers to temporally ordered groups to capture the evolution of user group interests. Our extensive experiments on both industrial and public datasets confirm the effectiveness and efficiency of DMGIN. The A/B test in our LBS advertising system shows that DMGIN improves CTR by 4.7% and Revenue per Mile by 2.3%.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2508.21572": {
            "title": "NewsReX: A More Efficient Approach to News Recommendation with Keras 3 and JAX",
            "authors": "Igor L. R. Azevedo, Toyotaro Suzumura, Yuichiro Yasui",
            "first_author": "Igor L. R. Azevedo",
            "url": "http://arxiv.org/abs/2508.21572v1",
            "pdf_url": "http://arxiv.org/abs/2508.21572",
            "publish_date": "2025-08-29",
            "abstract": "Reproducing and comparing results in news recommendation research has become increasingly difficult. This is due to a fragmented ecosystem of diverse codebases, varied configurations, and mainly due to resource-intensive models. We introduce NewsReX, an open-source library designed to streamline this process. Our key contribution is a modern implementation built on Keras 3 and JAX, which provides an increase in computational efficiency. Experiments show that NewsReX is faster than current implementations. To support broader research, we provide a straightforward guide and scripts for training models on custom datasets. We validated this functionality using a proprietary Japanese news dataset from Nikkei News, a leading Japanese media corporation renowned for its comprehensive coverage of business, economic, and financial news. NewsReX makes reproducing complex experiments faster and more accessible to a wider range of hardware making sure the speed up it also achieved for less powerful GPUs, like an 8GB RTX 3060 Ti. Beyond the library, this paper offers an analysis of key training parameters often overlooked in the literature, including the effect of different negative sampling strategies, the varying number of epochs, the impact of random batching, and more. This supplementary analysis serves as a valuable reference for future research, aiming to reduce redundant computation when comparing baselines and guide best practices. Code available at https://github.com/igor17400/NewsReX.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2508.20945": {
            "title": "Efficient Large-Scale Cross-Domain Sequential Recommendation with Dynamic State Representations",
            "authors": "Manuel V. Loureiro, Steven Derby, Aleksei Medvedev, Alejandro Ariza-Casabona, Gonzalo Fiz Pontiveros, Tri Kurniawan Wijaya",
            "first_author": "Manuel V. Loureiro",
            "url": "http://arxiv.org/abs/2508.20945v1",
            "pdf_url": "http://arxiv.org/abs/2508.20945",
            "publish_date": "2025-08-28",
            "abstract": "Recently, autoregressive recommendation models (ARMs), such as Meta's HSTU model, have emerged as a major breakthrough over traditional Deep Learning Recommendation Models (DLRMs), exhibiting the highly sought-after scaling law behaviour. However, when applied to multi-domain scenarios, the transformer architecture's attention maps become a computational bottleneck, as they attend to all items across every domain. To tackle this challenge, systems must efficiently balance inter and intra-domain knowledge transfer. In this work, we introduce a novel approach for scalable multi-domain recommendation systems by replacing full inter-domain attention with two innovative mechanisms: 1) Transition-Aware Positional Embeddings (TAPE): We propose novel positional embeddings that account for domain-transition specific information. This allows attention to be focused solely on intra-domain items, effectively reducing the unnecessary computational cost associated with attending to irrelevant domains. 2) Dynamic Domain State Representation (DDSR): We introduce a dynamic state representation for each domain, which is stored and accessed during subsequent token predictions. This enables the efficient transfer of relevant domain information without relying on full attention maps. Our method offers a scalable solution to the challenges posed by large-scale, multi-domain recommendation systems and demonstrates significant improvements in retrieval tasks by separately modelling and combining inter- and intra-domain representations.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2508.20587": {
            "title": "SemSR: Semantics aware robust Session-based Recommendations",
            "authors": "Jyoti Narwariya, Priyanka Gupta, Muskan Gupta, Jyotsana Khatri, Lovekesh Vig",
            "first_author": "Jyoti Narwariya",
            "url": "http://arxiv.org/abs/2508.20587v1",
            "pdf_url": "http://arxiv.org/abs/2508.20587",
            "publish_date": "2025-08-28",
            "abstract": "Session-based recommendation (SR) models aim to recommend items to anonymous users based on their behavior during the current session. While various SR models in the literature utilize item sequences to predict the next item, they often fail to leverage semantic information from item titles or descriptions impeding session intent identification and interpretability. Recent research has explored Large Language Models (LLMs) as promising approaches to enhance session-based recommendations, with both prompt-based and fine-tuning based methods being widely investigated. However, prompt-based methods struggle to identify optimal prompts that elicit correct reasoning and lack task-specific feedback at test time, resulting in sub-optimal recommendations. Fine-tuning methods incorporate domain-specific knowledge but incur significant computational costs for implementation and maintenance. In this paper, we present multiple approaches to utilize LLMs for session-based recommendation: (i) in-context LLMs as recommendation agents, (ii) LLM-generated representations for semantic initialization of deep learning SR models, and (iii) integration of LLMs with data-driven SR models. Through comprehensive experiments on two real-world publicly available datasets, we demonstrate that LLM-based methods excel at coarse-level retrieval (high recall values), while traditional data-driven techniques perform well at fine-grained ranking (high Mean Reciprocal Rank values). Furthermore, the integration of LLMs with data-driven SR models significantly out performs both standalone LLM approaches and data-driven deep learning models, as well as baseline SR models, in terms of both Recall and MRR metrics.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2508.20427": {
            "title": "Rethinking Purity and Diversity in Multi-Behavior Sequential Recommendation from the Frequency Perspective",
            "authors": "Yongqiang Han, Kai Cheng, Kefan Wang, Enhong Chen",
            "first_author": "Yongqiang Han",
            "url": "http://arxiv.org/abs/2508.20427v1",
            "pdf_url": "http://arxiv.org/abs/2508.20427",
            "publish_date": "2025-08-28",
            "abstract": "In recommendation systems, users often exhibit multiple behaviors, such as browsing, clicking, and purchasing. Multi-behavior sequential recommendation (MBSR) aims to consider these different behaviors in an integrated manner to improve the recommendation performance of the target behavior. However, some behavior data will also bring inevitable noise to the modeling of user interests. Some research efforts focus on data denoising from the frequency domain perspective to improve the accuracy of user preference prediction. These studies indicate that low-frequency information tends to be valuable and reliable, while high-frequency information is often associated with noise. In this paper, we argue that high-frequency information is by no means insignificant. Further experimental results highlight that low frequency corresponds to the purity of user interests, while high frequency corresponds to the diversity of user interests. Building upon this finding, we proposed our model PDB4Rec, which efficiently extracts information across various frequency bands and their relationships, and introduces Boostrapping Balancer mechanism to balance their contributions for improved recommendation performance. Sufficient experiments on real-world datasets demonstrate the effectiveness and efficiency of our model.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2508.20399": {
            "title": "A Case Study of Balanced Query Recommendation on Wikipedia",
            "authors": "Harshit Mishra, Sucheta Soundarajan",
            "first_author": "Harshit Mishra",
            "url": "http://arxiv.org/abs/2508.20399v1",
            "pdf_url": "http://arxiv.org/abs/2508.20399",
            "publish_date": "2025-08-28",
            "abstract": "Modern IR systems are an extremely important tool for seeking information. In addition to search, such systems include a number of query reformulation methods, such as query expansion and query recommendations, to provide high quality results. However, results returned by such methods sometimes exhibit undesirable or wrongful bias with respect to protected categories such as gender or race. Our earlier work considered the problem of balanced query recommendation, where instead of re-ranking a list of results based on fairness measures, the goal was to suggest queries that are relevant to a user's search query but exhibit less bias than the original query. In this work, we present a case study of BalancedQR using an extension of BalancedQR that handles biases in multiple dimensions. It employs a Pareto front approach that finds balanced queries, optimizing for multiple objectives such as gender bias and regional bias, along with the relevance of returned results. We evaluate the extended version of BalancedQR on a Wikipedia dataset.Our results demonstrate the effectiveness of our extension to BalancedQR framework and highlight the significant impact of subtle query wording,linguistic choice on retrieval.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2508.20359": {
            "title": "Progressive Semantic Residual Quantization for Multimodal-Joint Interest Modeling in Music Recommendation",
            "authors": "Shijia Wang, Tianpei Ouyang, Qiang Xiao, Dongjing Wang, Yintao Ren, Songpei Xu, Da Guo, Chuanjiang Luo",
            "first_author": "Shijia Wang",
            "url": "http://arxiv.org/abs/2508.20359v1",
            "pdf_url": "http://arxiv.org/abs/2508.20359",
            "publish_date": "2025-08-28",
            "abstract": "In music recommendation systems, multimodal interest learning is pivotal, which allows the model to capture nuanced preferences, including textual elements such as lyrics and various musical attributes such as different instruments and melodies. Recently, methods that incorporate multimodal content features through semantic IDs have achieved promising results. However, existing methods suffer from two critical limitations: 1) intra-modal semantic degradation, where residual-based quantization processes gradually decouple discrete IDs from original content semantics, leading to semantic drift; and 2) inter-modal modeling gaps, where traditional fusion strategies either overlook modal-specific details or fail to capture cross-modal correlations, hindering comprehensive user interest modeling. To address these challenges, we propose a novel multimodal recommendation framework with two stages. In the first stage, our Progressive Semantic Residual Quantization (PSRQ) method generates modal-specific and modal-joint semantic IDs by explicitly preserving the prefix semantic feature. In the second stage, to model multimodal interest of users, a Multi-Codebook Cross-Attention (MCCA) network is designed to enable the model to simultaneously capture modal-specific interests and perceive cross-modal correlations. Extensive experiments on multiple real-world datasets demonstrate that our framework outperforms state-of-the-art baselines. This framework has been deployed on one of China's largest music streaming platforms, and online A/B tests confirm significant improvements in commercial metrics, underscoring its practical value for industrial-scale recommendation systems.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2508.20328": {
            "title": "Multi-View Graph Convolution Network for Internal Talent Recommendation Based on Enterprise Emails",
            "authors": "Soo Hyun Kim, Jang-Hyun Kim",
            "first_author": "Soo Hyun Kim",
            "url": "http://arxiv.org/abs/2508.20328v1",
            "pdf_url": "http://arxiv.org/abs/2508.20328",
            "publish_date": "2025-08-28",
            "abstract": "Internal talent recommendation is a critical strategy for organizational continuity, yet conventional approaches suffer from structural limitations, often overlooking qualified candidates by relying on the narrow perspective of a few managers. To address this challenge, we propose a novel framework that models two distinct dimensions of an employee's position fit from email data: WHAT they do (semantic similarity of tasks) and HOW they work (structural characteristics of their interactions and collaborations). These dimensions are represented as independent graphs and adaptively fused using a Dual Graph Convolutional Network (GCN) with a gating mechanism. Experiments show that our proposed gating-based fusion model significantly outperforms other fusion strategies and a heuristic baseline, achieving a top performance of 40.9% on Hit@100. Importantly, it is worth noting that the model demonstrates high interpretability by learning distinct, context-aware fusion strategies for different job families. For example, it learned to prioritize relational (HOW) data for 'sales and marketing' job families while applying a balanced approach for 'research' job families. This research offers a quantitative and comprehensive framework for internal talent discovery, minimizing the risk of candidate omission inherent in traditional methods. Its primary contribution lies in its ability to empirically determine the optimal fusion ratio between task alignment (WHAT) and collaborative patterns (HOW), which is required for employees to succeed in the new positions, thereby offering important practical implications.",
            "primary_category": "cs.LG",
            "code_url": "null"
        },
        "2508.20312": {
            "title": "ELIXIR: Efficient and LIghtweight model for eXplaIning Recommendations",
            "authors": "Ben Kabongo, Vincent Guigue, Pirmin Lemberger",
            "first_author": "Ben Kabongo",
            "url": "http://arxiv.org/abs/2508.20312v2",
            "pdf_url": "http://arxiv.org/abs/2508.20312",
            "publish_date": "2025-08-27",
            "abstract": "Collaborative filtering drives many successful recommender systems but struggles with fine-grained user-item interactions and explainability. As users increasingly seek transparent recommendations, generating textual explanations through language models has become a critical research area. Existing methods employ either RNNs or Transformers. However, RNN-based approaches fail to leverage the capabilities of pre-trained Transformer models, whereas Transformer-based methods often suffer from suboptimal adaptation and neglect aspect modeling, which is crucial for personalized explanations. We propose ELIXIR (Efficient and LIghtweight model for eXplaIning Recommendations), a multi-task model combining rating prediction with personalized review generation. ELIXIR jointly learns global and aspect-specific representations of users and items, optimizing overall rating, aspect-level ratings, and review generation, with personalized attention to emphasize aspect importance. Based on a T5-small (60M) model, we demonstrate the effectiveness of our aspect-based architecture in guiding text generation in a personalized context, where state-of-the-art approaches exploit much larger models but fail to match user preferences as well. Experimental results on TripAdvisor and RateBeer demonstrate that ELIXIR significantly outperforms strong baseline models, especially in review generation.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2508.20024": {
            "title": "Using item recommendations and LLMs in marketing email titles",
            "authors": "Deddy Jobson, Muktti Shukla, Phuong Dinh, Julio Christian Young, Nick Pittoni, Nina Chen, Ryan Ginstrom",
            "first_author": "Deddy Jobson",
            "url": "http://arxiv.org/abs/2508.20024v3",
            "pdf_url": "http://arxiv.org/abs/2508.20024",
            "publish_date": "2025-08-27",
            "abstract": "E-commerce marketplaces make use of a number of marketing channels like emails, push notifications, etc. to reach their users and stimulate purchases. Personalized emails especially are a popular touch point for marketers to inform users of latest items in stock, especially for those who stopped visiting the marketplace. Such emails contain personalized recommendations tailored to each user's interests, enticing users to buy relevant items. A common limitation of these emails is that the primary entry point, the title of the email, tends to follow fixed templates, failing to inspire enough interest in the contents. In this work, we explore the potential of large language models (LLMs) for generating thematic titles that reflect the personalized content of the emails. We perform offline simulations and conduct online experiments on the order of millions of users, finding our techniques useful in improving the engagement between customers and our emails. We highlight key findings and learnings as we productionize the safe and automated generation of email titles for millions of users.",
            "primary_category": "cs.LG",
            "code_url": "null"
        },
        "2508.19918": {
            "title": "Refining Text Generation for Realistic Conversational Recommendation via Direct Preference Optimization",
            "authors": "Manato Tajiri, Michimasa Inaba",
            "first_author": "Manato Tajiri",
            "url": "http://arxiv.org/abs/2508.19918v3",
            "pdf_url": "http://arxiv.org/abs/2508.19918",
            "publish_date": "2025-08-27",
            "abstract": "Conversational Recommender Systems (CRSs) aim to elicit user preferences via natural dialogue to provide suitable item recommendations. However, current CRSs often deviate from realistic human interactions by rapidly recommending items in brief sessions. This work addresses this gap by leveraging Large Language Models (LLMs) to generate dialogue summaries from dialogue history and item recommendation information from item description. This approach enables the extraction of both explicit user statements and implicit preferences inferred from the dialogue context. We introduce a method using Direct Preference Optimization (DPO) to ensure dialogue summary and item recommendation information are rich in information crucial for effective recommendations. Experiments on two public datasets validate our method's effectiveness in fostering more natural and realistic conversational recommendation processes. Our implementation is publicly available at: https://github.com/UEC-InabaLab/Refining-LLM-Text",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2508.19591": {
            "title": "A Model-agnostic Strategy to Mitigate Embedding Degradation in Personalized Federated Recommendation",
            "authors": "Jiakui Shen, Yunqi Mi, Guoshuai Zhao, Jialie Shen, Xueming Qian",
            "first_author": "Jiakui Shen",
            "url": "http://arxiv.org/abs/2508.19591v1",
            "pdf_url": "http://arxiv.org/abs/2508.19591",
            "publish_date": "2025-08-27",
            "abstract": "Centralized recommender systems encounter privacy leakage due to the need to collect user behavior and other private data. Hence, federated recommender systems (FedRec) have become a promising approach with an aggregated global model on the server. However, this distributed training paradigm suffers from embedding degradation caused by suboptimal personalization and dimensional collapse, due to the existence of sparse interactions and heterogeneous preferences. To this end, we propose a novel model-agnostic strategy for FedRec to strengthen the personalized embedding utility, which is called Personalized Local-Global Collaboration (PLGC). It is the first research in federated recommendation to alleviate the dimensional collapse issue. Particularly, we incorporate the frozen global item embedding table into local devices. Based on a Neural Tangent Kernel strategy that dynamically balances local and global information, PLGC optimizes personalized representations during forward inference, ultimately converging to user-specific preferences. Additionally, PLGC carries on a contrastive objective function to reduce embedding redundancy by dissolving dependencies between dimensions, thereby improving the backward representation learning process. We introduce PLGC as a model-agnostic personalized training strategy for federated recommendations that can be applied to existing baselines to alleviate embedding degradation. Extensive experiments on five real-world datasets have demonstrated the effectiveness and adaptability of PLGC, which outperforms various baseline algorithms.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2508.19569": {
            "title": "Skill-based Explanations for Serendipitous Course Recommendation",
            "authors": "Hung Chau, Run Yu, Zachary Pardos, Peter Brusilovsky",
            "first_author": "Hung Chau",
            "url": "http://arxiv.org/abs/2508.19569v1",
            "pdf_url": "http://arxiv.org/abs/2508.19569",
            "publish_date": "2025-08-27",
            "abstract": "Academic choice is crucial in U.S. undergraduate education, allowing students significant freedom in course selection. However, navigating the complex academic environment is challenging due to limited information, guidance, and an overwhelming number of choices, compounded by time restrictions and the high demand for popular courses. Although career counselors exist, their numbers are insufficient, and course recommendation systems, though personalized, often lack insight into student perceptions and explanations to assess course relevance. In this paper, a deep learning-based concept extraction model is developed to efficiently extract relevant concepts from course descriptions to improve the recommendation process. Using this model, the study examines the effects of skill-based explanations within a serendipitous recommendation framework, tested through the AskOski system at the University of California, Berkeley. The findings indicate that these explanations not only increase user interest, particularly in courses with high unexpectedness, but also bolster decision-making confidence. This underscores the importance of integrating skill-related data and explanations into educational recommendation systems.",
            "primary_category": "cs.AI",
            "code_url": "null"
        },
        "2508.19547": {
            "title": "Improving Recommendation Fairness via Graph Structure and Representation Augmentation",
            "authors": "Tongxin Xu, Wenqiang Liu, Chenzhong Bin, Cihan Xiao, Zhixin Zeng, Tianlong Gu",
            "first_author": "Tongxin Xu",
            "url": "http://arxiv.org/abs/2508.19547v1",
            "pdf_url": "http://arxiv.org/abs/2508.19547",
            "publish_date": "2025-08-27",
            "abstract": "Graph Convolutional Networks (GCNs) have become increasingly popular in recommendation systems. However, recent studies have shown that GCN-based models will cause sensitive information to disseminate widely in the graph structure, amplifying data bias and raising fairness concerns. While various fairness methods have been proposed, most of them neglect the impact of biased data on representation learning, which results in limited fairness improvement. Moreover, some studies have focused on constructing fair and balanced data distributions through data augmentation, but these methods significantly reduce utility due to disruption of user preferences. In this paper, we aim to design a fair recommendation method from the perspective of data augmentation to improve fairness while preserving recommendation utility. To achieve fairness-aware data augmentation with minimal disruption to user preferences, we propose two prior hypotheses. The first hypothesis identifies sensitive interactions by comparing outcomes of performance-oriented and fairness-aware recommendations, while the second one focuses on detecting sensitive features by analyzing feature similarities between biased and debiased representations. Then, we propose a dual data augmentation framework for fair recommendation, which includes two data augmentation strategies to generate fair augmented graphs and feature representations. Furthermore, we introduce a debiasing learning method that minimizes the dependence between the learned representations and sensitive information to eliminate bias. Extensive experiments on two real-world datasets demonstrate the superiority of our proposed framework.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2508.19539": {
            "title": "A Hybrid Recommendation Framework for Enhancing User Engagement in Local News",
            "authors": "Payam Pourashraf, Bamshad Mobasher",
            "first_author": "Payam Pourashraf",
            "url": "http://arxiv.org/abs/2508.19539v1",
            "pdf_url": "http://arxiv.org/abs/2508.19539",
            "publish_date": "2025-08-27",
            "abstract": "Local news organizations face an urgent need to boost reader engagement amid declining circulation and competition from global media. Personalized news recommender systems offer a promising solution by tailoring content to user interests. Yet, conventional approaches often emphasize general preferences and may overlook nuanced or eclectic interests in local news.   We propose a hybrid news recommender that integrates local and global preference models to improve engagement. Building on evidence of the value of localized models, our method unifies local and non-local predictors in one framework. The system adaptively combines recommendations from a local model, specialized in region-specific content, and a global model that captures broader preferences. Ensemble strategies and multiphase training balance the two.   We evaluated the model on two datasets: a synthetic set based on Syracuse newspaper distributions and a Danish dataset (EB-NeRD) labeled for local and non-local content with an LLM. Results show our integrated approach outperforms single-model baselines in accuracy and coverage, suggesting improved personalization that can drive user engagement.   The findings have practical implications for publishers, especially local outlets. By leveraging both community-specific and general user interests, the hybrid recommender can deliver more relevant content, increasing retention and subscriptions. In sum, this work introduces a new direction for recommender systems, bridging local and global models to revitalize local news consumption through scalable, personalized user experiences.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2508.19507": {
            "title": "A Self-Supervised Mixture-of-Experts Framework for Multi-behavior Recommendation",
            "authors": "Kyungho Kim, Sunwoo Kim, Geon Lee, Kijung Shin",
            "first_author": "Kyungho Kim",
            "url": "http://arxiv.org/abs/2508.19507v2",
            "pdf_url": "http://arxiv.org/abs/2508.19507",
            "publish_date": "2025-08-27",
            "abstract": "In e-commerce, where users face a vast array of possible item choices, recommender systems are vital for helping them discover suitable items they might otherwise overlook. While many recommender systems primarily rely on a user's purchase history, recent multi-behavior recommender systems incorporate various auxiliary user behaviors, such as item clicks and cart additions, to enhance recommendations. Despite their overall performance gains, their effectiveness varies considerably between visited items (i.e., those a user has interacted with through auxiliary behaviors) and unvisited items (i.e., those with which the user has had no such interactions). Specifically, our analysis reveals that (1) existing multi-behavior recommender systems exhibit a significant gap in recommendation quality between the two item types (visited and unvisited items) and (2) achieving strong performance on both types with a single model architecture remains challenging. To tackle these issues, we propose a novel multi-behavior recommender system, MEMBER. It employs a mixture-of-experts framework, with experts designed to recommend the two item types, respectively. Each expert is trained using a self-supervised method specialized for its design goal. In our comprehensive experiments, we show the effectiveness of MEMBER across both item types, achieving up to 65.46% performance gain over the best competitor in terms of Hit Ratio@20.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2508.19489": {
            "title": "Interactive Graph Visualization and TeamingRecommendation in an Interdisciplinary Project'sTalent Knowledge Graph",
            "authors": "Jiawei Xu, Juichien Chen, Yilin Ye, Zhandos Sembay, Swathi Thaker, Pamela Payne-Foster, Jake Chen, Ying Ding",
            "first_author": "Jiawei Xu",
            "url": "http://arxiv.org/abs/2508.19489v1",
            "pdf_url": "http://arxiv.org/abs/2508.19489",
            "publish_date": "2025-08-27",
            "abstract": "Interactive visualization of large scholarly knowledge graphs combined with LLM reasoning shows promise butremains under-explored. We address this gap by developing an interactive visualization system for the Cell Map forAI Talent Knowledge Graph (28,000 experts and 1,179 biomedical datasets). Our approach integrates WebGLvisualization with LLM agents to overcome limitations of traditional tools such as Gephi, particularly for large-scaleinteractive node handling. Key functionalities include responsive exploration, filtering, and AI-drivenrecommendations with justifications. This integration can potentially enable users to effectively identify potentialcollaborators and relevant dataset users within biomedical and AI research communities. The system contributes anovel framework that enhances knowledge graph exploration through intuitive visualization and transparent, LLM-guided recommendations. This adaptable solution extends beyond the CM4AI community to other large knowledgegraphs, improving information representation and decision-making. Demo: https://cm4aikg.vercel.app/",
            "primary_category": "cs.DL",
            "code_url": "null"
        },
        "2508.18892": {
            "title": "Recommendations for Best Practices for Data Preservation and Open Science in HEP",
            "authors": "Simone Campana, Irakli Chakaberia, Gang Chen, Cristinel Diaconu, Caterina Doglioni, Dillon S. Fitzgerald, Vincent Garonne, Anne Gentil-Beccot, Fleur Heiniger, Michael D. Hildreth, Julie M. Hogan, Hao Hu, Eric Lancon, Clemens Lange, Kati Lassila-Perini, Olivia Mandica-Hart, Zach Marshall, Thomas McCauley, Harvey Newman, Mihoko Nojiri, Ianna Osborne, Fazhi Qi, Salom\u00e9 Rohr, Stefan Roiser, Thomas Sch\u00f6rner, Ulrich Schwickerath, Elizabeth Sexton-Kennedy, Seema Sharma, Tibor \u0160imko, Michael Sparks, Graeme Andrew Stewart, Nicola Tarocco, Giacomo Tenaglia, Gustavo Valdiviesso, Antonia Winkler, Christoph Wissing",
            "first_author": "Simone Campana",
            "url": "http://arxiv.org/abs/2508.18892v1",
            "pdf_url": "http://arxiv.org/abs/2508.18892",
            "publish_date": "2025-08-26",
            "abstract": "These recommendations are the result of reflections by scientists and experts who are, or have been, involved in the preservation of high-energy physics data. The work has been done under the umbrella of the Data Lifecycle panel of the International Committee of Future Accelerators (ICFA), drawing on the expertise of a wide range of stakeholders.   A key indicator of success in the data preservation efforts is the long-term usability of the data. Experience shows that achieving this requires providing a rich set of information in various forms, which can only be effectively collected and preserved during the period of active data use.   The recommendations are intended to be actionable by the indicated actors and specific to the particle physics domain. They cover a wide range of actions, many of which are interdependent. These dependencies are indicated within the recommendations and can be used as a road map to guide implementation efforts.   These recommendations are best accessed and viewed through the web application, see https://icfa-data-best-practices.app.cern.ch/",
            "primary_category": "hep-ex",
            "code_url": "null"
        },
        "2508.18841": {
            "title": "Recycling History: Efficient Recommendations from Contextual Dueling Bandits",
            "authors": "Suryanarayana Sankagiri, Jalal Etesami, Pouria Fatemi, Matthias Grossglauser",
            "first_author": "Suryanarayana Sankagiri",
            "url": "http://arxiv.org/abs/2508.18841v1",
            "pdf_url": "http://arxiv.org/abs/2508.18841",
            "publish_date": "2025-08-26",
            "abstract": "The contextual duelling bandit problem models adaptive recommender systems, where the algorithm presents a set of items to the user, and the user's choice reveals their preference. This setup is well suited for implicit choices users make when navigating a content platform, but does not capture other possible comparison queries. Motivated by the fact that users provide more reliable feedback after consuming items, we propose a new bandit model that can be described as follows. The algorithm recommends one item per time step; after consuming that item, the user is asked to compare it with another item chosen from the user's consumption history. Importantly, in our model, this comparison item can be chosen without incurring any additional regret, potentially leading to better performance. However, the regret analysis is challenging because of the temporal dependency in the user's history. To overcome this challenge, we first show that the algorithm can construct informative queries provided the history is rich, i.e., satisfies a certain diversity condition. We then show that a short initial random exploration phase is sufficient for the algorithm to accumulate a rich history with high probability. This result, proven via matrix concentration bounds, yields $O(\\sqrt{T})$ regret guarantees. Additionally, our simulations show that reusing past items for comparisons can lead to significantly lower regret than only comparing between simultaneously recommended items.",
            "primary_category": "cs.LG",
            "code_url": "null"
        },
        "2508.18700": {
            "title": "Taming the One-Epoch Phenomenon in Online Recommendation System by Two-stage Contrastive ID Pre-training",
            "authors": "Yi-Ping Hsu, Po-Wei Wang, Chantat Eksombatchai, Jiajing Xu",
            "first_author": "Yi-Ping Hsu",
            "url": "http://arxiv.org/abs/2508.18700v1",
            "pdf_url": "http://arxiv.org/abs/2508.18700",
            "publish_date": "2025-08-26",
            "abstract": "ID-based embeddings are widely used in web-scale online recommendation systems. However, their susceptibility to overfitting, particularly due to the long-tail nature of data distributions, often limits training to a single epoch, a phenomenon known as the \"one-epoch problem.\" This challenge has driven research efforts to optimize performance within the first epoch by enhancing convergence speed or feature sparsity. In this study, we introduce a novel two-stage training strategy that incorporates a pre-training phase using a minimal model with contrastive loss, enabling broader data coverage for the embedding system. Our offline experiments demonstrate that multi-epoch training during the pre-training phase does not lead to overfitting, and the resulting embeddings improve online generalization when fine-tuned for more complex downstream recommendation tasks. We deployed the proposed system in live traffic at Pinterest, achieving significant site-wide engagement gains.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2508.18442": {
            "title": "DenseRec: Revisiting Dense Content Embeddings for Sequential Transformer-based Recommendation",
            "authors": "Jan Malte Lichtenberg, Antonio De Candia, Matteo Ruffini",
            "first_author": "Jan Malte Lichtenberg",
            "url": "http://arxiv.org/abs/2508.18442v1",
            "pdf_url": "http://arxiv.org/abs/2508.18442",
            "publish_date": "2025-08-25",
            "abstract": "Transformer-based sequential recommenders, such as SASRec or BERT4Rec, typically rely solely on learned item ID embeddings, making them vulnerable to the item cold-start problem, particularly in environments with dynamic item catalogs. While dense content embeddings from pre-trained models offer potential solutions, direct integration into transformer-based recommenders has consistently underperformed compared to ID-only approaches. We revisit this integration challenge and propose DenseRec, a simple yet effective method that introduces a dual-path embedding approach. DenseRec learns a linear projection from the dense embedding space into the ID embedding space during training, enabling seamless generalization to previously unseen items without requiring specialized embedding models or complex infrastructure. In experiments on three real-world datasets, we find DenseRec to consistently outperform an ID-only SASRec baseline, even without additional hyperparameter tuning and while using compact embedding models. Our analysis suggests improvements primarily arise from better sequence representations in the presence of unseen items, positioning DenseRec as a practical and robust solution for cold-start sequential recommendation.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2508.18166": {
            "title": "PCR-CA: Parallel Codebook Representations with Contrastive Alignment for Multiple-Category App Recommendation",
            "authors": "Bin Tan, Wangyao Ge, Yidi Wang, Xin Liu, Jeff Burtoft, Hao Fan, Hui Wang",
            "first_author": "Bin Tan",
            "url": "http://arxiv.org/abs/2508.18166v4",
            "pdf_url": "http://arxiv.org/abs/2508.18166",
            "publish_date": "2025-08-25",
            "abstract": "Modern app store recommender systems struggle with multiple-category apps, as traditional taxonomies fail to capture overlapping semantics, leading to suboptimal personalization. We propose PCR-CA (Parallel Codebook Representations with Contrastive Alignment), an end-to-end framework for improved CTR prediction. PCR-CA first extracts compact multimodal embeddings from app text, then introduces a Parallel Codebook VQ-AE module that learns discrete semantic representations across multiple codebooks in parallel -- unlike hierarchical residual quantization (RQ-VAE). This design enables independent encoding of diverse aspects (e.g., gameplay, art style), better modeling multiple-category semantics. To bridge semantic and collaborative signals, we employ a contrastive alignment loss at both the user and item levels, enhancing representation learning for long-tail items. Additionally, a dual-attention fusion mechanism combines ID-based and semantic features to capture user interests, especially for long-tail apps. Experiments on a large-scale dataset show PCR-CA achieves a +0.76% AUC improvement over strong baselines, with +2.15% AUC gains for long-tail apps. Online A/B testing further validates our approach, showing a +10.52% lift in CTR and a +16.30% improvement in CVR, demonstrating PCR-CA's effectiveness in real-world deployment. The new framework has now been fully deployed on the Microsoft Store.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2508.18142": {
            "title": "Mirroring Users: Towards Building Preference-aligned User Simulator with User Feedback in Recommendation",
            "authors": "Tianjun Wei, Huizhong Guo, Yingpeng Du, Zhu Sun, Chen Huang, Dongxia Wang, Jie Zhang",
            "first_author": "Tianjun Wei",
            "url": "http://arxiv.org/abs/2508.18142v1",
            "pdf_url": "http://arxiv.org/abs/2508.18142",
            "publish_date": "2025-08-25",
            "abstract": "User simulation is increasingly vital to develop and evaluate recommender systems (RSs). While Large Language Models (LLMs) offer promising avenues to simulate user behavior, they often struggle with the absence of specific domain alignment required for RSs and the efficiency demands of large-scale simulation. A vast yet underutilized resource for enhancing this alignment is the extensive user feedback inherent in RSs. However, directly leveraging such feedback presents two significant challenges. First, user feedback in RSs is often ambiguous and noisy, which negatively impacts effective preference alignment. Second, the massive volume of feedback largely hinders the efficiency of preference alignment, necessitating an efficient filtering mechanism to identify more informative samples. To overcome these hurdles, we introduce a novel data construction framework that leverages user feedback in RSs with advanced LLM capabilities to generate high-quality simulation data. Our framework unfolds in two key phases: (1) employing LLMs to generate cognitive decision-making processes on constructed simulation samples, reducing ambiguity in raw user feedback; (2) data distillation based on uncertainty estimation and behavior sampling to filter challenging yet denoised simulation samples. Accordingly, we fine-tune lightweight LLMs, as user simulators, using such high-quality dataset with corresponding decision-making processes. Extensive experiments verify that our framework significantly boosts the alignment with human preferences and in-domain reasoning capabilities of fine-tuned LLMs, and provides more insightful and interpretable signals when interacting with RSs. We believe our work will advance the RS community and offer valuable insights for broader human-centric AI research.",
            "primary_category": "cs.HC",
            "code_url": "null"
        },
        "2508.18132": {
            "title": "Test-Time Scaling Strategies for Generative Retrieval in Multimodal Conversational Recommendations",
            "authors": "Hung-Chun Hsu, Yuan-Ching Kuo, Chao-Han Huck Yang, Szu-Wei Fu, Hanrong Ye, Hongxu Yin, Yu-Chiang Frank Wang, Ming-Feng Tsai, Chuan-Ju Wang",
            "first_author": "Hung-Chun Hsu",
            "url": "http://arxiv.org/abs/2508.18132v1",
            "pdf_url": "http://arxiv.org/abs/2508.18132",
            "publish_date": "2025-08-25",
            "abstract": "The rapid evolution of e-commerce has exposed the limitations of traditional product retrieval systems in managing complex, multi-turn user interactions. Recent advances in multimodal generative retrieval -- particularly those leveraging multimodal large language models (MLLMs) as retrievers -- have shown promise. However, most existing methods are tailored to single-turn scenarios and struggle to model the evolving intent and iterative nature of multi-turn dialogues when applied naively. Concurrently, test-time scaling has emerged as a powerful paradigm for improving large language model (LLM) performance through iterative inference-time refinement. Yet, its effectiveness typically relies on two conditions: (1) a well-defined problem space (e.g., mathematical reasoning), and (2) the model's ability to self-correct -- conditions that are rarely met in conversational product search. In this setting, user queries are often ambiguous and evolving, and MLLMs alone have difficulty grounding responses in a fixed product corpus. Motivated by these challenges, we propose a novel framework that introduces test-time scaling into conversational multimodal product retrieval. Our approach builds on a generative retriever, further augmented with a test-time reranking (TTR) mechanism that improves retrieval accuracy and better aligns results with evolving user intent throughout the dialogue. Experiments across multiple benchmarks show consistent improvements, with average gains of 14.5 points in MRR and 10.6 points in nDCG@1.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2508.17618": {
            "title": "Preference Trajectory Modeling via Flow Matching for Sequential Recommendation",
            "authors": "Li Li, Mingyue Cheng, Yuyang Ye, Zhiding Liu, Enhong Chen",
            "first_author": "Li Li",
            "url": "http://arxiv.org/abs/2508.17618v1",
            "pdf_url": "http://arxiv.org/abs/2508.17618",
            "publish_date": "2025-08-25",
            "abstract": "Sequential recommendation predicts each user's next item based on their historical interaction sequence. Recently, diffusion models have attracted significant attention in this area due to their strong ability to model user interest distributions. They typically generate target items by denoising Gaussian noise conditioned on historical interactions. However, these models face two critical limitations. First, they exhibit high sensitivity to the condition, making it difficult to recover target items from pure Gaussian noise. Second, the inference process is computationally expensive, limiting practical deployment. To address these issues, we propose FlowRec, a simple yet effective sequential recommendation framework which leverages flow matching to explicitly model user preference trajectories from current states to future interests. Flow matching is an emerging generative paradigm, which offers greater flexibility in initial distributions and enables more efficient sampling. Based on this, we construct a personalized behavior-based prior distribution to replace Gaussian noise and learn a vector field to model user preference trajectories. To better align flow matching with the recommendation objective, we further design a single-step alignment loss incorporating both positive and negative samples, improving sampling efficiency and generation quality. Extensive experiments on four benchmark datasets verify the superiority of FlowRec over the state-of-the-art baselines.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2508.17304": {
            "title": "An Efficient Recommendation Filtering-based Trust Model for Securing Internet of Things",
            "authors": "Muhammad Ibn Ziauddin, Rownak Rahad Rabbi, SM Mehrab, Fardin Faiyaz, Mosarrat Jahan",
            "first_author": "Muhammad Ibn Ziauddin",
            "url": "http://arxiv.org/abs/2508.17304v2",
            "pdf_url": "http://arxiv.org/abs/2508.17304",
            "publish_date": "2025-08-24",
            "abstract": "Trust computation is crucial for ensuring the security of the Internet of Things (IoT). However, current trust-based mechanisms for IoT have limitations that impact data security. Sliding window-based trust schemes cannot ensure reliable trust computation due to their inability to select appropriate window lengths. Besides, recent trust scores are emphasized when considering the effect of time on trust. This can cause a sudden change in overall trust score based on recent behavior, potentially misinterpreting an honest service provider as malicious and vice versa. Moreover, clustering mechanisms used to filter recommendations in trust computation often lead to slower results. In this paper, we propose a robust trust model to address these limitations. The proposed approach determines the window length dynamically to guarantee accurate trust computation. It uses the harmonic mean of average trust score and time to prevent sudden fluctuations in trust scores. Additionally, an efficient personalized subspace clustering algorithm is used to exclude recommendations. We present a security analysis demonstrating the resiliency of the proposed scheme against bad-mouthing, ballot-stuffing, and on-off attacks. The proposed scheme demonstrates a competitive performance in detecting bad-mouthing attacks, while outperforming existing works with an approximately 44% improvement in accuracy for detecting on-off attacks. It maintains its effectiveness even when the percentage of on-off attackers increases and in scenarios where multiple attacks occur simultaneously. Additionally, the proposed scheme reduces the recommendation filtering time by 95%.",
            "primary_category": "cs.CR",
            "code_url": "null"
        },
        "2508.16793": {
            "title": "Bootstrapping Conditional Retrieval for User-to-Item Recommendations",
            "authors": "Hongtao Lin, Haoyu Chen, Jaewon Jang, Jiajing Xu",
            "first_author": "Hongtao Lin",
            "url": "http://arxiv.org/abs/2508.16793v1",
            "pdf_url": "http://arxiv.org/abs/2508.16793",
            "publish_date": "2025-08-22",
            "abstract": "User-to-item retrieval has been an active research area in recommendation system, and two tower models are widely adopted due to model simplicity and serving efficiency. In this work, we focus on a variant called \\textit{conditional retrieval}, where we expect retrieved items to be relevant to a condition (e.g. topic). We propose a method that uses the same training data as standard two tower models but incorporates item-side information as conditions in query. This allows us to bootstrap new conditional retrieval use cases and encourages feature interactions between user and condition. Experiments show that our method can retrieve highly relevant items and outperforms standard two tower models with filters on engagement metrics. The proposed model is deployed to power a topic-based notification feed at Pinterest and led to +0.26\\% weekly active users.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2509.10468": {
            "title": "Learning Decomposed Contextual Token Representations from Pretrained and Collaborative Signals for Generative Recommendation",
            "authors": "Yifan Liu, Yaokun Liu, Zelin Li, Zhenrui Yue, Gyuseok Lee, Ruichen Yao, Yang Zhang, Dong Wang",
            "first_author": "Yifan Liu",
            "url": "http://arxiv.org/abs/2509.10468v1",
            "pdf_url": "http://arxiv.org/abs/2509.10468",
            "publish_date": "2025-08-22",
            "abstract": "Recent advances in generative recommenders adopt a two-stage paradigm: items are first tokenized into semantic IDs using a pretrained tokenizer, and then large language models (LLMs) are trained to generate the next item via sequence-to-sequence modeling. However, these two stages are optimized for different objectives: semantic reconstruction during tokenizer pretraining versus user interaction modeling during recommender training. This objective misalignment leads to two key limitations: (i) suboptimal static tokenization, where fixed token assignments fail to reflect diverse usage contexts; and (ii) discarded pretrained semantics, where pretrained knowledge - typically from language model embeddings - is overwritten during recommender training on user interactions. To address these limitations, we propose to learn DEcomposed COntextual Token Representations (DECOR), a unified framework that preserves pretrained semantics while enhancing the adaptability of token embeddings. DECOR introduces contextualized token composition to refine token embeddings based on user interaction context, and decomposed embedding fusion that integrates pretrained codebook embeddings with newly learned collaborative embeddings. Experiments on three real-world datasets demonstrate that DECOR consistently outperforms state-of-the-art baselines in recommendation performance. Our code will be made available upon publication.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2508.16269": {
            "title": "Representation Learning of Auxiliary Concepts for Improved Student Modeling and Exercise Recommendation",
            "authors": "Yahya Badran, Christine Preisach",
            "first_author": "Yahya Badran",
            "url": "http://arxiv.org/abs/2508.16269v1",
            "pdf_url": "http://arxiv.org/abs/2508.16269",
            "publish_date": "2025-08-22",
            "abstract": "Personalized recommendation is a key feature of intelligent tutoring systems, typically relying on accurate models of student knowledge. Knowledge Tracing (KT) models enable this by estimating a student's mastery based on their historical interactions. Many KT models rely on human-annotated knowledge concepts (KCs), which tag each exercise with one or more skills or concepts believed to be necessary for solving it. However, these KCs can be incomplete, error-prone, or overly general.   In this paper, we propose a deep learning model that learns sparse binary representations of exercises, where each bit indicates the presence or absence of a latent concept. We refer to these representations as auxiliary KCs. These representations capture conceptual structure beyond human-defined annotations and are compatible with both classical models (e.g., BKT) and modern deep learning KT architectures.   We demonstrate that incorporating auxiliary KCs improves both student modeling and adaptive exercise recommendation. For student modeling, we show that augmenting classical models like BKT with auxiliary KCs leads to improved predictive performance. For recommendation, we show that using auxiliary KCs enhances both reinforcement learning-based policies and a simple planning-based method (expectimax), resulting in measurable gains in student learning outcomes within a simulated student environment.",
            "primary_category": "cs.LG",
            "code_url": "null"
        },
        "2508.16210": {
            "title": "Modeling User Preferences as Distributions for Optimal Transport-based Cross-domain Recommendation under Non-overlapping Settings",
            "authors": "Ziyin Xiao, Toyotaro Suzumura",
            "first_author": "Ziyin Xiao",
            "url": "http://arxiv.org/abs/2508.16210v1",
            "pdf_url": "http://arxiv.org/abs/2508.16210",
            "publish_date": "2025-08-22",
            "abstract": "Cross-Domain Recommender (CDR) systems aim to transfer knowledge from dense to sparse domains, alleviating data sparsity and cold-start issues in single-domain recommendation. While many methods assume overlapping users or items to connect domains, this is often unrealistic in real-world settings. Thus, non-overlapping CDR systems, which require no shared users or items, are needed.   However, non-overlapping CDR is challenging due to: (1) the absence of overlap preventing direct bridges between domains, and (2) large distributional discrepancies degrading transfer performance. Moreover, most recommenders represent user preferences as discrete vectors, failing to capture their fine-grained, multi-faceted nature.   We propose DUP-OT (Distributional User Preferences with Optimal Transport), a framework for non-overlapping CDR. DUP-OT has three stages: (1) Shared Preprocessing, where review-based embeddings and an autoencoder encode users and items from both domains; (2) User GMM Weight Learning, which models user preferences as Gaussian mixtures with learned weights; and (3) Cross-domain Rating Prediction, where optimal transport aligns Gaussian components across domains, enabling preference transfer from source to target.   Experiments on Amazon review datasets show that DUP-OT effectively mitigates domain discrepancy and outperforms state-of-the-art baselines under the non-overlapping CDR setting.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2508.16170": {
            "title": "EGRA:Toward Enhanced Behavior Graphs and Representation Alignment for Multimodal Recommendation",
            "authors": "Xiaoxiong Zhang, Xin Zhou, Zhiwei Zeng, Yongjie Wang, Dusit Niyato, Zhiqi Shen",
            "first_author": "Xiaoxiong Zhang",
            "url": "http://arxiv.org/abs/2508.16170v1",
            "pdf_url": "http://arxiv.org/abs/2508.16170",
            "publish_date": "2025-08-22",
            "abstract": "MultiModal Recommendation (MMR) systems have emerged as a promising solution for improving recommendation quality by leveraging rich item-side modality information, prompting a surge of diverse methods. Despite these advances, existing methods still face two critical limitations. First, they use raw modality features to construct item-item links for enriching the behavior graph, while giving limited attention to balancing collaborative and modality-aware semantics or mitigating modality noise in the process. Second, they use a uniform alignment weight across all entities and also maintain a fixed alignment strength throughout training, limiting the effectiveness of modality-behavior alignment. To address these challenges, we propose EGRA. First, instead of relying on raw modality features, it alleviates sparsity by incorporating into the behavior graph an item-item graph built from representations generated by a pretrained MMR model. This enables the graph to capture both collaborative patterns and modality aware similarities with enhanced robustness against modality noise. Moreover, it introduces a novel bi-level dynamic alignment weighting mechanism to improve modality-behavior representation alignment, which dynamically assigns alignment strength across entities according to their alignment degree, while gradually increasing the overall alignment intensity throughout training. Extensive experiments on five datasets show that EGRA significantly outperforms recent methods, confirming its effectiveness.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2508.16126": {
            "title": "Spacetime-GR: A Spacetime-Aware Generative Model for Large Scale Online POI Recommendation",
            "authors": "Haitao Lin, Zhen Yang, Jiawei Xue, Ziji Zhang, Luzhu Wang, Yikun Gu, Yao Xu, Xin Li",
            "first_author": "Haitao Lin",
            "url": "http://arxiv.org/abs/2508.16126v1",
            "pdf_url": "http://arxiv.org/abs/2508.16126",
            "publish_date": "2025-08-22",
            "abstract": "Building upon the strong sequence modeling capability, Generative Recommendation (GR) has gradually assumed a dominant position in the application of recommendation tasks (e.g., video and product recommendation). However, the application of Generative Recommendation in Point-of-Interest (POI) recommendation, where user preferences are significantly affected by spatiotemporal variations, remains a challenging open problem. In this paper, we propose Spacetime-GR, the first spacetime-aware generative model for large-scale online POI recommendation. It extends the strong sequence modeling ability of generative models by incorporating flexible spatiotemporal information encoding. Specifically, we first introduce a geographic-aware hierarchical POI indexing strategy to address the challenge of large vocabulary modeling. Subsequently, a novel spatiotemporal encoding module is introduced to seamlessly incorporate spatiotemporal context into user action sequences, thereby enhancing the model's sensitivity to spatiotemporal variations. Furthermore, we incorporate multimodal POI embeddings to enrich the semantic understanding of each POI. Finally, to facilitate practical deployment, we develop a set of post-training adaptation strategies after sufficient pre-training on action sequences. These strategies enable Spacetime-GR to generate outputs in multiple formats (i.e., embeddings, ranking scores and POI candidates) and support a wide range of downstream application scenarios (i.e., ranking and end-to-end recommendation). We evaluate the proposed model on both public benchmark datasets and large-scale industrial datasets, demonstrating its superior performance over existing methods in terms of POI recommendation accuracy and ranking quality. Furthermore, the model is the first generative model deployed in online POI recommendation services that scale to hundreds of millions of POIs and users.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2508.15486": {
            "title": "LongRetriever: Towards Ultra-Long Sequence based Candidate Retrieval for Recommendation",
            "authors": "Qin Ren, Zheng Chai, Xijun Xiao, Yuchao Zheng, Di Wu",
            "first_author": "Qin Ren",
            "url": "http://arxiv.org/abs/2508.15486v2",
            "pdf_url": "http://arxiv.org/abs/2508.15486",
            "publish_date": "2025-08-21",
            "abstract": "Precisely modeling user ultra-long sequences is critical for industrial recommender systems. Current approaches predominantly focus on leveraging ultra-long sequences in the ranking stage, whereas research for the candidate retrieval stage remains under-explored. This paper presents LongRetriever, a practical framework for incorporating ultra-long sequences into the retrieval stage of recommenders. Specifically, we propose in-context training and multi-context retrieval, which enable candidate-specific interaction between user sequence and candidate item, and ensure training-serving consistency under the search-based paradigm. Extensive online A/B testing conducted on a large-scale e-commerce platform demonstrates statistically significant improvements, confirming the framework's effectiveness. Currently, LongRetriever has been fully deployed in the platform, impacting billions of users.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2508.15388": {
            "title": "TrackRec: Iterative Alternating Feedback with Chain-of-Thought via Preference Alignment for Recommendation",
            "authors": "Yu Xia, Rui Zhong, Zeyu Song, Wei Yang, Junchen Wan, Qingpeng Cai, Chi Lu, Peng Jiang",
            "first_author": "Yu Xia",
            "url": "http://arxiv.org/abs/2508.15388v1",
            "pdf_url": "http://arxiv.org/abs/2508.15388",
            "publish_date": "2025-08-21",
            "abstract": "The extensive world knowledge and powerful reasoning capabilities of large language models (LLMs) have attracted significant attention in recommendation systems (RS). Specifically, The chain of thought (CoT) has been shown to improve the performance of LLMs on complex reasoning tasks for RS. However, due to the fact that LLMs often suffer from hallucination issues, there is no guarantee that their reasoning CoT is effective. A key challenge is to further enhance the recommendation capabilities of LLMs through effective CoT reasonings. Therefore, we propose \\textbf{TrackRec}, a framework designed to enhance reasoning capabilities of LLMs for RS. TrackRec specifically focuses on accurately inferring recommendation CoT \\textbf{(RecCoT)} for user preference using the knowledge from LLMs. This RecCoT can serve both as an explanation for the LLM's completion of recommendation tasks and as auxiliary features to assist recommendation models in accomplishing recommendation tasks. TrackRec consists of a RecCoT generator $(G)$ and a RecCoT validator $(V)$. Furthermore, we design alternating feedback learning mechanism that $G$ undergoes direct preference optimization via feedback from $V$ to produce increasingly accurate RecCoT aligned with $V$'s standards. Meanwhile, $V$ is fine-tuned using the inference feedback from $G$ to enhance its validation capabilities in alignment with recommendation tasks. Through iterative alternating feedback learning between $G$ and $V$, TrackRec continuously improves the user preference analysis capability of $G$ and the validation capacity of $V$. Extensive experiments demonstrate the effectiveness of our approach, showing that it surpasses state-of-the-art methods. Moreover, TrackRec has been deployed on a lagre advertising platform with hundreds of millions of users, achieving substantial gains.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2508.15308": {
            "title": "REG4Rec: Reasoning-Enhanced Generative Model for Large-Scale Recommendation Systems",
            "authors": "Haibo Xing, Hao Deng, Yucheng Mao, Jinxin Hu, Yi Xu, Hao Zhang, Jiahao Wang, Shizhun Wang, Yu Zhang, Xiaoyi Zeng, Jing Zhang",
            "first_author": "Haibo Xing",
            "url": "http://arxiv.org/abs/2508.15308v2",
            "pdf_url": "http://arxiv.org/abs/2508.15308",
            "publish_date": "2025-08-21",
            "abstract": "Sequential recommendation aims to predict a user's next action in large-scale recommender systems. While traditional methods often suffer from insufficient information interaction, recent generative recommendation models partially address this issue by directly generating item predictions. To better capture user intents, recent studies have introduced a reasoning process into generative recommendation, significantly improving recommendation performance. However, these approaches are constrained by the singularity of item semantic representations, facing challenges such as limited diversity in reasoning pathways and insufficient reliability in the reasoning process. To tackle these issues, we introduce REG4Rec, a reasoning-enhanced generative model that constructs multiple dynamic semantic reasoning paths alongside a self-reflection process, ensuring high-confidence recommendations. Specifically, REG4Rec utilizes an MoE-based parallel quantization codebook (MPQ) to generate multiple unordered semantic tokens for each item, thereby constructing a larger-scale diverse reasoning space. Furthermore, to enhance the reliability of reasoning, we propose a training reasoning enhancement stage, which includes Preference Alignment for Reasoning (PARS) and a Multi-Step Reward Augmentation (MSRA) strategy. PARS uses reward functions tailored for recommendation to enhance reasoning and reflection, while MSRA introduces future multi-step actions to improve overall generalization. During inference, Consistency-Oriented Self-Reflection for Pruning (CORP) is proposed to discard inconsistent reasoning paths, preventing the propagation of erroneous reasoning. Lastly, we develop an efficient offline training strategy for large-scale recommendation. Experiments on real-world datasets and online evaluations show that REG4Rec delivers outstanding performance and substantial practical value.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2508.15263": {
            "title": "Curriculum Approximate Unlearning for Session-based Recommendation",
            "authors": "Liu Yang, Zhaochun Ren, Ziqi Zhao, Pengjie Ren, Zhumin Chen, Xinyi Li, Shuaiqiang Wang, Dawei Yin, Xin Xin",
            "first_author": "Liu Yang",
            "url": "http://arxiv.org/abs/2508.15263v1",
            "pdf_url": "http://arxiv.org/abs/2508.15263",
            "publish_date": "2025-08-21",
            "abstract": "Approximate unlearning for session-based recommendation refers to eliminating the influence of specific training samples from the recommender without retraining of (sub-)models. Gradient ascent (GA) is a representative method to conduct approximate unlearning. However, there still exist dual challenges to apply GA for session-based recommendation. On the one hand, naive applying of GA could lead to degradation of recommendation performance. On the other hand, existing studies fail to consider the ordering of unlearning samples when simultaneously processing multiple unlearning requests, leading to sub-optimal recommendation performance and unlearning effect. To address the above challenges, we introduce CAU, a curriculum approximate unlearning framework tailored to session-based recommendation. CAU handles the unlearning task with a GA term on unlearning samples. Specifically, to address the first challenge, CAU formulates the overall optimization task as a multi-objective optimization problem, where the GA term for unlearning samples is combined with retaining terms for preserving performance. The multi-objective optimization problem is solved through seeking the Pareto-Optimal solution, which achieves effective unlearning with trivial sacrifice on recommendation performance. To tackle the second challenge, CAU adopts a curriculum-based sequence to conduct unlearning on batches of unlearning samples. The key motivation is to perform unlearning from easy samples to harder ones. To this end, CAU first introduces two metrics to measure the unlearning difficulty, including gradient unlearning difficulty and embedding unlearning difficulty. Then, two strategies, hard-sampling and soft-sampling, are proposed to select unlearning samples according to difficulty scores.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2508.15262": {
            "title": "M-$LLM^3$REC: A Motivation-Aware User-Item Interaction Framework for Enhancing Recommendation Accuracy with LLMs",
            "authors": "Lining Chen, Qingwen Zeng, Huaming Chen",
            "first_author": "Lining Chen",
            "url": "http://arxiv.org/abs/2508.15262v1",
            "pdf_url": "http://arxiv.org/abs/2508.15262",
            "publish_date": "2025-08-21",
            "abstract": "Recommendation systems have been essential for both user experience and platform efficiency by alleviating information overload and supporting decision-making. Traditional methods, i.e., content-based filtering, collaborative filtering, and deep learning, have achieved impressive results in recommendation systems. However, the cold-start and sparse-data scenarios are still challenging to deal with. Existing solutions either generate pseudo-interaction sequence, which often introduces redundant or noisy signals, or rely heavily on semantic similarity, overlooking dynamic shifts in user motivation. To address these limitations, this paper proposes a novel recommendation framework, termed M-$LLM^3$REC, which leverages large language models for deep motivational signal extraction from limited user interactions. M-$LLM^3$REC comprises three integrated modules: the Motivation-Oriented Profile Extractor (MOPE), Motivation-Oriented Trait Encoder (MOTE), and Motivational Alignment Recommender (MAR). By emphasizing motivation-driven semantic modeling, M-$LLM^3$REC demonstrates robust, personalized, and generalizable recommendations, particularly boosting performance in cold-start situations in comparison with the state-of-the-art frameworks.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2508.15030": {
            "title": "Collab-REC: An LLM-based Agentic Framework for Balancing Recommendations in Tourism",
            "authors": "Ashmi Banerjee, Fitri Nur Aisyah, Adithi Satish, Wolfgang W\u00f6rndl, Yashar Deldjoo",
            "first_author": "Ashmi Banerjee",
            "url": "http://arxiv.org/abs/2508.15030v1",
            "pdf_url": "http://arxiv.org/abs/2508.15030",
            "publish_date": "2025-08-20",
            "abstract": "We propose Collab-REC, a multi-agent framework designed to counteract popularity bias and enhance diversity in tourism recommendations. In our setting, three LLM-based agents -- Personalization, Popularity, and Sustainability generate city suggestions from complementary perspectives. A non-LLM moderator then merges and refines these proposals via multi-round negotiation, ensuring each agent's viewpoint is incorporated while penalizing spurious or repeated responses. Experiments on European city queries show that Collab-REC improves diversity and overall relevance compared to a single-agent baseline, surfacing lesser-visited locales that often remain overlooked. This balanced, context-aware approach addresses over-tourism and better aligns with constraints provided by the user, highlighting the promise of multi-stakeholder collaboration in LLM-driven recommender systems.",
            "primary_category": "cs.AI",
            "code_url": "null"
        },
        "2508.14948": {
            "title": "Large Foundation Model for Ads Recommendation",
            "authors": "Shangyu Zhang, Shijie Quan, Zhongren Wang, Junwei Pan, Tianqu Zhuang, Bo Fu, Yilong Sun, Jieying Lin, Jushuo Chen, Xiaotian Li, Zhixiang Feng, Xian Hu, Huiting Deng, Hua Lu, Jinpeng Wang, Boqi Dai, Xiaoyu Chen, Bin Hu, Lili Huang, Yanwen Wu, Yeshou Cai, Qi Zhou, Huang Tang, Chunfeng Yang, Chengguo Yin, Tingyu Jiang, Lifeng Wang, Shudong Huang, Dapeng Liu, Lei Xiao, Haijie Gu, Shu-Tao Xia, Jie Jiang",
            "first_author": "Shangyu Zhang",
            "url": "http://arxiv.org/abs/2508.14948v1",
            "pdf_url": "http://arxiv.org/abs/2508.14948",
            "publish_date": "2025-08-20",
            "abstract": "Online advertising relies on accurate recommendation models, with recent advances using pre-trained large-scale foundation models (LFMs) to capture users' general interests across multiple scenarios and tasks. However, existing methods have critical limitations: they extract and transfer only user representations (URs), ignoring valuable item representations (IRs) and user-item cross representations (CRs); and they simply use a UR as a feature in downstream applications, which fails to bridge upstream-downstream gaps and overlooks more transfer granularities. In this paper, we propose LFM4Ads, an All-Representation Multi-Granularity transfer framework for ads recommendation. It first comprehensively transfers URs, IRs, and CRs, i.e., all available representations in the pre-trained foundation model. To effectively utilize the CRs, it identifies the optimal extraction layer and aggregates them into transferable coarse-grained forms. Furthermore, we enhance the transferability via multi-granularity mechanisms: non-linear adapters for feature-level transfer, an Isomorphic Interaction Module for module-level transfer, and Standalone Retrieval for model-level transfer. LFM4Ads has been successfully deployed in Tencent's industrial-scale advertising platform, processing tens of billions of daily samples while maintaining terabyte-scale model parameters with billions of sparse embedding keys across approximately two thousand features. Since its production deployment in Q4 2024, LFM4Ads has achieved 10+ successful production launches across various advertising scenarios, including primary ones like Weixin Moments and Channels. These launches achieve an overall GMV lift of 2.45% across the entire platform, translating to estimated annual revenue increases in the hundreds of millions of dollars.",
            "primary_category": "cs.LG",
            "code_url": "null"
        },
        "2509.08829": {
            "title": "PerFairX: Is There a Balance Between Fairness and Personality in Large Language Model Recommendations?",
            "authors": "Chandan Kumar Sah",
            "first_author": "Chandan Kumar Sah",
            "url": "http://arxiv.org/abs/2509.08829v1",
            "pdf_url": "http://arxiv.org/abs/2509.08829",
            "publish_date": "2025-08-20",
            "abstract": "The integration of Large Language Models (LLMs) into recommender systems has enabled zero-shot, personality-based personalization through prompt-based interactions, offering a new paradigm for user-centric recommendations. However, incorporating user personality traits via the OCEAN model highlights a critical tension between achieving psychological alignment and ensuring demographic fairness. To address this, we propose PerFairX, a unified evaluation framework designed to quantify the trade-offs between personalization and demographic equity in LLM-generated recommendations. Using neutral and personality-sensitive prompts across diverse user profiles, we benchmark two state-of-the-art LLMs, ChatGPT and DeepSeek, on movie (MovieLens 10M) and music (Last.fm 360K) datasets. Our results reveal that personality-aware prompting significantly improves alignment with individual traits but can exacerbate fairness disparities across demographic groups. Specifically, DeepSeek achieves stronger psychological fit but exhibits higher sensitivity to prompt variations, while ChatGPT delivers stable yet less personalized outputs. PerFairX provides a principled benchmark to guide the development of LLM-based recommender systems that are both equitable and psychologically informed, contributing to the creation of inclusive, user-centric AI applications in continual learning contexts.",
            "primary_category": "cs.CY",
            "code_url": "null"
        },
        "2508.14515": {
            "title": "MISS: Multi-Modal Tree Indexing and Searching with Lifelong Sequential Behavior for Retrieval Recommendation",
            "authors": "Chengcheng Guo, Junda She, Kuo Cai, Shiyao Wang, Qigen Hu, Qiang Luo, Kun Gai, Guorui Zhou",
            "first_author": "Chengcheng Guo",
            "url": "http://arxiv.org/abs/2508.14515v1",
            "pdf_url": "http://arxiv.org/abs/2508.14515",
            "publish_date": "2025-08-20",
            "abstract": "Large-scale industrial recommendation systems typically employ a two-stage paradigm of retrieval and ranking to handle huge amounts of information. Recent research focuses on improving the performance of retrieval model. A promising way is to introduce extensive information about users and items. On one hand, lifelong sequential behavior is valuable. Existing lifelong behavior modeling methods in ranking stage focus on the interaction of lifelong behavior and candidate items from retrieval stage. In retrieval stage, it is difficult to utilize lifelong behavior because of a large corpus of candidate items. On the other hand, existing retrieval methods mostly relay on interaction information, potentially disregarding valuable multi-modal information. To solve these problems, we represent the pioneering exploration of leveraging multi-modal information and lifelong sequence model within the advanced tree-based retrieval model. We propose Multi-modal Indexing and Searching with lifelong Sequence (MISS), which contains a multi-modal index tree and a multi-modal lifelong sequence modeling module. Specifically, for better index structure, we propose multi-modal index tree, which is built using the multi-modal embedding to precisely represent item similarity. To precisely capture diverse user interests in user lifelong sequence, we propose collaborative general search unit (Co-GSU) and multi-modal general search unit (MM-GSU) for multi-perspective interests searching.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2508.13981": {
            "title": "Multi-User Contextual Cascading Bandits for Personalized Recommendation",
            "authors": "Jiho Park, Huiwen Jia",
            "first_author": "Jiho Park",
            "url": "http://arxiv.org/abs/2508.13981v2",
            "pdf_url": "http://arxiv.org/abs/2508.13981",
            "publish_date": "2025-08-19",
            "abstract": "We introduce a Multi-User Contextual Cascading Bandit model, a new combinatorial bandit framework that captures realistic online advertising scenarios where multiple users interact with sequentially displayed items simultaneously. Unlike classical contextual bandits, MCCB integrates three key structural elements: (i) cascading feedback based on sequential arm exposure, (ii) parallel context sessions enabling selective exploration, and (iii) heterogeneous arm-level rewards. We first propose Upper Confidence Bound with Backward Planning (UCBBP), a UCB-style algorithm tailored to this setting, and prove that it achieves a regret bound of $\\widetilde{O}(\\sqrt{THN})$ over $T$ episodes, $H$ session steps, and $N$ contexts per episode. Motivated by the fact that many users interact with the system simultaneously, we introduce a second algorithm, termed Active Upper Confidence Bound with Backward Planning (AUCBBP), which shows a strict efficiency improvement in context scaling, i.e., user scaling, with a regret bound of $\\widetilde{O}(\\sqrt{T+HN})$. We validate our theoretical findings via numerical experiments, demonstrating the empirical effectiveness of both algorithms under various settings.",
            "primary_category": "cs.LG",
            "code_url": "null"
        },
        "2508.13889": {
            "title": "CARE: Contextual Adaptation of Recommenders for LLM-based Conversational Recommendation",
            "authors": "Chuang Li, Yang Deng, Hengchang Hu, See-Kiong Ng, Min-Yen Kan, Haizhou Li",
            "first_author": "Chuang Li",
            "url": "http://arxiv.org/abs/2508.13889v1",
            "pdf_url": "http://arxiv.org/abs/2508.13889",
            "publish_date": "2025-08-19",
            "abstract": "We tackle the challenge of integrating large language models (LLMs) with external recommender systems to enhance domain expertise in conversational recommendation (CRS). Current LLM-based CRS approaches primarily rely on zero- or few-shot methods for generating item recommendations based on user queries, but this method faces two significant challenges: (1) without domain-specific adaptation, LLMs frequently recommend items not in the target item space, resulting in low recommendation accuracy; and (2) LLMs largely rely on dialogue context for content-based recommendations, neglecting the collaborative relationships among entities or item sequences. To address these limitations, we introduce the CARE (Contextual Adaptation of Recommenders) framework. CARE customizes LLMs for CRS tasks, and synergizes them with external recommendation systems. CARE (a) integrates external recommender systems as domain experts, producing recommendations through entity-level insights, and (b) enhances those recommendations by leveraging contextual information for more accurate and unbiased final recommendations using LLMs. Our results demonstrate that incorporating external recommender systems with entity-level information significantly enhances recommendation accuracy of LLM-based CRS by an average of 54% and 25% for ReDial and INSPIRED datasets. The most effective strategy in the CARE framework involves LLMs selecting and reranking candidate items that external recommenders provide based on contextual insights. Our analysis indicates that the CARE framework effectively addresses the identified challenges and mitigates the popularity bias in the external recommender.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2508.13870": {
            "title": "Bites of Tomorrow: Personalized Recommendations for a Healthier and Greener Plate",
            "authors": "Jiazheng Jing, Yinan Zhang, Chunyan Miao",
            "first_author": "Jiazheng Jing",
            "url": "http://arxiv.org/abs/2508.13870v1",
            "pdf_url": "http://arxiv.org/abs/2508.13870",
            "publish_date": "2025-08-19",
            "abstract": "The recent emergence of extreme climate events has significantly raised awareness about sustainable living. In addition to developing energy-saving materials and technologies, existing research mainly relies on traditional methods that encourage behavioral shifts towards sustainability, which can be overly demanding or only passively engaging. In this work, we propose to employ recommendation systems to actively nudge users toward more sustainable choices. We introduce Green Recommender Aligned with Personalized Eating (GRAPE), which is designed to prioritize and recommend sustainable food options that align with users' evolving preferences. We also design two innovative Green Loss functions that cater to green indicators with either uniform or differentiated priorities, thereby enhancing adaptability across a range of scenarios. Extensive experiments on a real-world dataset demonstrate the effectiveness of our GRAPE.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2508.13745": {
            "title": "Refining Contrastive Learning and Homography Relations for Multi-Modal Recommendation",
            "authors": "Shouxing Ma, Yawen Zeng, Shiqing Wu, Guandong Xu",
            "first_author": "Shouxing Ma",
            "url": "http://arxiv.org/abs/2508.13745v1",
            "pdf_url": "http://arxiv.org/abs/2508.13745",
            "publish_date": "2025-08-19",
            "abstract": "Multi-modal recommender system focuses on utilizing rich modal information ( i.e., images and textual descriptions) of items to improve recommendation performance. The current methods have achieved remarkable success with the powerful structure modeling capability of graph neural networks. However, these methods are often hindered by sparse data in real-world scenarios. Although contrastive learning and homography ( i.e., homogeneous graphs) are employed to address the data sparsity challenge, existing methods still suffer two main limitations: 1) Simple multi-modal feature contrasts fail to produce effective representations, causing noisy modal-shared features and loss of valuable information in modal-unique features; 2) The lack of exploration of the homograph relations between user interests and item co-occurrence results in incomplete mining of user-item interplay.   To address the above limitations, we propose a novel framework for \\textbf{R}\\textbf{E}fining multi-mod\\textbf{A}l cont\\textbf{R}astive learning and ho\\textbf{M}ography relations (\\textbf{REARM}). Specifically, we complement multi-modal contrastive learning by employing meta-network and orthogonal constraint strategies, which filter out noise in modal-shared features and retain recommendation-relevant information in modal-unique features. To mine homogeneous relationships effectively, we integrate a newly constructed user interest graph and an item co-occurrence graph with the existing user co-occurrence and item semantic graphs for graph learning. The extensive experiments on three real-world datasets demonstrate the superiority of REARM to various state-of-the-art baselines. Our visualization further shows an improvement made by REARM in distinguishing between modal-shared and modal-unique features. Code is available \\href{https://github.com/MrShouxingMa/REARM}{here}.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2508.13670": {
            "title": "MUFFIN: Mixture of User-Adaptive Frequency Filtering for Sequential Recommendation",
            "authors": "Ilwoong Baek, Mincheol Yoon, Seongmin Park, Jongwuk Lee",
            "first_author": "Ilwoong Baek",
            "url": "http://arxiv.org/abs/2508.13670v1",
            "pdf_url": "http://arxiv.org/abs/2508.13670",
            "publish_date": "2025-08-19",
            "abstract": "Sequential recommendation (SR) aims to predict users' subsequent interactions by modeling their sequential behaviors. Recent studies have explored frequency domain analysis, which effectively models periodic patterns in user sequences. However, existing frequency-domain SR models still face two major drawbacks: (i) limited frequency band coverage, often missing critical behavioral patterns in a specific frequency range, and (ii) lack of personalized frequency filtering, as they apply an identical filter for all users regardless of their distinct frequency characteristics. To address these challenges, we propose a novel frequency-domain model, Mixture of User-adaptive Frequency FIlteriNg (MUFFIN), operating through two complementary modules. (i) The global filtering module (GFM) handles the entire frequency spectrum to capture comprehensive behavioral patterns. (ii) The local filtering module (LFM) selectively emphasizes important frequency bands without excluding information from other ranges. (iii) In both modules, the user-adaptive filter (UAF) is adopted to generate user-specific frequency filters tailored to individual unique characteristics. Finally, by aggregating both modules, MUFFIN captures diverse user behavioral patterns across the full frequency spectrum. Extensive experiments show that MUFFIN consistently outperforms state-of-the-art frequency-domain SR models over five benchmark datasets. The source code is available at https://github.com/ilwoong100/MUFFIN.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2508.13568": {
            "title": "Understanding Distribution Structure on Calibrated Recommendation Systems",
            "authors": "Diego Correa da Silva, Denis Robson Dantas Boaventura, Mayki dos Santos Oliveira, Eduardo Ferreira da Silva, Joel Machado Pires, Frederico Ara\u00fajo Dur\u00e3o",
            "first_author": "Diego Correa da Silva",
            "url": "http://arxiv.org/abs/2508.13568v1",
            "pdf_url": "http://arxiv.org/abs/2508.13568",
            "publish_date": "2025-08-19",
            "abstract": "Traditional recommender systems aim to generate a recommendation list comprising the most relevant or similar items to the user's profile. These approaches can create recommendation lists that omit item genres from the less prominent areas of a user's profile, thereby undermining the user's experience. To solve this problem, the calibrated recommendation system provides a guarantee of including less representative areas in the recommended list. The calibrated context works with three distributions. The first is from the user's profile, the second is from the candidate items, and the last is from the recommendation list. These distributions are G-dimensional, where G is the total number of genres in the system. This high dimensionality requires a different evaluation method, considering that traditional recommenders operate in a one-dimensional data space. In this sense, we implement fifteen models that help to understand how these distributions are structured. We evaluate the users' patterns in three datasets from the movie domain. The results indicate that the models of outlier detection provide a better understanding of the structures. The calibrated system creates recommendation lists that act similarly to traditional recommendation lists, allowing users to change their groups of preferences to the same degree.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2508.13517": {
            "title": "Heterogeneous Influence Maximization in User Recommendation",
            "authors": "Hongru Hou, Jiachen Sun, Wenqing Lin, Wendong Bi, Xiangrong Wang, Deqing Yang",
            "first_author": "Hongru Hou",
            "url": "http://arxiv.org/abs/2508.13517v1",
            "pdf_url": "http://arxiv.org/abs/2508.13517",
            "publish_date": "2025-08-19",
            "abstract": "User recommendation systems enhance user engagement by encouraging users to act as inviters to interact with other users (invitees), potentially fostering information propagation. Conventional recommendation methods typically focus on modeling interaction willingness. Influence-Maximization (IM) methods focus on identifying a set of users to maximize the information propagation. However, existing methods face two significant challenges. First, recommendation methods fail to unleash the candidates' spread capability. Second, IM methods fail to account for the willingness to interact. To solve these issues, we propose two models named HeteroIR and HeteroIM. HeteroIR provides an intuitive solution to unleash the dissemination potential of user recommendation systems. HeteroIM fills the gap between the IM method and the recommendation task, improving interaction willingness and maximizing spread coverage. The HeteroIR introduces a two-stage framework to estimate the spread profits. The HeteroIM incrementally selects the most influential invitee to recommend and rerank based on the number of reverse reachable (RR) sets containing inviters and invitees. RR set denotes a set of nodes that can reach a target via propagation. Extensive experiments show that HeteroIR and HeteroIM significantly outperform the state-of-the-art baselines with the p-value < 0.05. Furthermore, we have deployed HeteroIR and HeteroIM in Tencent's online gaming platforms and gained an 8.5\\% and 10\\% improvement in the online A/B test, respectively. Implementation codes are available at https://github.com/socialalgo/HIM.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2508.13500": {
            "title": "LLM-Enhanced Linear Autoencoders for Recommendation",
            "authors": "Jaewan Moon, Seongmin Park, Jongwuk Lee",
            "first_author": "Jaewan Moon",
            "url": "http://arxiv.org/abs/2508.13500v2",
            "pdf_url": "http://arxiv.org/abs/2508.13500",
            "publish_date": "2025-08-19",
            "abstract": "Large language models (LLMs) have been widely adopted to enrich the semantic representation of textual item information in recommender systems. However, existing linear autoencoders (LAEs) that incorporate textual information rely on sparse word co-occurrence patterns, limiting their ability to capture rich textual semantics. To address this, we propose L3AE, the first integration of LLMs into the LAE framework. L3AE effectively integrates the heterogeneous knowledge of textual semantics and user-item interactions through a two-phase optimization strategy. (i) L3AE first constructs a semantic item-to-item correlation matrix from LLM-derived item representations. (ii) It then learns an item-to-item weight matrix from collaborative signals while distilling semantic item correlations as regularization. Notably, each phase of L3AE is optimized through closed-form solutions, ensuring global optimality and computational efficiency. Extensive experiments demonstrate that L3AE consistently outperforms state-of-the-art LLM-enhanced models on three benchmark datasets, achieving gains of 27.6% in Recall@20 and 39.3% in NDCG@20. The source code is available at https://github.com/jaewan7599/L3AE_CIKM2025.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2508.13473": {
            "title": "Reactive Users vs. Recommendation Systems: An Adaptive Policy to Manage Opinion Drifts",
            "authors": "Atefeh Mollabagher, Parinaz Naghizadeh",
            "first_author": "Atefeh Mollabagher",
            "url": "http://arxiv.org/abs/2508.13473v1",
            "pdf_url": "http://arxiv.org/abs/2508.13473",
            "publish_date": "2025-08-19",
            "abstract": "Recommendation systems are used in a range of platforms to maximize user engagement through personalization and the promotion of popular content. It has been found that such recommendations may shape users' opinions over time. In this paper, we ask whether reactive users, who are cognizant of the influence of the content they consume, can prevent such changes by adaptively adjusting their content consumption choices. To this end, we study users' opinion dynamics under two types of stochastic policies: a passive policy where the probability of clicking on recommended content is fixed and a reactive policy where clicking probability adaptively decreases following large opinion drifts. We analytically derive the expected opinion and user utility under these policies. We show that the adaptive policy can help users prevent opinion drifts and that when a user prioritizes opinion preservation, the expected utility of the adaptive policy outperforms the fixed policy. We validate our theoretical findings through numerical simulations. These findings help better understand how user-level strategies can challenge the biases induced by recommendation systems.",
            "primary_category": "cs.GT",
            "code_url": "null"
        },
        "2508.13423": {
            "title": "AdaptJobRec: Enhancing Conversational Career Recommendation through an LLM-Powered Agentic System",
            "authors": "Qixin Wang, Dawei Wang, Kun Chen, Yaowei Hu, Puneet Girdhar, Ruoteng Wang, Aadesh Gupta, Chaitanya Devella, Wenlai Guo, Shangwen Huang, Bachir Aoun, Greg Hayworth, Han Li, Xintao Wu",
            "first_author": "Qixin Wang",
            "url": "http://arxiv.org/abs/2508.13423v1",
            "pdf_url": "http://arxiv.org/abs/2508.13423",
            "publish_date": "2025-08-19",
            "abstract": "In recent years, recommendation systems have evolved from providing a single list of recommendations to offering a comprehensive suite of topic focused services. To better accomplish this task, conversational recommendation systems (CRS) have progressed from basic retrieval augmented LLM generation to agentic systems with advanced reasoning and self correction capabilities. However, agentic systems come with notable response latency, a longstanding challenge for conversational recommendation systems. To balance the trade off between handling complex queries and minimizing latency, we propose AdaptJobRec, the first conversational job recommendation system that leverages autonomous agent to integrate personalized recommendation algorithm tools. The system employs a user query complexity identification mechanism to minimize response latency. For straightforward queries, the agent directly selects the appropriate tool for rapid responses. For complex queries, the agent uses the memory processing module to filter chat history for relevant content, then passes the results to the intelligent task decomposition planner, and finally executes the tasks using personalized recommendation tools. Evaluation on Walmart's real world career recommendation scenarios demonstrates that AdaptJobRec reduces average response latency by up to 53.3% compared to competitive baselines, while significantly improving recommendation accuracy.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2508.13404": {
            "title": "TASER: Table Agents for Schema-guided Extraction and Recommendation",
            "authors": "Nicole Cho, Kirsty Fielding, William Watson, Sumitra Ganesh, Manuela Veloso",
            "first_author": "Nicole Cho",
            "url": "http://arxiv.org/abs/2508.13404v2",
            "pdf_url": "http://arxiv.org/abs/2508.13404",
            "publish_date": "2025-08-18",
            "abstract": "Real-world financial documents report essential information about an entity's financial holdings that can span millions of different financial instrument types. Yet, these details are often buried in messy, multi-page, fragmented tables - for example, 99.4% of the tables in our dataset have no bounding boxes with the maximum number of rows amounting to 426 per table across 44 pages. To tackle these unique challenges from real-world tables, we present a continuously learning, agentic table extraction system, TASER (Table Agents for Schema-guided Extraction and Recommendation) that extracts highly unstructured, multi-page, heterogeneous tables into normalized, schema-conforming outputs. Our table agents execute on table detection, classification, extraction, and recommendations by leveraging an initial schema. Then, our Recommender Agent reviews the outputs, recommends schema revisions, and decides on the final recommendations, enabling TASER to outperform existing table detection models such as Table Transformer by 10.1%. Within this continuous learning process, we highlight that larger batch sizes result in a 104.3% increase in schema recommendations that are actionable and utilized, resulting in a 9.8% increase in extracted holdings - highlighting the importance of a continuous learning process. To train TASER, we have manually labeled 22,584 pages (28,150,449 tokens), 3,213 tables for $731,685,511,687 of holdings culminating in one of the first real financial table datasets. We release our dataset TASERTab to enable the research community to access real-world financial tables and outputs. Our results highlight the promise of agentic, schema-guided extraction systems for robust understanding of real-world financial tables.",
            "primary_category": "cs.AI",
            "code_url": "null"
        },
        "2508.13064": {
            "title": "Is This News Still Interesting to You?: Lifetime-aware Interest Matching for News Recommendation",
            "authors": "Seongeun Ryu, Yunyong Ko, Sang-Wook Kim",
            "first_author": "Seongeun Ryu",
            "url": "http://arxiv.org/abs/2508.13064v1",
            "pdf_url": "http://arxiv.org/abs/2508.13064",
            "publish_date": "2025-08-18",
            "abstract": "Personalized news recommendation aims to deliver news articles aligned with users' interests, serving as a key solution to alleviate the problem of information overload on online news platforms. While prior work has improved interest matching through refined representations of news and users, the following time-related challenges remain underexplored: (C1) leveraging the age of clicked news to infer users' interest persistence, and (C2) modeling the varying lifetime of news across topics and users. To jointly address these challenges, we propose a novel Lifetime-aware Interest Matching framework for nEws recommendation, named LIME, which incorporates three key strategies: (1) User-Topic lifetime-aware age representation to capture the relative age of news with respect to a user-topic pair, (2) Candidate-aware lifetime attention for generating temporally aligned user representation, and (3) Freshness-guided interest refinement for prioritizing valid candidate news at prediction time. Extensive experiments on two real-world datasets demonstrate that LIME consistently outperforms a wide range of state-of-the-art news recommendation methods, and its model agnostic strategies significantly improve recommendation accuracy.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2508.13019": {
            "title": "Informfully Recommenders -- Reproducibility Framework for Diversity-aware Intra-session Recommendations",
            "authors": "Lucien Heitz, Runze Li, Oana Inel, Abraham Bernstein",
            "first_author": "Lucien Heitz",
            "url": "http://arxiv.org/abs/2508.13019v1",
            "pdf_url": "http://arxiv.org/abs/2508.13019",
            "publish_date": "2025-08-18",
            "abstract": "Norm-aware recommender systems have gained increased attention, especially for diversity optimization. The recommender systems community has well-established experimentation pipelines that support reproducible evaluations by facilitating models' benchmarking and comparisons against state-of-the-art methods. However, to the best of our knowledge, there is currently no reproducibility framework to support thorough norm-driven experimentation at the pre-processing, in-processing, post-processing, and evaluation stages of the recommender pipeline. To address this gap, we present Informfully Recommenders, a first step towards a normative reproducibility framework that focuses on diversity-aware design built on Cornac. Our extension provides an end-to-end solution for implementing and experimenting with normative and general-purpose diverse recommender systems that cover 1) dataset pre-processing, 2) diversity-optimized models, 3) dedicated intrasession item re-ranking, and 4) an extensive set of diversity metrics. We demonstrate the capabilities of our extension through an extensive offline experiment in the news domain.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2508.12706": {
            "title": "Asymmetric Diffusion Recommendation Model",
            "authors": "Yongchun Zhu, Guanyu Jiang, Jingwu Chen, Feng Zhang, Xiao Yang, Zuotao Liu",
            "first_author": "Yongchun Zhu",
            "url": "http://arxiv.org/abs/2508.12706v1",
            "pdf_url": "http://arxiv.org/abs/2508.12706",
            "publish_date": "2025-08-18",
            "abstract": "Recently, motivated by the outstanding achievements of diffusion models, the diffusion process has been employed to strengthen representation learning in recommendation systems. Most diffusion-based recommendation models typically utilize standard Gaussian noise in symmetric forward and reverse processes in continuous data space. Nevertheless, the samples derived from recommendation systems inhabit a discrete data space, which is fundamentally different from the continuous one. Moreover, Gaussian noise has the potential to corrupt personalized information within latent representations. In this work, we propose a novel and effective method, named Asymmetric Diffusion Recommendation Model (AsymDiffRec), which learns forward and reverse processes in an asymmetric manner. We define a generalized forward process that simulates the missing features in real-world recommendation samples. The reverse process is then performed in an asymmetric latent feature space. To preserve personalized information within the latent representation, a task-oriented optimization strategy is introduced. In the serving stage, the raw sample with missing features is regarded as a noisy input to generate a denoising and robust representation for the final prediction. By equipping base models with AsymDiffRec, we conduct online A/B tests, achieving improvements of +0.131% and +0.166% in terms of users' active days and app usage duration respectively. Additionally, the extended offline experiments also demonstrate improvements. AsymDiffRec has been implemented in the Douyin Music App.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2508.12651": {
            "title": "The Maximum Coverage Model and Recommendation System for UAV Vertiports Location Planning",
            "authors": "Chunliang Hua, Xiao Hu, Jiayang Sun, Zeyuan Yang",
            "first_author": "Chunliang Hua",
            "url": "http://arxiv.org/abs/2508.12651v1",
            "pdf_url": "http://arxiv.org/abs/2508.12651",
            "publish_date": "2025-08-18",
            "abstract": "As urban aerial mobility (UAM) infrastructure development accelerates globally, cities like Shenzhen are planning large-scale vertiport networks (e.g., 1,200+ facilities by 2026). Existing planning frameworks remain inadequate for this complexity due to historical limitations in data granularity and real-world applicability. This paper addresses these gaps by first proposing the Capacitated Dynamic Maximum Covering Location Problem (CDMCLP), a novel optimization framework that simultaneously models urban-scale spatial-temporal demand, heterogeneous user behaviors, and infrastructure capacity constraints. Building on this foundation, we introduce an Integrated Planning Recommendation System that combines CDMCLP with socio-economic factors and dynamic clustering initialization. This system leverages adaptive parameter tuning based on empirical user behavior to generate practical planning solutions. Validation in a Chinese center city demonstrates the effectiveness of the new optimization framework and recommendation system. Under the evaluation and optimization of CDMCLP, the quantitative performance of traditional location methods are exposed and can be improved by 38\\%--52\\%, while the recommendation system shows user-friendliness and the effective integration of complex elements. By integrating mathematical rigor with practical implementation considerations, this hybrid approach bridges the gap between theoretical location modeling and real-world UAM infrastructure planning, offering municipalities a pragmatic tool for vertiport network design.",
            "primary_category": "cs.AI",
            "code_url": "null"
        },
        "2508.12645": {
            "title": "Diagnostic-Guided Dynamic Profile Optimization for LLM-based User Simulators in Sequential Recommendation",
            "authors": "Hongyang Liu, Zhu Sun, Tianjun Wei, Yan Wang, Jiajie Zhu, Xinghua Qu",
            "first_author": "Hongyang Liu",
            "url": "http://arxiv.org/abs/2508.12645v3",
            "pdf_url": "http://arxiv.org/abs/2508.12645",
            "publish_date": "2025-08-18",
            "abstract": "Recent advances in large language models (LLMs) have enabled realistic user simulators for developing and evaluating recommender systems (RSs). However, existing LLM-based simulators for RSs face two major limitations: (1) static and single-step prompt-based inference that leads to inaccurate and incomplete user profile construction; (2) unrealistic and single-round recommendation-feedback interaction pattern that fails to capture real-world scenarios. To address these limitations, we propose DGDPO (Diagnostic-Guided Dynamic Profile Optimization), a novel framework that constructs user profile through a dynamic and iterative optimization process to enhance the simulation fidelity. Specifically, DGDPO incorporates two core modules within each optimization loop: firstly, a specialized LLM-based diagnostic module, calibrated through our novel training strategy, accurately identifies specific defects in the user profile. Subsequently, a generalized LLM-based treatment module analyzes the diagnosed defect and generates targeted suggestions to refine the profile. Furthermore, unlike existing LLM-based user simulators that are limited to single-round interactions, we are the first to integrate DGDPO with sequential recommenders, enabling a bidirectional evolution where user profiles and recommendation strategies adapt to each other over multi-round interactions. Extensive experiments conducted on three real-world datasets demonstrate the effectiveness of our proposed framework.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2509.21777": {
            "title": "SynerGen: Contextualized Generative Recommender for Unified Search and Recommendation",
            "authors": "Vianne R. Gao, Chen Xue, Marc Versage, Xie Zhou, Zhongruo Wang, Chao Li, Yeon Seonwoo, Nan Chen, Zhen Ge, Gourab Kundu, Weiqi Zhang, Tian Wang, Qingjun Cui, Trishul Chilimbi",
            "first_author": "Vianne R. Gao",
            "url": "http://arxiv.org/abs/2509.21777v1",
            "pdf_url": "http://arxiv.org/abs/2509.21777",
            "publish_date": "2025-09-26",
            "abstract": "The dominant retrieve-then-rank pipeline in large-scale recommender systems suffers from mis-calibration and engineering overhead due to its architectural split and differing optimization objectives. While recent generative sequence models have shown promise in unifying retrieval and ranking by auto-regressively generating ranked items, existing solutions typically address either personalized search or query-free recommendation, often exhibiting performance trade-offs when attempting to unify both. We introduce \\textit{SynerGen}, a novel generative recommender model that bridges this critical gap by providing a single generative backbone for both personalized search and recommendation, while simultaneously excelling at retrieval and ranking tasks. Trained on behavioral sequences, our decoder-only Transformer leverages joint optimization with InfoNCE for retrieval and a hybrid pointwise-pairwise loss for ranking, allowing semantic signals from search to improve recommendation and vice versa. We also propose a novel time-aware rotary positional embedding to effectively incorporate time information into the attention mechanism. \\textit{SynerGen} achieves significant improvements on widely adopted recommendation and search benchmarks compared to strong generative recommender and joint search and recommendation baselines. This work demonstrates the viability of a single generative foundation model for industrial-scale unified information access.",
            "primary_category": "cs.CL",
            "code_url": "null"
        },
        "2509.24424": {
            "title": "Multi-Item-Query Attention for Stable Sequential Recommendation",
            "authors": "Mingshi Xu, Haoren Zhu, Wilfred Siu Hung Ng",
            "first_author": "Mingshi Xu",
            "url": "http://arxiv.org/abs/2509.24424v1",
            "pdf_url": "http://arxiv.org/abs/2509.24424",
            "publish_date": "2025-09-29",
            "abstract": "The inherent instability and noise in user interaction data challenge sequential recommendation systems. Prevailing masked attention models, relying on a single query from the most recent item, are sensitive to this noise, reducing prediction reliability. We propose the Multi-Item-Query attention mechanism (MIQ-Attn) to enhance model stability and accuracy. MIQ-Attn constructs multiple diverse query vectors from user interactions, effectively mitigating noise and improving consistency. It is designed for easy adoption as a drop-in replacement for existing single-query attention. Experiments show MIQ-Attn significantly improves performance on benchmark datasets.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2509.23649": {
            "title": "From Past To Path: Masked History Learning for Next-Item Prediction in Generative Recommendation",
            "authors": "KaiWen Wei, Kejun He, Xiaomian Kang, Jie Zhang, Yuming Yang, Jiang Zhong, He Bai, Junnan Zhu",
            "first_author": "KaiWen Wei",
            "url": "http://arxiv.org/abs/2509.23649v1",
            "pdf_url": "http://arxiv.org/abs/2509.23649",
            "publish_date": "2025-09-28",
            "abstract": "Generative recommendation, which directly generates item identifiers, has emerged as a promising paradigm for recommendation systems. However, its potential is fundamentally constrained by the reliance on purely autoregressive training. This approach focuses solely on predicting the next item while ignoring the rich internal structure of a user's interaction history, thus failing to grasp the underlying intent. To address this limitation, we propose Masked History Learning (MHL), a novel training framework that shifts the objective from simple next-step prediction to deep comprehension of history. MHL augments the standard autoregressive objective with an auxiliary task of reconstructing masked historical items, compelling the model to understand ``why'' an item path is formed from the user's past behaviors, rather than just ``what'' item comes next. We introduce two key contributions to enhance this framework: (1) an entropy-guided masking policy that intelligently targets the most informative historical items for reconstruction, and (2) a curriculum learning scheduler that progressively transitions from history reconstruction to future prediction. Experiments on three public datasets show that our method significantly outperforms state-of-the-art generative models, highlighting that a comprehensive understanding of the past is crucial for accurately predicting a user's future path. The code will be released to the public.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2509.23560": {
            "title": "A Hierarchical Structure-Enhanced Personalized Recommendation Model for Traditional Chinese Medicine Formulas Based on KG Diffusion Guidance",
            "authors": "ChaoBo Zhang, Long Tan",
            "first_author": "ChaoBo Zhang",
            "url": "http://arxiv.org/abs/2509.23560v1",
            "pdf_url": "http://arxiv.org/abs/2509.23560",
            "publish_date": "2025-09-28",
            "abstract": "Artificial intelligence technology plays a crucial role in recommending prescriptions for traditional Chinese medicine (TCM). Previous studies have made significant progress by focusing on the symptom-herb relationship in prescriptions. However, several limitations hinder model performance: (i) Insufficient attention to patient-personalized information such as age, BMI, and medical history, which hampers accurate identification of syndrome and reduces efficacy. (ii) The typical long-tailed distribution of herb data introduces training biases and affects generalization ability. (iii) The oversight of the 'monarch, minister, assistant and envoy' compatibility among herbs increases the risk of toxicity or side effects, opposing the 'treatment based on syndrome differentiation' principle in clinical TCM. Therefore, we propose a novel hierarchical structure-enhanced personalized recommendation model for TCM formulas based on knowledge graph diffusion guidance, namely TCM-HEDPR. Specifically, we pre-train symptom representations using patient-personalized prompt sequences and apply prompt-oriented contrastive learning for data augmentation. Furthermore, we employ a KG-guided homogeneous graph diffusion method integrated with a self-attention mechanism to globally capture the non-linear symptom-herb relationship. Lastly, we design a heterogeneous graph hierarchical network to integrate herbal dispensing relationships with implicit syndromes, guiding the prescription generation process at a fine-grained level and mitigating the long-tailed herb data distribution problem. Extensive experiments on two public datasets and one clinical dataset demonstrate the effectiveness of TCM-HEDPR. In addition, we incorporate insights from modern medicine and network pharmacology to evaluate the recommended prescriptions comprehensively. It can provide a new paradigm for the recommendation of modern TCM.",
            "primary_category": "cs.AI",
            "code_url": "null"
        },
        "2509.23242": {
            "title": "TATTOO: Training-free AesTheTic-aware Outfit recOmmendation",
            "authors": "Yuntian Wu, Xiaonan Hu, Ziqi Zhou, Hao Lu",
            "first_author": "Yuntian Wu",
            "url": "http://arxiv.org/abs/2509.23242v1",
            "pdf_url": "http://arxiv.org/abs/2509.23242",
            "publish_date": "2025-09-27",
            "abstract": "The global fashion e-commerce market relies significantly on intelligent and aesthetic-aware outfit-completion tools to promote sales. While previous studies have approached the problem of fashion outfit-completion and compatible-item retrieval, most of them require expensive, task-specific training on large-scale labeled data, and no effort is made to guide outfit recommendation with explicit human aesthetics. In the era of Multimodal Large Language Models (MLLMs), we show that the conventional training-based pipeline could be streamlined to a training-free paradigm, with better recommendation scores and enhanced aesthetic awareness. We achieve this with TATTOO, a Training-free AesTheTic-aware Outfit recommendation approach. It first generates a target-item description using MLLMs, followed by an aesthetic chain-of-thought used to distill the images into a structured aesthetic profile including color, style, occasion, season, material, and balance. By fusing the visual summary of the outfit with the textual description and aesthetics vectors using a dynamic entropy-gated mechanism, candidate items can be represented in a shared embedding space and be ranked accordingly. Experiments on a real-world evaluation set Aesthetic-100 show that TATTOO achieves state-of-the-art performance compared with existing training-based methods. Another standard Polyvore dataset is also used to measure the advanced zero-shot retrieval capability of our training-free method.",
            "primary_category": "cs.CV",
            "code_url": "null"
        },
        "2509.23175": {
            "title": "WARBERT: A Hierarchical BERT-based Model for Web API Recommendation",
            "authors": "Zishuo Xu, Yuhong Gu, Dezhong Yao",
            "first_author": "Zishuo Xu",
            "url": "http://arxiv.org/abs/2509.23175v1",
            "pdf_url": "http://arxiv.org/abs/2509.23175",
            "publish_date": "2025-09-27",
            "abstract": "With the emergence of Web 2.0 and microservices architecture, the number of Web APIs has increased dramatically, further intensifying the demand for efficient Web API recommendation. Existing solutions typically fall into two categories: recommendation-type methods, which treat each API as a label for classification, and match-type methods, which focus on matching mashups through API retrieval. However, three critical challenges persist: 1) the semantic ambiguities in comparing API and mashup descriptions, 2) the lack of detailed comparisons between the individual API and the mashup in recommendation-type methods, and 3) time inefficiencies for API retrieval in match-type methods. To address these challenges, we propose WARBERT, a hierarchical BERT-based model for Web API recommendation. WARBERT leverages dual-component feature fusion and attention comparison to extract precise semantic representations of API and mashup descriptions. WARBERT consists of two main components: WARBERT(R) for Recommendation and WARBERT(M) for Matching. Specifically, WAR-BERT(R) serves as an initial filter, narrowing down the candidate APIs, while WARBERT(M) refines the matching process by calculating the similarity between candidate APIs and mashup. The final likelihood of a mashup being matched with an API is determined by combining the predictions from WARBERT(R) and WARBERT(M). Additionally, WARBERT(R) incorporates an auxiliary task of mashup category judgment, which enhances its effectiveness in candidate selection. Experimental results on the ProgrammableWeb dataset demonstrate that WARBERT outperforms most existing solutions and achieves improvements of up to 11.7% compared to the model MTFM (Multi-Task Fusion Model), delivering significant enhancements in accuracy and effiency.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2509.22681": {
            "title": "FLAME: A Serving System Optimized for Large-Scale Generative Recommendation with Efficiency",
            "authors": "Xianwen Guo, Bin Huang, Xiaomeng Wu, Guanlin Wu, Fangjian Li, Shijia Wang, Qiang Xiao, Chuanjiang Luo, Yong Li",
            "first_author": "Xianwen Guo",
            "url": "http://arxiv.org/abs/2509.22681v1",
            "pdf_url": "http://arxiv.org/abs/2509.22681",
            "publish_date": "2025-09-17",
            "abstract": "Generative recommendation (GR) models possess greater scaling power compared to traditional deep learning recommendation models (DLRMs), yet they also impose a tremendous increase in computational burden. Measured in FLOPs, a typical GR model's workload sits in $10^9 \\sim 10^{11}$ range, roughly four orders of magnitude higher than traditional DLRMs. Delivering accurate results in a few tens of milliseconds while processing billions of such requests per day puts extreme demands on the performance of the online serving system. Therefore, for industry practitioners, the alluring gains of GR models are tempered by the formidable challenge of online deployment at scale in production services. In this work, we introduce a comprehensive solution of online serving system tailored For Large-scale GenerAtive RecoMmendation with Efficiency (FLAME). Specifically, we leveraging CPU-GPU heterogeneous hardware to decouple feature pre-processing and model computation. We encapsulated several memory optimization features as the Proximal Data Accelerator (PDA) module to make full use of limited bandwidth and storage resources, which achieves a 1.9x throughput gain and a 1.7x latency reduction. We implement the Fused Kernel Engine (FKE) module based on the functionality and interface of NVIDIA TensorRT to boost model computation, delivering a speedup ratio of 4.6x-6.1x, throughput gain ratio of 4.7x-6.3x one step further. In addition, we design the Dynamic Stream Orchestrator (DSO) module to coordinate concurrent requests, enhancing the system throughput performance with 1.3x improvement in throughput and 2.3x speed-up under non-uniform distribution of upstream candidates. Comprehensive evaluations demonstrate that our FLAME effectively supports large-scale online deployment of GR models and achieves remarkable improvements in system performance.",
            "primary_category": "cs.DC",
            "code_url": "null"
        },
        "2509.22661": {
            "title": "Next Point-of-interest (POI) Recommendation Model Based on Multi-modal Spatio-temporal Context Feature Embedding",
            "authors": "Lingyu Zhang, Guobin Wu, Yan Wang, Pengfei Xu, Jian Liang, Xuan Song, Yunhai Wang",
            "first_author": "Lingyu Zhang",
            "url": "http://arxiv.org/abs/2509.22661v1",
            "pdf_url": "http://arxiv.org/abs/2509.22661",
            "publish_date": "2025-08-29",
            "abstract": "The next Point-of-interest (POI) recommendation is mainly based on sequential traffic information to predict the user's next boarding point location. This is a highly regarded and widely applied research task in the field of intelligent transportation, and there have been many research results to date. Traditional POI prediction models primarily rely on short-term traffic sequence information, often neglecting both long-term and short-term preference data, as well as crucial spatiotemporal context features in user behavior. To address this issue, this paper introduces user long-term preference information and key spatiotemporal context information, and proposes a POI recommendation model based on multimodal spatiotemporal context feature embedding. The model extracts long-term preference features and key spatiotemporal context features from traffic data through modules such as spatiotemporal feature processing, multimodal embedding, and self-attention aggregation. It then uses a weighted fusion method to dynamically adjust the weights of long-term and short-term features based on users' historical behavior patterns and the current context. Finally, the fused features are matched using attention, and the probability of each location candidate becoming the next location is calculated. This paper conducts experimental verification on multiple transportation datasets, and the results show that the POI prediction model combining multiple types of features has higher prediction accuracy than existing SOTA models and methods.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2509.22659": {
            "title": "Federated Consistency- and Complementarity-aware Consensus-enhanced Recommendation",
            "authors": "Yunqi Mi, Boyang Yan, Guoshuai Zhao, Jialie Shen, Xueming Qian",
            "first_author": "Yunqi Mi",
            "url": "http://arxiv.org/abs/2509.22659v1",
            "pdf_url": "http://arxiv.org/abs/2509.22659",
            "publish_date": "2025-08-27",
            "abstract": "Personalized federated recommendation system (FedRec) has gained significant attention for its ability to preserve privacy in delivering tailored recommendations. To alleviate the statistical heterogeneity challenges among clients and improve personalization, decoupling item embeddings into the server and client-specific views has become a promising way. Among them, the global item embedding table serves as a consensus representation that integrates and reflects the collective patterns across all clients. However, the inherent sparsity and high uniformity of interaction data from massive-scale clients results in degraded consensus and insufficient decoupling, reducing consensus's utility. To this end, we propose a \\textbf{Fed}erated \\textbf{C}onsistency- and \\textbf{C}omplementarity-aware \\textbf{C}onsensus-enhanced \\textbf{R}ecommendation (Fed3CR) method for personalized FedRec. To improve the efficiency of the utilization of consensus, we propose an \\textbf{A}daptive \\textbf{C}onsensus \\textbf{E}nhancement (ACE) strategy to learn the relationship between global and client-specific item embeddings. It enables the client to adaptively enhance specific information in the consensus, transforming it into a form that best suits itself. To improve the quality of decoupling, we propose a \\textbf{C}onsistency- and \\textbf{C}omplementarity-aware \\textbf{O}ptimization (C2O) strategy, which helps to learn more effective and complementary representations. Notably, our proposed Fed3CR is a plug-and-play method, which can be integrated with other FedRec methods to improve its performance. Extensive experiments on four real-world datasets represent the superior performance of Fed3CR.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2509.26107": {
            "title": "Items Proxy Bridging: Enabling Frictionless Critiquing in Knowledge Graph Recommendations",
            "authors": "Huanyu Zhang, Xiaoxuan Shen, Yu Lei, Baolin Yi, Jianfang Liu, Yinao xie",
            "first_author": "Huanyu Zhang",
            "url": "http://arxiv.org/abs/2509.26107v1",
            "pdf_url": "http://arxiv.org/abs/2509.26107",
            "publish_date": "2025-09-30",
            "abstract": "Modern recommender systems place great inclination towards facilitating user experience, as more applications enabling users to critique and then refine recommendations immediately. Considering the real-time requirements, critique-able recommender systems typically straight modify the model parameters and update the recommend list through analyzing the user critiquing keyphrases in the inference phase. Current critiquing methods require first constructing a specially designated model which establish direct correlations between users and keyphrases during the training phase allowing for innovative recommendations upon the critiquing,restricting the applicable scenarios. Additionally, all these approaches ignore the catastrophic forgetting problem, where the cumulative changes in parameters during continuous multi-step critiquing may lead to a collapse in model performance. Thus, We conceptualize a proxy bridging users and keyphrases, proposing a streamlined yet potent Items Proxy Generic Critiquing Framework (IPGC) framework, which can serve as a universal plugin for most knowledge graph recommender models based on collaborative filtering (CF) strategies. IPGC provides a new paradigm for frictionless integration of critique mechanisms to enable iterative recommendation refinement in mainstream recommendation scenarios. IPGC describes the items proxy mechanism for transforming the critiquing optimization objective of user-keyphrase pairs into user-item pairs, adapting it for general CF recommender models without the necessity of specifically designed user-keyphrase correlation module. Furthermore, an anti-forgetting regularizer is introduced in order to efficiently mitigate the catastrophic forgetting problem of the model as a prior for critiquing optimization.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2509.26063": {
            "title": "Fading to Grow: Growing Preference Ratios via Preference Fading Discrete Diffusion for Recommendation",
            "authors": "Guoqing Hu, An Zhang. Shuchang Liu, Wenyu Mao, Jiancan Wu, Xun Yang, Xiang Li, Lantao Hu, Han Li, Kun Gai, Xiang Wang",
            "first_author": "Guoqing Hu",
            "url": "http://arxiv.org/abs/2509.26063v1",
            "pdf_url": "http://arxiv.org/abs/2509.26063",
            "publish_date": "2025-09-30",
            "abstract": "Recommenders aim to rank items from a discrete item corpus in line with user interests, yet suffer from extremely sparse user preference data. Recent advances in diffusion models have inspired diffusion-based recommenders, which alleviate sparsity by injecting noise during a forward process to prevent the collapse of perturbed preference distributions. However, current diffusion-based recommenders predominantly rely on continuous Gaussian noise, which is intrinsically mismatched with the discrete nature of user preference data in recommendation. In this paper, building upon recent advances in discrete diffusion, we propose PreferGrow, a discrete diffusion-based recommender system that models preference ratios by fading and growing user preferences over the discrete item corpus. PreferGrow differs from existing diffusion-based recommenders in three core aspects: (1) Discrete modeling of preference ratios: PreferGrow models relative preference ratios between item pairs, rather than operating in the item representation or raw score simplex. This formulation aligns naturally with the discrete and ranking-oriented nature of recommendation tasks. (2) Perturbing via preference fading: Instead of injecting continuous noise, PreferGrow fades user preferences by replacing the preferred item with alternatives -- physically akin to negative sampling -- thereby eliminating the need for any prior noise assumption. (3) Preference reconstruction via growing: PreferGrow reconstructs user preferences by iteratively growing the preference signals from the estimated ratios. PreferGrow offers a well-defined matrix-based formulation with theoretical guarantees on Markovianity and reversibility, and it demonstrates consistent performance gains over state-of-the-art diffusion-based recommenders across five benchmark datasets, highlighting both its theoretical soundness and empirical effectiveness.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2509.25992": {
            "title": "MHINDR -- a DSM5 based mental health diagnosis and recommendation framework using LLM",
            "authors": "Vaishali Agarwal, Sachin Thukral, Arnab Chatterjee",
            "first_author": "Vaishali Agarwal",
            "url": "http://arxiv.org/abs/2509.25992v1",
            "pdf_url": "http://arxiv.org/abs/2509.25992",
            "publish_date": "2025-09-30",
            "abstract": "Mental health forums offer valuable insights into psychological issues, stressors, and potential solutions. We propose MHINDR, a large language model (LLM) based framework integrated with DSM-5 criteria to analyze user-generated text, dignose mental health conditions, and generate personalized interventions and insights for mental health practitioners. Our approach emphasizes on the extraction of temporal information for accurate diagnosis and symptom progression tracking, together with psychological features to create comprehensive mental health summaries of users. The framework delivers scalable, customizable, and data-driven therapeutic recommendations, adaptable to diverse clinical contexts, patient needs, and workplace well-being programs.",
            "primary_category": "cs.SI",
            "code_url": "null"
        },
        "2509.25755": {
            "title": "HiFIRec: Towards High-Frequency yet Low-Intention Behaviors for Multi-Behavior Recommendation",
            "authors": "Ruiqi Luo, Ran Jin, Zhenglong Li, Kaixi Hu, Xiaohui Tao, Lin Li",
            "first_author": "Ruiqi Luo",
            "url": "http://arxiv.org/abs/2509.25755v1",
            "pdf_url": "http://arxiv.org/abs/2509.25755",
            "publish_date": "2025-09-30",
            "abstract": "Multi-behavior recommendation leverages multiple types of user-item interactions to address data sparsity and cold-start issues, providing personalized services in domains such as healthcare and e-commerce. Most existing methods utilize graph neural networks to model user intention in a unified manner, which inadequately considers the heterogeneity across different behaviors. Especially, high-frequency yet low-intention behaviors may implicitly contain noisy signals, and frequent patterns that are plausible while misleading, thereby hindering the learning of user intentions. To this end, this paper proposes a novel multi-behavior recommendation method, HiFIRec, that corrects the effect of high-frequency yet low-intention behaviors by differential behavior modeling. To revise the noisy signals, we hierarchically suppress it across layers by extracting neighborhood information through layer-wise neighborhood aggregation and further capturing user intentions through adaptive cross-layer feature fusion. To correct plausible frequent patterns, we propose an intensity-aware non-sampling strategy that dynamically adjusts the weights of negative samples. Extensive experiments on two benchmarks show that HiFIRec relatively improves HR@10 by 4.21%-6.81% over several state-of-the-art methods.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2509.25522": {
            "title": "Understanding Generative Recommendation with Semantic IDs from a Model-scaling View",
            "authors": "Jingzhe Liu, Liam Collins, Jiliang Tang, Tong Zhao, Neil Shah, Clark Mingxuan Ju",
            "first_author": "Jingzhe Liu",
            "url": "http://arxiv.org/abs/2509.25522v2",
            "pdf_url": "http://arxiv.org/abs/2509.25522",
            "publish_date": "2025-09-29",
            "abstract": "Recent advancements in generative models have allowed the emergence of a promising paradigm for recommender systems (RS), known as Generative Recommendation (GR), which tries to unify rich item semantics and collaborative filtering signals. One popular modern approach is to use semantic IDs (SIDs), which are discrete codes quantized from the embeddings of modality encoders (e.g., large language or vision models), to represent items in an autoregressive user interaction sequence modeling setup (henceforth, SID-based GR). While generative models in other domains exhibit well-established scaling laws, our work reveals that SID-based GR shows significant bottlenecks while scaling up the model. In particular, the performance of SID-based GR quickly saturates as we enlarge each component: the modality encoder, the quantization tokenizer, and the RS itself. In this work, we identify the limited capacity of SIDs to encode item semantic information as one of the fundamental bottlenecks. Motivated by this observation, as an initial effort to obtain GR models with better scaling behaviors, we revisit another GR paradigm that directly uses large language models (LLMs) as recommenders (henceforth, LLM-as-RS). Our experiments show that the LLM-as-RS paradigm has superior model scaling properties and achieves up to 20 percent improvement over the best achievable performance of SID-based GR through scaling. We also challenge the prevailing belief that LLMs struggle to capture collaborative filtering information, showing that their ability to model user-item interactions improves as LLMs scale up. Our analyses on both SID-based GR and LLMs across model sizes from 44M to 14B parameters underscore the intrinsic scaling limits of SID-based GR and position LLM-as-RS as a promising path toward foundation models for GR.",
            "primary_category": "cs.AI",
            "code_url": "null"
        },
        "2509.25289": {
            "title": "ClustRecNet: A Novel End-to-End Deep Learning Framework for Clustering Algorithm Recommendation",
            "authors": "Mohammadreza Bakhtyari, Bogdan Mazoure, Renato Cordeiro de Amorim, Guillaume Rabusseau, Vladimir Makarenkov",
            "first_author": "Mohammadreza Bakhtyari",
            "url": "http://arxiv.org/abs/2509.25289v2",
            "pdf_url": "http://arxiv.org/abs/2509.25289",
            "publish_date": "2025-09-29",
            "abstract": "We introduce ClustRecNet - a novel deep learning (DL)-based recommendation framework for determining the most suitable clustering algorithms for a given dataset, addressing the long-standing challenge of clustering algorithm selection in unsupervised learning. To enable supervised learning in this context, we construct a comprehensive data repository comprising 34,000 synthetic datasets with diverse structural properties. Each of them was processed using 10 popular clustering algorithms. The resulting clusterings were assessed via the Adjusted Rand Index (ARI) to establish ground truth labels, used for training and evaluation of our DL model. The proposed network architecture integrates convolutional, residual, and attention mechanisms to capture both local and global structural patterns from the input data. This design supports end-to-end training to learn compact representations of datasets and enables direct recommendation of the most suitable clustering algorithm, reducing reliance on handcrafted meta-features and traditional Cluster Validity Indices (CVIs). Comprehensive experiments across synthetic and real-world benchmarks demonstrate that our DL model consistently outperforms conventional CVIs (e.g. Silhouette, Calinski-Harabasz, Davies-Bouldin, and Dunn) as well as state-of-the-art AutoML clustering recommendation approaches (e.g. ML2DAC, AutoCluster, and AutoML4Clust). Notably, the proposed model achieves a 0.497 ARI improvement over the Calinski-Harabasz index on synthetic data and a 15.3% ARI gain over the best-performing AutoML approach on real-world data.",
            "primary_category": "cs.LG",
            "code_url": "null"
        },
        "2510.02215": {
            "title": "C2AL: Cohort-Contrastive Auxiliary Learning for Large-scale Recommendation Systems",
            "authors": "Mertcan Cokbas, Ziteng Liu, Zeyi Tao, Elder Veliz, Qin Huang, Ellie Wen, Huayu Li, Qiang Jin, Murat Duman, Benjamin Au, Guy Lebanon, Sagar Chordia, Chengkai Zhang",
            "first_author": "Mertcan Cokbas",
            "url": "http://arxiv.org/abs/2510.02215v2",
            "pdf_url": "http://arxiv.org/abs/2510.02215",
            "publish_date": "2025-10-02",
            "abstract": "Training large-scale recommendation models under a single global objective implicitly assumes homogeneity across user populations. However, real-world data are composites of heterogeneous cohorts with distinct conditional distributions. As models increase in scale and complexity and as more data is used for training, they become dominated by central distribution patterns, neglecting head and tail regions. This imbalance limits the model's learning ability and can result in inactive attention weights or dead neurons. In this paper, we reveal how the attention mechanism can play a key role in factorization machines for shared embedding selection, and propose to address this challenge by analyzing the substructures in the dataset and exposing those with strong distributional contrast through auxiliary learning. Unlike previous research, which heuristically applies weighted labels or multi-task heads to mitigate such biases, we leverage partially conflicting auxiliary labels to regularize the shared representation. This approach customizes the learning process of attention layers to preserve mutual information with minority cohorts while improving global performance. We evaluated C2AL on massive production datasets with billions of data points each for six SOTA models. Experiments show that the factorization machine is able to capture fine-grained user-ad interactions using the proposed method, achieving up to a 0.16% reduction in normalized entropy overall and delivering gains exceeding 0.30% on targeted minority cohorts.",
            "primary_category": "cs.LG",
            "code_url": "null"
        },
        "2510.01698": {
            "title": "TalkPlay-Tools: Conversational Music Recommendation with LLM Tool Calling",
            "authors": "Seungheon Doh, Keunwoo Choi, Juhan Nam",
            "first_author": "Seungheon Doh",
            "url": "http://arxiv.org/abs/2510.01698v3",
            "pdf_url": "http://arxiv.org/abs/2510.01698",
            "publish_date": "2025-10-02",
            "abstract": "While the recent developments in large language models (LLMs) have successfully enabled generative recommenders with natural language interactions, their recommendation behavior is limited, leaving other simpler yet crucial components such as metadata or attribute filtering underutilized in the system. We propose an LLM-based music recommendation system with tool calling to serve as a unified retrieval-reranking pipeline. Our system positions an LLM as an end-to-end recommendation system that interprets user intent, plans tool invocations, and orchestrates specialized components: boolean filters (SQL), sparse retrieval (BM25), dense retrieval (embedding similarity), and generative retrieval (semantic IDs). Through tool planning, the system predicts which types of tools to use, their execution order, and the arguments needed to find music matching user preferences, supporting diverse modalities while seamlessly integrating multiple database filtering methods. We demonstrate that this unified tool-calling framework achieves competitive performance across diverse recommendation scenarios by selectively employing appropriate retrieval methods based on user queries, envisioning a new paradigm for conversational music recommendation systems.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2510.01622": {
            "title": "LLM4Rec: Large Language Models for Multimodal Generative Recommendation with Causal Debiasing",
            "authors": "Bo Ma, Hang Li, ZeHua Hu, XiaoFan Gui, LuYao Liu, Simon Lau",
            "first_author": "Bo Ma",
            "url": "http://arxiv.org/abs/2510.01622v1",
            "pdf_url": "http://arxiv.org/abs/2510.01622",
            "publish_date": "2025-10-02",
            "abstract": "Contemporary generative recommendation systems face significant challenges in handling multimodal data, eliminating algorithmic biases, and providing transparent decision-making processes. This paper introduces an enhanced generative recommendation framework that addresses these limitations through five key innovations: multimodal fusion architecture, retrieval-augmented generation mechanisms, causal inference-based debiasing, explainable recommendation generation, and real-time adaptive learning capabilities. Our framework leverages advanced large language models as the backbone while incorporating specialized modules for cross-modal understanding, contextual knowledge integration, bias mitigation, explanation synthesis, and continuous model adaptation. Extensive experiments on three benchmark datasets (MovieLens-25M, Amazon-Electronics, Yelp-2023) demonstrate consistent improvements in recommendation accuracy, fairness, and diversity compared to existing approaches. The proposed framework achieves up to 2.3% improvement in NDCG@10 and 1.4% enhancement in diversity metrics while maintaining computational efficiency through optimized inference strategies.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2510.01609": {
            "title": "AgentRec: Next-Generation LLM-Powered Multi-Agent Collaborative Recommendation with Adaptive Intelligence",
            "authors": "Bo Ma, Hang Li, ZeHua Hu, XiaoFan Gui, LuYao Liu, Simon Lau",
            "first_author": "Bo Ma",
            "url": "http://arxiv.org/abs/2510.01609v1",
            "pdf_url": "http://arxiv.org/abs/2510.01609",
            "publish_date": "2025-10-02",
            "abstract": "Interactive conversational recommender systems have gained significant attention for their ability to capture user preferences through natural language interactions. However, existing approaches face substantial challenges in handling dynamic user preferences, maintaining conversation coherence, and balancing multiple ranking objectives simultaneously. This paper introduces AgentRec, a next-generation LLM-powered multi-agent collaborative recommendation framework that addresses these limitations through hierarchical agent networks with adaptive intelligence. Our approach employs specialized LLM-powered agents for conversation understanding, preference modeling, context awareness, and dynamic ranking, coordinated through an adaptive weighting mechanism that learns from interaction patterns. We propose a three-tier learning strategy combining rapid response for simple queries, intelligent reasoning for complex preferences, and deep collaboration for challenging scenarios. Extensive experiments on three real-world datasets demonstrate that AgentRec achieves consistent improvements over state-of-the-art baselines, with 2.8\\% enhancement in conversation success rate, 1.9\\% improvement in recommendation accuracy (NDCG@10), and 3.2\\% better conversation efficiency while maintaining comparable computational costs through intelligent agent coordination.",
            "primary_category": "cs.AI",
            "code_url": "null"
        },
        "2510.00080": {
            "title": "SoREX: Towards Self-Explainable Social Recommendation with Relevant Ego-Path Extraction",
            "authors": "Hanze Guo, Yijun Ma, Xiao Zhou",
            "first_author": "Hanze Guo",
            "url": "http://arxiv.org/abs/2510.00080v1",
            "pdf_url": "http://arxiv.org/abs/2510.00080",
            "publish_date": "2025-09-30",
            "abstract": "Social recommendation has been proven effective in addressing data sparsity in user-item interaction modeling by leveraging social networks. The recent integration of Graph Neural Networks (GNNs) has further enhanced prediction accuracy in contemporary social recommendation algorithms. However, many GNN-based approaches in social recommendation lack the ability to furnish meaningful explanations for their predictions. In this study, we confront this challenge by introducing SoREX, a self-explanatory GNN-based social recommendation framework. SoREX adopts a two-tower framework enhanced by friend recommendation, independently modeling social relations and user-item interactions, while jointly optimizing an auxiliary task to reinforce social signals. To offer explanations, we propose a novel ego-path extraction approach. This method involves transforming the ego-net of a target user into a collection of multi-hop ego-paths, from which we extract factor-specific and candidate-aware ego-path subsets as explanations. This process facilitates the summarization of detailed comparative explanations among different candidate items through intricate substructure analysis. Furthermore, we conduct explanation re-aggregation to explicitly correlate explanations with downstream predictions, imbuing our framework with inherent self-explainability. Comprehensive experiments conducted on four widely adopted benchmark datasets validate the effectiveness of SoREX in predictive accuracy. Additionally, qualitative and quantitative analyses confirm the efficacy of the extracted explanations in SoREX. Our code and data are available at https://github.com/antman9914/SoREX.",
            "primary_category": "cs.SI",
            "code_url": "null"
        },
        "2510.03038": {
            "title": "CHORD: Customizing Hybrid-precision On-device Model for Sequential Recommendation with Device-cloud Collaboration",
            "authors": "Tianqi Liu, Kairui Fu, Shengyu Zhang, Wenyan Fan, Zhaocheng Du, Jieming Zhu, Fan Wu, Fei Wu",
            "first_author": "Tianqi Liu",
            "url": "http://arxiv.org/abs/2510.03038v1",
            "pdf_url": "http://arxiv.org/abs/2510.03038",
            "publish_date": "2025-10-03",
            "abstract": "With the advancement of mobile device capabilities, deploying reranking models directly on devices has become feasible, enabling real-time contextual recommendations. When migrating models from cloud to devices, resource heterogeneity inevitably necessitates model compression. Recent quantization methods show promise for efficient deployment, yet they overlook device-specific user interests, resulting in compromised recommendation accuracy. While on-device finetuning captures personalized user preference, it imposes additional computational burden through local retraining. To address these challenges, we propose a framework for \\underline{\\textbf{C}}ustomizing \\underline{\\textbf{H}}ybrid-precision \\underline{\\textbf{O}}n-device model for sequential \\underline{\\textbf{R}}ecommendation with \\underline{\\textbf{D}}evice-cloud collaboration (\\textbf{CHORD}), leveraging channel-wise mixed-precision quantization to simultaneously achieve personalization and resource-adaptive deployment. CHORD distributes randomly initialized models across heterogeneous devices and identifies user-specific critical parameters through auxiliary hypernetwork modules on the cloud. Our parameter sensitivity analysis operates across multiple granularities (layer, filter, and element levels), enabling precise mapping from user profiles to quantization strategy. Through on-device mixed-precision quantization, CHORD delivers dynamic model adaptation and accelerated inference without backpropagation, eliminating costly retraining cycles. We minimize communication overhead by encoding quantization strategies using only 2 bits per channel instead of 32-bit weights. Experiments on three real-world datasets with two popular backbones (SASRec and Caser) demonstrate the accuracy, efficiency, and adaptivity of CHORD.",
            "primary_category": "cs.LG",
            "code_url": "null"
        },
        "2510.02656": {
            "title": "A Simple but Effective Elaborative Query Reformulation Approach for Natural Language Recommendation",
            "authors": "Qianfeng Wen, Yifan Liu, Justin Cui, Joshua Zhang, Anton Korikov, George-Kirollos Saad, Scott Sanner",
            "first_author": "Qianfeng Wen",
            "url": "http://arxiv.org/abs/2510.02656v1",
            "pdf_url": "http://arxiv.org/abs/2510.02656",
            "publish_date": "2025-10-03",
            "abstract": "Natural Language (NL) recommender systems aim to retrieve relevant items from free-form user queries and item descriptions. Existing systems often rely on dense retrieval (DR), which struggles to interpret challenging queries that express broad (e.g., \"cities for youth friendly activities\") or indirect (e.g., \"cities for a high school graduation trip\") user intents. While query reformulation (QR) has been widely adopted to improve such systems, existing QR methods tend to focus only on expanding the range of query subtopics (breadth) or elaborating on the potential meaning of a query (depth), but not both. In this paper, we propose EQR (Elaborative Subtopic Query Reformulation), a large language model-based QR method that combines both breadth and depth by generating potential query subtopics with information-rich elaborations. We also introduce three new natural language recommendation benchmarks in travel, hotel, and restaurant domains to establish evaluation of NL recommendation with challenging queries. Experiments show EQR substantially outperforms state-of-the-art QR methods in various evaluation metrics, highlighting that a simple yet effective QR approach can significantly improve NL recommender systems for queries with broad and indirect user intents.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2510.02352": {
            "title": "Evaluating Bias in Spoken Dialogue LLMs for Real-World Decisions and Recommendations",
            "authors": "Yihao Wu, Tianrui Wang, Yizhou Peng, Yi-Wen Chao, Xuyi Zhuang, Xinsheng Wang, Shunshun Yin, Ziyang Ma",
            "first_author": "Yihao Wu",
            "url": "http://arxiv.org/abs/2510.02352v1",
            "pdf_url": "http://arxiv.org/abs/2510.02352",
            "publish_date": "2025-09-27",
            "abstract": "While biases in large language models (LLMs), such as stereotypes and cultural tendencies in outputs, have been examined and identified, their presence and characteristics in spoken dialogue models (SDMs) with audio input and output remain largely unexplored. Paralinguistic features, such as age, gender, and accent, can affect model outputs; when compounded by multi-turn conversations, these effects may exacerbate biases, with potential implications for fairness in decision-making and recommendation tasks. In this paper, we systematically evaluate biases in speech LLMs and study the impact of multi-turn dialogues with repeated negative feedback. Bias is measured using Group Unfairness Score (GUS) for decisions and similarity-based normalized statistics rate (SNSR) for recommendations, across both open-source models like Qwen2.5-Omni and GLM-4-Voice, as well as closed-source APIs such as GPT-4o Audio and Gemini-2.5-Flash. Our analysis reveals that closed-source models generally exhibit lower bias, while open-source models are more sensitive to age and gender, and recommendation tasks tend to amplify cross-group disparities. We found that biased decisions may persist in multi-turn conversations. This work provides the first systematic study of biases in end-to-end spoken dialogue models, offering insights towards fair and reliable audio-based interactive systems. To facilitate further research, we release the FairDialogue dataset and evaluation code.",
            "primary_category": "cs.CL",
            "code_url": "null"
        },
        "2510.02331": {
            "title": "Synthetic Dialogue Generation for Interactive Conversational Elicitation & Recommendation (ICER)",
            "authors": "Moonkyung Ryu, Chih-Wei Hsu, Yinlam Chow, Mohammad Ghavamzadeh, Craig Boutilier",
            "first_author": "Moonkyung Ryu",
            "url": "http://arxiv.org/abs/2510.02331v1",
            "pdf_url": "http://arxiv.org/abs/2510.02331",
            "publish_date": "2025-09-26",
            "abstract": "While language models (LMs) offer great potential for conversational recommender systems (CRSs), the paucity of public CRS data makes fine-tuning LMs for CRSs challenging. In response, LMs as user simulators qua data generators can be used to train LM-based CRSs, but often lack behavioral consistency, generating utterance sequences inconsistent with those of any real user. To address this, we develop a methodology for generating natural dialogues that are consistent with a user's underlying state using behavior simulators together with LM-prompting. We illustrate our approach by generating a large, open-source CRS data set with both preference elicitation and example critiquing. Rater evaluation on some of these dialogues shows them to exhibit considerable consistency, factuality and naturalness.",
            "primary_category": "cs.CL",
            "code_url": "null"
        },
        "2510.04551": {
            "title": "Fine-grained auxiliary learning for real-world product recommendation",
            "authors": "Mario Almagro, Diego Ortego, David Jimenez",
            "first_author": "Mario Almagro",
            "url": "http://arxiv.org/abs/2510.04551v1",
            "pdf_url": "http://arxiv.org/abs/2510.04551",
            "publish_date": "2025-10-06",
            "abstract": "Product recommendation is the task of recovering the closest items to a given query within a large product corpora. Generally, one can determine if top-ranked products are related to the query by applying a similarity threshold; exceeding it deems the product relevant, otherwise manual revision is required. Despite being a well-known problem, the integration of these models in real-world systems is often overlooked. In particular, production systems have strong coverage requirements, i.e., a high proportion of recommendations must be automated. In this paper we propose ALC , an Auxiliary Learning strategy that boosts Coverage through learning fine-grained embeddings. Concretely, we introduce two training objectives that leverage the hardest negatives in the batch to build discriminative training signals between positives and negatives. We validate ALC using three extreme multi-label classification approaches in two product recommendation datasets; LF-AmazonTitles-131K and Tech and Durables (proprietary), demonstrating state-of-the-art coverage rates when combined with a recent threshold-consistent margin loss.",
            "primary_category": "cs.CL",
            "code_url": "null"
        },
        "2510.04508": {
            "title": "MARCO: A Cooperative Knowledge Transfer Framework for Personalized Cross-domain Recommendations",
            "authors": "Lili Xie, Yi Zhang, Ruihong Qiu, Jiajun Liu, Sen Wang",
            "first_author": "Lili Xie",
            "url": "http://arxiv.org/abs/2510.04508v1",
            "pdf_url": "http://arxiv.org/abs/2510.04508",
            "publish_date": "2025-10-06",
            "abstract": "Recommender systems frequently encounter data sparsity issues, particularly when addressing cold-start scenarios involving new users or items. Multi-source cross-domain recommendation (CDR) addresses these challenges by transferring valuable knowledge from multiple source domains to enhance recommendations in a target domain. However, existing reinforcement learning (RL)-based CDR methods typically rely on a single-agent framework, leading to negative transfer issues caused by inconsistent domain contributions and inherent distributional discrepancies among source domains. To overcome these limitations, MARCO, a Multi-Agent Reinforcement Learning-based Cross-Domain recommendation framework, is proposed. It leverages cooperative multi-agent reinforcement learning, where each agent is dedicated to estimating the contribution from an individual source domain, effectively managing credit assignment and mitigating negative transfer. In addition, an entropy-based action diversity penalty is introduced to enhance policy expressiveness and stabilize training by encouraging diverse agents' joint actions. Extensive experiments across four benchmark datasets demonstrate MARCO's superior performance over state-of-the-art methods, highlighting its robustness and strong generalization capabilities. The code is at https://github.com/xiewilliams/MARCO.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2510.04502": {
            "title": "Causality-aware Graph Aggregation Weight Estimator for Popularity Debiasing in Top-K Recommendation",
            "authors": "Yue Que, Yingyi Zhang, Xiangyu Zhao, Chen Ma",
            "first_author": "Yue Que",
            "url": "http://arxiv.org/abs/2510.04502v1",
            "pdf_url": "http://arxiv.org/abs/2510.04502",
            "publish_date": "2025-10-06",
            "abstract": "Graph-based recommender systems leverage neighborhood aggregation to generate node representations, which is highly sensitive to popularity bias, resulting in an echo effect during information propagation. Existing graph-based debiasing solutions refine the aggregation process with attempts such as edge reconstruction or weight adjustment. However, these methods remain inadequate in fully alleviating popularity bias. Specifically, this is because 1) they provide no insights into graph aggregation rationality, thus lacking an optimality guarantee; 2) they fail to well balance the training and debiasing process, which undermines the effectiveness. In this paper, we propose a novel approach to mitigate popularity bias through rational modeling of the graph aggregation process. We reveal that graph aggregation is a special form of backdoor adjustment in causal inference, where the aggregation weight corresponds to the historical interaction likelihood distribution. Based on this insight, we devise an encoder-decoder architecture, namely Causality-aware Graph Aggregation Weight Estimator for Debiasing (CAGED), to approximate the unbiased aggregation weight by optimizing the evidence lower bound of the interaction likelihood. In order to enhance the debiasing effectiveness during early training stages, we further design a momentum update strategy that incrementally refines the aggregation weight matrix. Extensive experiments on three datasets demonstrate that CAGED outperforms existing graph-based debiasing methods. Our implementation is available at https://github.com/QueYork/CAGED.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2510.04375": {
            "title": "Adaptive Weighted Loss for Sequential Recommendations on Sparse Domains",
            "authors": "Akshay Mittal, Vinay Venkatesh, Krishna Kandi, Shalini Sudarshan",
            "first_author": "Akshay Mittal",
            "url": "http://arxiv.org/abs/2510.04375v1",
            "pdf_url": "http://arxiv.org/abs/2510.04375",
            "publish_date": "2025-10-05",
            "abstract": "The effectiveness of single-model sequential recommendation architectures, while scalable, is often limited when catering to \"power users\" in sparse or niche domains. Our previous research, PinnerFormerLite, addressed this by using a fixed weighted loss to prioritize specific domains. However, this approach can be sub-optimal, as a single, uniform weight may not be sufficient for domains with very few interactions, where the training signal is easily diluted by the vast, generic dataset.   This paper proposes a novel, data-driven approach: a Dynamic Weighted Loss function with comprehensive theoretical foundations and extensive empirical validation. We introduce an adaptive algorithm that adjusts the loss weight for each domain based on its sparsity in the training data, assigning a higher weight to sparser domains and a lower weight to denser ones. This ensures that even rare user interests contribute a meaningful gradient signal, preventing them from being overshadowed.   We provide rigorous theoretical analysis including convergence proofs, complexity analysis, and bounds analysis to establish the stability and efficiency of our approach. Our comprehensive empirical validation across four diverse datasets (MovieLens, Amazon Electronics, Yelp Business, LastFM Music) with state-of-the-art baselines (SIGMA, CALRec, SparseEnNet) demonstrates that this dynamic weighting system significantly outperforms all comparison methods, particularly for sparse domains, achieving substantial lifts in key metrics like Recall at 10 and NDCG at 10 while maintaining performance on denser domains and introducing minimal computational overhead.",
            "primary_category": "cs.LG",
            "code_url": "null"
        },
        "2510.04272": {
            "title": "Closing the Loop: Coordinating Inventory and Recommendation via Deep Reinforcement Learning on Multiple Timescales",
            "authors": "Jinyang Jiang, Jinhui Han, Yijie Peng, Ying Zhang",
            "first_author": "Jinyang Jiang",
            "url": "http://arxiv.org/abs/2510.04272v1",
            "pdf_url": "http://arxiv.org/abs/2510.04272",
            "publish_date": "2025-10-05",
            "abstract": "Effective cross-functional coordination is essential for enhancing firm-wide profitability, particularly in the face of growing organizational complexity and scale. Recent advances in artificial intelligence, especially in reinforcement learning (RL), offer promising avenues to address this fundamental challenge. This paper proposes a unified multi-agent RL framework tailored for joint optimization across distinct functional modules, exemplified via coordinating inventory replenishment and personalized product recommendation. We first develop an integrated theoretical model to capture the intricate interplay between these functions and derive analytical benchmarks that characterize optimal coordination. The analysis reveals synchronized adjustment patterns across products and over time, highlighting the importance of coordinated decision-making. Leveraging these insights, we design a novel multi-timescale multi-agent RL architecture that decomposes policy components according to departmental functions and assigns distinct learning speeds based on task complexity and responsiveness. Our model-free multi-agent design improves scalability and deployment flexibility, while multi-timescale updates enhance convergence stability and adaptability across heterogeneous decisions. We further establish the asymptotic convergence of the proposed algorithm. Extensive simulation experiments demonstrate that the proposed approach significantly improves profitability relative to siloed decision-making frameworks, while the behaviors of the trained RL agents align closely with the managerial insights from our theoretical model. Taken together, this work provides a scalable, interpretable RL-based solution to enable effective cross-functional coordination in complex business settings.",
            "primary_category": "cs.AI",
            "code_url": "null"
        },
        "2510.04239": {
            "title": "Empowering Denoising Sequential Recommendation with Large Language Model Embeddings",
            "authors": "Tongzhou Wu, Yuhao Wang, Maolin Wang, Chi Zhang, Xiangyu Zhao",
            "first_author": "Tongzhou Wu",
            "url": "http://arxiv.org/abs/2510.04239v1",
            "pdf_url": "http://arxiv.org/abs/2510.04239",
            "publish_date": "2025-10-05",
            "abstract": "Sequential recommendation aims to capture user preferences by modeling sequential patterns in user-item interactions. However, these models are often influenced by noise such as accidental interactions, leading to suboptimal performance. Therefore, to reduce the effect of noise, some works propose explicitly identifying and removing noisy items. However, we find that simply relying on collaborative information may result in an over-denoising problem, especially for cold items. To overcome these limitations, we propose a novel framework: Interest Alignment for Denoising Sequential Recommendation (IADSR) which integrates both collaborative and semantic information. Specifically, IADSR is comprised of two stages: in the first stage, we obtain the collaborative and semantic embeddings of each item from a traditional sequential recommendation model and an LLM, respectively. In the second stage, we align the collaborative and semantic embeddings and then identify noise in the interaction sequence based on long-term and short-term interests captured in the collaborative and semantic modalities. Our extensive experiments on four public datasets validate the effectiveness of the proposed framework and its compatibility with different sequential recommendation systems.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2510.03930": {
            "title": "LLM Chemistry Estimation for Multi-LLM Recommendation",
            "authors": "Huascar Sanchez, Briland Hitaj",
            "first_author": "Huascar Sanchez",
            "url": "http://arxiv.org/abs/2510.03930v1",
            "pdf_url": "http://arxiv.org/abs/2510.03930",
            "publish_date": "2025-10-04",
            "abstract": "Multi-LLM collaboration promises accurate, robust, and context-aware solutions, yet existing approaches rely on implicit selection and output assessment without analyzing whether collaborating models truly complement or conflict. We introduce LLM Chemistry -- a framework that measures when LLM combinations exhibit synergistic or antagonistic behaviors that shape collective performance beyond individual capabilities. We formalize the notion of chemistry among LLMs, propose algorithms that quantify it by analyzing interaction dependencies, and recommend optimal model ensembles accordingly. Our theoretical analysis shows that chemistry among collaborating LLMs is most evident under heterogeneous model profiles, with its outcome impact shaped by task type, group size, and complexity. Evaluation on classification, summarization, and program repair tasks provides initial evidence for these task-dependent effects, thereby reinforcing our theoretical results. This establishes LLM Chemistry as both a diagnostic factor in multi-LLM systems and a foundation for ensemble recommendation.",
            "primary_category": "cs.LG",
            "code_url": "null"
        },
        "2510.03350": {
            "title": "How does course recommendation impact student outcomes? Examining directed self-placement with regression discontinuity analysis",
            "authors": "Jason Godfrey",
            "first_author": "Jason Godfrey",
            "url": "http://arxiv.org/abs/2510.03350v1",
            "pdf_url": "http://arxiv.org/abs/2510.03350",
            "publish_date": "2025-10-02",
            "abstract": "For many students, placement into developmental education becomes a self-fulfilling prophecy. Placing college students into developmental education significantly negatively impacts student attainment, student probability of passing, and college credits earned. To combat these negative effects, many universities are investigating alternative placement mechanisms. Could directed self-placement be an effective alternative mechanism? Do students who self-place suffer the same negative impacts from placement recommendations as their traditionally placed counterparts? This paper uses longitudinal data with causal inference methods to examine whether directed self-placement has similar negative impacts on student grades and pass rates as mandatory placement schema. We begin with an analysis of over 20,000 student placement records into one of two different placement tracks for first-year writing. Longitudinal and institutional data allow us to control for characteristic variables such as student race, family income, and sex. The results of our regression discontinuity design show that directed self-placement does not negatively impact student grades or pass rate. This may be an improvement for students who place at or near the threshold for developmental/remedial education; However, class, race, and gender-based statistical differences persist in the program at-large, demonstrating that placement technique plays only one part in building a more equitable program.",
            "primary_category": "econ.GN",
            "code_url": "null"
        },
        "2510.06078": {
            "title": "Constraint-Aware Route Recommendation from Natural Language via Hierarchical LLM Agents",
            "authors": "Tao Zhe, Rui Liu, Fateme Memar, Xiao Luo, Wei Fan, Xinyue Ye, Zhongren Peng, Dongjie Wang",
            "first_author": "Tao Zhe",
            "url": "http://arxiv.org/abs/2510.06078v1",
            "pdf_url": "http://arxiv.org/abs/2510.06078",
            "publish_date": "2025-10-07",
            "abstract": "Route recommendation aims to provide users with optimal travel plans that satisfy diverse and complex requirements. Classical routing algorithms (e.g., shortest-path and constraint-aware search) are efficient but assume structured inputs and fixed objectives, limiting adaptability to natural-language queries. Recent LLM-based approaches enhance flexibility but struggle with spatial reasoning and the joint modeling of route-level and POI-level preferences. To address these limitations, we propose RouteLLM, a hierarchical multi-agent framework that grounds natural-language intents into constraint-aware routes. It first parses user queries into structured intents including POIs, paths, and constraints. A manager agent then coordinates specialized sub-agents: a constraint agent that resolves and formally check constraints, a POI agent that retrieves and ranks candidate POIs, and a path refinement agent that refines routes via a routing engine with preference-conditioned costs. A final verifier agent ensures constraint satisfaction and produces the final route with an interpretable rationale. This design bridges linguistic flexibility and spatial structure, enabling reasoning over route feasibility and user preferences. Experiments show that our method reliably grounds textual preferences into constraint-aware routes, improving route quality and preference satisfaction over classical methods.",
            "primary_category": "cs.AI",
            "code_url": "null"
        },
        "2510.05598": {
            "title": "AgentDR Dynamic Recommendation with Implicit Item-Item Relations via LLM-based Agents",
            "authors": "Mingdai Yang, Nurendra Choudhary, Jiangshu Du, Edward W. Huang, Philip S. Yu, Karthik Subbian, Danai Kourta",
            "first_author": "Mingdai Yang",
            "url": "http://arxiv.org/abs/2510.05598v1",
            "pdf_url": "http://arxiv.org/abs/2510.05598",
            "publish_date": "2025-10-07",
            "abstract": "Recent agent-based recommendation frameworks aim to simulate user behaviors by incorporating memory mechanisms and prompting strategies, but they struggle with hallucinating non-existent items and full-catalog ranking. Besides, a largely underexplored opportunity lies in leveraging LLMs'commonsense reasoning to capture user intent through substitute and complement relationships between items, which are usually implicit in datasets and difficult for traditional ID-based recommenders to capture. In this work, we propose a novel LLM-agent framework, AgenDR, which bridges LLM reasoning with scalable recommendation tools. Our approach delegates full-ranking tasks to traditional models while utilizing LLMs to (i) integrate multiple recommendation outputs based on personalized tool suitability and (ii) reason over substitute and complement relationships grounded in user history. This design mitigates hallucination, scales to large catalogs, and enhances recommendation relevance through relational reasoning. Through extensive experiments on three public grocery datasets, we show that our framework achieves superior full-ranking performance, yielding on average a twofold improvement over its underlying tools. We also introduce a new LLM-based evaluation metric that jointly measures semantic alignment and ranking correctness.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2510.05495": {
            "title": "Automated Research Article Classification and Recommendation Using NLP and ML",
            "authors": "Shadikur Rahman, Hasibul Karim Shanto, Umme Ayman Koana, Syed Muhammad Danish",
            "first_author": "Shadikur Rahman",
            "url": "http://arxiv.org/abs/2510.05495v1",
            "pdf_url": "http://arxiv.org/abs/2510.05495",
            "publish_date": "2025-10-07",
            "abstract": "In the digital era, the exponential growth of scientific publications has made it increasingly difficult for researchers to efficiently identify and access relevant work. This paper presents an automated framework for research article classification and recommendation that leverages Natural Language Processing (NLP) techniques and machine learning. Using a large-scale arXiv.org dataset spanning more than three decades, we evaluate multiple feature extraction approaches (TF--IDF, Count Vectorizer, Sentence-BERT, USE, Mirror-BERT) in combination with diverse machine learning classifiers (Logistic Regression, SVM, Na\\\"ive Bayes, Random Forest, Gradient Boosted Trees, and k-Nearest Neighbour). Our experiments show that Logistic Regression with TF--IDF consistently yields the best classification performance, achieving an accuracy of 69\\%. To complement classification, we incorporate a recommendation module based on the cosine similarity of vectorized articles, enabling efficient retrieval of related research papers. The proposed system directly addresses the challenge of information overload in digital libraries and demonstrates a scalable, data-driven solution to support literature discovery.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2510.05125": {
            "title": "Catalog-Native LLM: Speaking Item-ID Dialect with Less Entanglement for Recommendation",
            "authors": "Reza Shirkavand, Xiaokai Wei, Chen Wang, Zheng Hui, Heng Huang, Michelle Gong",
            "first_author": "Reza Shirkavand",
            "url": "http://arxiv.org/abs/2510.05125v1",
            "pdf_url": "http://arxiv.org/abs/2510.05125",
            "publish_date": "2025-09-30",
            "abstract": "While collaborative filtering delivers predictive accuracy and efficiency, and Large Language Models (LLMs) enable expressive and generalizable reasoning, modern recommendation systems must bring these strengths together. Growing user expectations, such as natural-language queries and transparent explanations, further highlight the need for a unified approach. However, doing so is nontrivial. Collaborative signals are often token-efficient but semantically opaque, while LLMs are semantically rich but struggle to model implicit user preferences when trained only on textual inputs. This paper introduces Item-ID + Oral-language Mixture-of-Experts Language Model (IDIOMoE), which treats item interaction histories as a native dialect within the language space, enabling collaborative signals to be understood in the same way as natural language. By splitting the Feed Forward Network of each block of a pretrained LLM into a separate text expert and an item expert with token-type gating, our method avoids destructive interference between text and catalog modalities. IDIOMoE demonstrates strong recommendation performance across both public and proprietary datasets, while preserving the text understanding of the pretrained model.",
            "primary_category": "cs.CL",
            "code_url": "null"
        },
        "2510.06924": {
            "title": "Ethical AI prompt recommendations in large language models using collaborative filtering",
            "authors": "Jordan Nelson, Almas Baimagambetov, Konstantinos Avgerinakis, Nikolaos Polatidis",
            "first_author": "Jordan Nelson",
            "url": "http://arxiv.org/abs/2510.06924v1",
            "pdf_url": "http://arxiv.org/abs/2510.06924",
            "publish_date": "2025-10-08",
            "abstract": "As large language models (LLMs) shape AI development, ensuring ethical prompt recommendations is crucial. LLMs offer innovation but risk bias, fairness issues, and accountability concerns. Traditional oversight methods struggle with scalability, necessitating dynamic solutions. This paper proposes using collaborative filtering, a technique from recommendation systems, to enhance ethical prompt selection. By leveraging user interactions, it promotes ethical guidelines while reducing bias. Contributions include a synthetic dataset for prompt recommendations and the application of collaborative filtering. The work also tackles challenges in ethical AI, such as bias mitigation, transparency, and preventing unethical prompt engineering.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2510.06657": {
            "title": "LLM-Powered Nuanced Video Attribute Annotation for Enhanced Recommendations",
            "authors": "Boyuan Long, Yueqi Wang, Hiloni Mehta, Mick Zomnir, Omkar Pathak, Changping Meng, Ruolin Jia, Yajun Peng, Dapeng Hong, Xia Wu, Mingyan Gao, Onkar Dalal, Ningren Han",
            "first_author": "Boyuan Long",
            "url": "http://arxiv.org/abs/2510.06657v1",
            "pdf_url": "http://arxiv.org/abs/2510.06657",
            "publish_date": "2025-10-08",
            "abstract": "This paper presents a case study on deploying Large Language Models (LLMs) as an advanced \"annotation\" mechanism to achieve nuanced content understanding (e.g., discerning content \"vibe\") at scale within a large-scale industrial short-form video recommendation system. Traditional machine learning classifiers for content understanding face protracted development cycles and a lack of deep, nuanced comprehension. The \"LLM-as-annotators\" approach addresses these by significantly shortening development times and enabling the annotation of subtle attributes. This work details an end-to-end workflow encompassing: (1) iterative definition and robust evaluation of target attributes, refined by offline metrics and online A/B testing; (2) scalable offline bulk annotation of video corpora using LLMs with multimodal features, optimized inference, and knowledge distillation for broad application; and (3) integration of these rich annotations into the online recommendation serving system, for example, through personalized restrict retrieval. Experimental results demonstrate the efficacy of this approach, with LLMs outperforming human raters in offline annotation quality for nuanced attributes and yielding significant improvements of user participation and satisfied consumption in online A/B tests. The study provides insights into designing and scaling production-level LLM pipelines for rich content evaluation, highlighting the adaptability and benefits of LLM-generated nuanced understanding for enhancing content discovery, user satisfaction, and the overall effectiveness of modern recommendation systems.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2510.06275": {
            "title": "Reproducibility Study of \"XRec: Large Language Models for Explainable Recommendation\"",
            "authors": "Ranjan Mishra, Julian I. Bibo, Quinten van Engelen, Henk Schaapman",
            "first_author": "Ranjan Mishra",
            "url": "http://arxiv.org/abs/2510.06275v1",
            "pdf_url": "http://arxiv.org/abs/2510.06275",
            "publish_date": "2025-10-06",
            "abstract": "In this study, we reproduced the work done in the paper \"XRec: Large Language Models for Explainable Recommendation\" by Ma et al. (2024). The original authors introduced XRec, a model-agnostic collaborative instruction-tuning framework that enables large language models (LLMs) to provide users with comprehensive explanations of generated recommendations. Our objective was to replicate the results of the original paper, albeit using Llama 3 as the LLM for evaluation instead of GPT-3.5-turbo. We built on the source code provided by Ma et al. (2024) to achieve our goal. Our work extends the original paper by modifying the input embeddings or deleting the output embeddings of XRec's Mixture of Experts module. Based on our results, XRec effectively generates personalized explanations and its stability is improved by incorporating collaborative information. However, XRec did not consistently outperform all baseline models in every metric. Our extended analysis further highlights the importance of the Mixture of Experts embeddings in shaping the explanation structures, showcasing how collaborative signals interact with language modeling. Through our work, we provide an open-source evaluation implementation that enhances accessibility for researchers and practitioners alike. Our complete code repository can be found at https://github.com/julianbibo/xrec-reproducibility.",
            "primary_category": "cs.CL",
            "code_url": "null"
        },
        "2510.08012": {
            "title": "Do We Really Need SFT? Prompt-as-Policy over Knowledge Graphs for Cold-start Next POI Recommendation",
            "authors": "Jinze Wang, Lu Zhang, Yiyang Cui, Zhishu Shen, Xingjun Ma, Jiong Jin, Tiehua Zhang",
            "first_author": "Jinze Wang",
            "url": "http://arxiv.org/abs/2510.08012v1",
            "pdf_url": "http://arxiv.org/abs/2510.08012",
            "publish_date": "2025-10-09",
            "abstract": "Next point-of-interest (POI) recommendation is crucial for smart urban services such as tourism, dining, and transportation, yet most approaches struggle under cold-start conditions where user-POI interactions are sparse. Recent efforts leveraging large language models (LLMs) address this challenge through either supervised fine-tuning (SFT) or in-context learning (ICL). However, SFT demands costly annotations and fails to generalize to inactive users, while static prompts in ICL cannot adapt to diverse user contexts. To overcome these limitations, we propose Prompt-as-Policy over knowledge graphs, a reinforcement-guided prompting framework that learns to construct prompts dynamically through contextual bandit optimization. Our method treats prompt construction as a learnable policy that adaptively determines (i) which relational evidences to include, (ii) the number of evidence per candidate, and (iii) their organization and ordering within prompts. More specifically, we construct a knowledge graph (KG) to discover candidates and mine relational paths, which are transformed into evidence cards that summarize rationales for each candidate POI. The frozen LLM then acts as a reasoning engine, generating recommendations from the KG-discovered candidate set based on the policy-optimized prompts. Experiments on three real-world datasets demonstrate that Prompt-as-Policy consistently outperforms state-of-the-art baselines, achieving average 7.7\\% relative improvements in Acc@1 for inactive users, while maintaining competitive performance on active users, without requiring model fine-tuning.",
            "primary_category": "cs.SI",
            "code_url": "null"
        },
        "2510.07910": {
            "title": "MMM: Quantum-Chemical Molecular Representation Learning for Combinatorial Drug Recommendation",
            "authors": "Chongmyung Kwon, Yujin Kim, Seoeun Park, Yunji Lee, Charmgil Hong",
            "first_author": "Chongmyung Kwon",
            "url": "http://arxiv.org/abs/2510.07910v1",
            "pdf_url": "http://arxiv.org/abs/2510.07910",
            "publish_date": "2025-10-09",
            "abstract": "Drug recommendation is an essential task in machine learning-based clinical decision support systems. However, the risk of drug-drug interactions (DDI) between co-prescribed medications remains a significant challenge. Previous studies have used graph neural networks (GNNs) to represent drug structures. Regardless, their simplified discrete forms cannot fully capture the molecular binding affinity and reactivity. Therefore, we propose Multimodal DDI Prediction with Molecular Electron Localization Function (ELF) Maps (MMM), a novel framework that integrates three-dimensional (3D) quantum-chemical information into drug representation learning. It generates 3D electron density maps using the ELF. To capture both therapeutic relevance and interaction risks, MMM combines ELF-derived features that encode global electronic properties with a bipartite graph encoder that models local substructure interactions. This design enables learning complementary characteristics of drug molecules. We evaluate MMM in the MIMIC-III dataset (250 drugs, 442 substructures), comparing it with several baseline models. In particular, a comparison with the GNN-based SafeDrug model demonstrates statistically significant improvements in the F1-score (p = 0.0387), Jaccard (p = 0.0112), and the DDI rate (p = 0.0386). These results demonstrate the potential of ELF-based 3D representations to enhance prediction accuracy and support safer combinatorial drug prescribing in clinical practice.",
            "primary_category": "cs.LG",
            "code_url": "null"
        },
        "2510.07784": {
            "title": "PLUM: Adapting Pre-trained Language Models for Industrial-scale Generative Recommendations",
            "authors": "Ruining He, Lukasz Heldt, Lichan Hong, Raghunandan Keshavan, Shifan Mao, Nikhil Mehta, Zhengyang Su, Alicia Tsai, Yueqi Wang, Shao-Chuan Wang, Xinyang Yi, Lexi Baugher, Baykal Cakici, Ed Chi, Cristos Goodrow, Ningren Han, He Ma, Romer Rosales, Abby Van Soest, Devansh Tandon, Su-Lin Wu, Weilong Yang, Yilin Zheng",
            "first_author": "Ruining He",
            "url": "http://arxiv.org/abs/2510.07784v1",
            "pdf_url": "http://arxiv.org/abs/2510.07784",
            "publish_date": "2025-10-09",
            "abstract": "Large Language Models (LLMs) pose a new paradigm of modeling and computation for information tasks. Recommendation systems are a critical application domain poised to benefit significantly from the sequence modeling capabilities and world knowledge inherent in these large models. In this paper, we introduce PLUM, a framework designed to adapt pre-trained LLMs for industry-scale recommendation tasks. PLUM consists of item tokenization using Semantic IDs, continued pre-training (CPT) on domain-specific data, and task-specific fine-tuning for recommendation objectives. For fine-tuning, we focus particularly on generative retrieval, where the model is directly trained to generate Semantic IDs of recommended items based on user context. We conduct comprehensive experiments on large-scale internal video recommendation datasets. Our results demonstrate that PLUM achieves substantial improvements for retrieval compared to a heavily-optimized production model built with large embedding tables. We also present a scaling study for the model's retrieval performance, our learnings about CPT, a few enhancements to Semantic IDs, along with an overview of the training and inference methods that enable launching this framework to billions of users in YouTube.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2510.07621": {
            "title": "Retentive Relevance: Capturing Long-Term User Value in Recommendation Systems",
            "authors": "Saeideh Bakhshi, Phuong Mai Nguyen, Robert Schiller, Tiantian Xu, Pawan Kodandapani, Andrew Levine, Cayman Simpson, Qifan Wang",
            "first_author": "Saeideh Bakhshi",
            "url": "http://arxiv.org/abs/2510.07621v1",
            "pdf_url": "http://arxiv.org/abs/2510.07621",
            "publish_date": "2025-10-08",
            "abstract": "Recommendation systems have traditionally relied on short-term engagement signals, such as clicks and likes, to personalize content. However, these signals are often noisy, sparse, and insufficient for capturing long-term user satisfaction and retention. We introduce Retentive Relevance, a novel content-level survey-based feedback measure that directly assesses users' intent to return to the platform for similar content. Unlike other survey measures that focus on immediate satisfaction, Retentive Relevance targets forward-looking behavioral intentions, capturing longer term user intentions and providing a stronger predictor of retention. We validate Retentive Relevance using psychometric methods, establishing its convergent, discriminant, and behavioral validity. Through large-scale offline modeling, we show that Retentive Relevance significantly outperforms both engagement signals and other survey measures in predicting next-day retention, especially for users with limited historical engagement. We develop a production-ready proxy model that integrates Retentive Relevance into the final stage of a multi-stage ranking system on a social media platform. Calibrated score adjustments based on this model yield substantial improvements in engagement, and retention, while reducing exposure to low-quality content, as demonstrated by large-scale A/B experiments. This work provides the first empirically validated framework linking content-level user perceptions to retention outcomes in production systems. We offer a scalable, user-centered solution that advances both platform growth and user experience. Our work has broad implications for responsible AI development.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2510.09435": {
            "title": "Cross-attention Secretly Performs Orthogonal Alignment in Recommendation Models",
            "authors": "Hyunin Lee, Yong Zhang, Hoang Vu Nguyen, Xiaoyi Liu, Namyong Park, Christopher Jung, Rong Jin, Yang Wang, Zhigang Wang, Somayeh Sojoudi, Xue Feng",
            "first_author": "Hyunin Lee",
            "url": "http://arxiv.org/abs/2510.09435v1",
            "pdf_url": "http://arxiv.org/abs/2510.09435",
            "publish_date": "2025-10-10",
            "abstract": "Cross-domain sequential recommendation (CDSR) aims to align heterogeneous user behavior sequences collected from different domains. While cross-attention is widely used to enhance alignment and improve recommendation performance, its underlying mechanism is not fully understood. Most researchers interpret cross-attention as residual alignment, where the output is generated by removing redundant and preserving non-redundant information from the query input by referencing another domain data which is input key and value. Beyond the prevailing view, we introduce Orthogonal Alignment, a phenomenon in which cross-attention discovers novel information that is not present in the query input, and further argue that those two contrasting alignment mechanisms can co-exist in recommendation models We find that when the query input and output of cross-attention are orthogonal, model performance improves over 300 experiments. Notably, Orthogonal Alignment emerges naturally, without any explicit orthogonality constraints. Our key insight is that Orthogonal Alignment emerges naturally because it improves scaling law. We show that baselines additionally incorporating cross-attention module outperform parameter-matched baselines, achieving a superior accuracy-per-model parameter. We hope these findings offer new directions for parameter-efficient scaling in multi-modal research.",
            "primary_category": "cs.LG",
            "code_url": "null"
        },
        "2510.09224": {
            "title": "Tag-Enriched Multi-Attention with Large Language Models for Cross-Domain Sequential Recommendation",
            "authors": "Wangyu Wu, Xuhang Chen, Zhenhong Chen, Jing-En Jiang, Kim-Fung Tsang, Xiaowei Huang, Fei Ma, Jimin Xiao",
            "first_author": "Wangyu Wu",
            "url": "http://arxiv.org/abs/2510.09224v2",
            "pdf_url": "http://arxiv.org/abs/2510.09224",
            "publish_date": "2025-10-10",
            "abstract": "Cross-Domain Sequential Recommendation (CDSR) plays a crucial role in modern consumer electronics and e-commerce platforms, where users interact with diverse services such as books, movies, and online retail products. These systems must accurately capture both domain-specific and cross-domain behavioral patterns to provide personalized and seamless consumer experiences. To address this challenge, we propose \\textbf{TEMA-LLM} (\\textit{Tag-Enriched Multi-Attention with Large Language Models}), a practical and effective framework that integrates \\textit{Large Language Models (LLMs)} for semantic tag generation and enrichment. Specifically, TEMA-LLM employs LLMs to assign domain-aware prompts and generate descriptive tags from item titles and descriptions. The resulting tag embeddings are fused with item identifiers as well as textual and visual features to construct enhanced item representations. A \\textit{Tag-Enriched Multi-Attention} mechanism is then introduced to jointly model user preferences within and across domains, enabling the system to capture complex and evolving consumer interests. Extensive experiments on four large-scale e-commerce datasets demonstrate that TEMA-LLM consistently outperforms state-of-the-art baselines, underscoring the benefits of LLM-based semantic tagging and multi-attention integration for consumer-facing recommendation systems. The proposed approach highlights the potential of LLMs to advance intelligent, user-centric services in the field of consumer electronics.",
            "primary_category": "cs.CV",
            "code_url": "null"
        },
        "2510.09167": {
            "title": "Hierarchical Semantic RL: Tackling the Problem of Dynamic Action Space for RL-based Recommendations",
            "authors": "Minmao Wang, Xingchen Liu, Shijie Yi, Likang Wu, Hongke Zhao, Fei Pan, Qingpeng Cai, Peng Jiang",
            "first_author": "Minmao Wang",
            "url": "http://arxiv.org/abs/2510.09167v1",
            "pdf_url": "http://arxiv.org/abs/2510.09167",
            "publish_date": "2025-10-10",
            "abstract": "Recommender Systems (RS) are fundamental to modern online services. While most existing approaches optimize for short-term engagement, recent work has begun to explore reinforcement learning (RL) to model long-term user value. However, these efforts face significant challenges due to the vast, dynamic action spaces inherent in recommendation, which hinder stable policy learning. To resolve this bottleneck, we introduce Hierarchical Semantic RL (HSRL), which reframes RL-based recommendation over a fixed Semantic Action Space (SAS). HSRL encodes items as Semantic IDs (SIDs) for policy learning, and maps SIDs back to their original items via a fixed, invertible lookup during execution. To align decision-making with SID generation, the Hierarchical Policy Network (HPN) operates in a coarse-to-fine manner, employing hierarchical residual state modeling to refine each level's context from the previous level's residual, thereby stabilizing training and reducing representation-decision mismatch. In parallel, a Multi-level Critic (MLC) provides token-level value estimates, enabling fine-grained credit assignment. Across public benchmarks and a large-scale production dataset from a leading Chinese short-video advertising platform, HSRL consistently surpasses state-of-the-art baselines. In online deployment over a seven-day A/B testing, it delivers an 18.421% CVR lift with only a 1.251% increase in cost, supporting HSRL as a scalable paradigm for RL-based recommendation. Our code is released at https://github.com/MinmaoWang/HSRL.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2510.09136": {
            "title": "Controlled Personalization in Legacy Media Online Services: A Case Study in News Recommendation",
            "authors": "Marlene Holzleitner, Stephan Leitner, Hanna Lind Jorgensen, Christoph Schmitz, Jacob Welander, Dietmar Jannach",
            "first_author": "Marlene Holzleitner",
            "url": "http://arxiv.org/abs/2510.09136v1",
            "pdf_url": "http://arxiv.org/abs/2510.09136",
            "publish_date": "2025-10-10",
            "abstract": "Personalized news recommendations have become a standard feature of large news aggregation services, optimizing user engagement through automated content selection. In contrast, legacy news media often approach personalization cautiously, striving to balance technological innovation with core editorial values. As a result, online platforms of traditional news outlets typically combine editorially curated content with algorithmically selected articles - a strategy we term controlled personalization. In this industry paper, we evaluate the effectiveness of controlled personalization through an A/B test conducted on the website of a major Norwegian legacy news organization. Our findings indicate that even a modest level of personalization yields substantial benefits. Specifically, we observe that users exposed to personalized content demonstrate higher click-through rates and reduced navigation effort, suggesting improved discovery of relevant content. Moreover, our analysis reveals that controlled personalization contributes to greater content diversity and catalog coverage and in addition reduces popularity bias. Overall, our results suggest that controlled personalization can successfully align user needs with editorial goals, offering a viable path for legacy media to adopt personalization technologies while upholding journalistic values.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2510.09129": {
            "title": "Generative Data Augmentation in Graph Contrastive Learning for Recommendation",
            "authors": "Yansong Wang, Qihui Lin, Junjie Huang, Tao Jia",
            "first_author": "Yansong Wang",
            "url": "http://arxiv.org/abs/2510.09129v1",
            "pdf_url": "http://arxiv.org/abs/2510.09129",
            "publish_date": "2025-10-10",
            "abstract": "Recommendation systems have become indispensable in various online platforms, from e-commerce to streaming services. A fundamental challenge in this domain is learning effective embeddings from sparse user-item interactions. While contrastive learning has recently emerged as a promising solution to this issue, generating augmented views for contrastive learning through most existing random data augmentation methods often leads to the alteration of original semantic information. In this paper, we propose a novel framework, GDA4Rec (Generative Data Augmentation in graph contrastive learning for Recommendation) to generate high-quality augmented views and provide robust self-supervised signals. Specifically, we employ a noise generation module that leverages deep generative models to approximate the distribution of original data for data augmentation. Additionally, GDA4Rec further extracts an item complement matrix to characterize the latent correlations between items and provide additional self-supervised signals. Lastly, a joint objective that integrates recommendation, data augmentation and contrastive learning is used to enforce the model to learn more effective and informative embeddings. Extensive experiments are conducted on three public datasets to demonstrate the superiority of the model. The code is available at: https://github.com/MrYansong/GDA4Rec.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2510.08626": {
            "title": "From What to Why: Thought-Space Recommendation with Small Language Models",
            "authors": "Prosenjit Biswas, Pervez Shaik, Abhinav Thorat, Ravi Kolla, Niranjan Pedanekar",
            "first_author": "Prosenjit Biswas",
            "url": "http://arxiv.org/abs/2510.08626v1",
            "pdf_url": "http://arxiv.org/abs/2510.08626",
            "publish_date": "2025-10-08",
            "abstract": "Large Language Models (LLMs) have advanced recommendation capabilities through enhanced reasoning, but pose significant challenges for real-world deployment due to high inference costs. Conversely, while Small Language Models (SLMs) offer an efficient alternative, their reasoning capabilities for recommendation remain underexplored. Existing systems often use natural language rationales merely as unsupervised descriptive text, failing to harness their full potential as learning signals. In this work our main idea is to create a common understanding of user and items across multiple domains called Thought Space with SLMs instead of using LLMs' distilled knowledge. To that end we propose PULSE (Preference Understanding by Latent Semantic Embeddings), a framework that treats SLM-generated rationales as director learning signals, supervising them with interaction histories to jointly model user actions (what) and their semantic drivers (why). Existing methods consider only interactions such as sequences and embeddings, whereas PULSE treats rationales as first-class signals, this novel design yields embeddings that are more robust and generalizable. Extensive experiments demonstrate that PULSE outperforms leading ID, Collaborative Filtering (CF), and LLM-based sequential recommendation models across multiple benchmark datasets. Furthermore, PULSE exhibits superior transferability in cross-domain recommendation and demonstrates strong performance on downstream tasks such as reasoning-oriented question answering. Our code is available \\href{https://anonymous.4open.science/r/Thinking_PULSE-0FC5/README.md}{here}.",
            "primary_category": "cs.CL",
            "code_url": "null"
        },
        "2510.11639": {
            "title": "OneRec-Think: In-Text Reasoning for Generative Recommendation",
            "authors": "Zhanyu Liu, Shiyao Wang, Xingmei Wang, Rongzhou Zhang, Jiaxin Deng, Honghui Bao, Jinghao Zhang, Wuchao Li, Pengfei Zheng, Xiangyu Wu, Yifei Hu, Qigen Hu, Xinchen Luo, Lejian Ren, Zixing Zhang, Qianqian Wang, Kuo Cai, Yunfan Wu, Hongtao Cheng, Zexuan Cheng, Lu Ren, Huanjie Wang, Yi Su, Ruiming Tang, Kun Gai, Guorui Zhou",
            "first_author": "Zhanyu Liu",
            "url": "http://arxiv.org/abs/2510.11639v1",
            "pdf_url": "http://arxiv.org/abs/2510.11639",
            "publish_date": "2025-10-13",
            "abstract": "The powerful generative capacity of Large Language Models (LLMs) has instigated a paradigm shift in recommendation. However, existing generative models (e.g., OneRec) operate as implicit predictors, critically lacking the capacity for explicit and controllable reasoning-a key advantage of LLMs. To bridge this gap, we propose OneRec-Think, a unified framework that seamlessly integrates dialogue, reasoning, and personalized recommendation. OneRec-Think incorporates: (1) Itemic Alignment: cross-modal Item-Textual Alignment for semantic grounding; (2) Reasoning Activation: Reasoning Scaffolding to activate LLM reasoning within the recommendation context; and (3) Reasoning Enhancement, where we design a recommendation-specific reward function that accounts for the multi-validity nature of user preferences. Experiments across public benchmarks show state-of-the-art performance. Moreover, our proposed \"Think-Ahead\" architecture enables effective industrial deployment on Kuaishou, achieving a 0.159\\% gain in APP Stay Time and validating the practical efficacy of the model's explicit reasoning capability.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2510.11472": {
            "title": "Differentiable Fast Top-K Selection for Large-Scale Recommendation",
            "authors": "Yanjie Zhu, Zhen Zhang, Yunli Wang, Zhiqiang Wang, Yu Li, Rufan Zhou, Shiyang Wen, Peng Jiang, Chenhao Lin, Jian Yang",
            "first_author": "Yanjie Zhu",
            "url": "http://arxiv.org/abs/2510.11472v1",
            "pdf_url": "http://arxiv.org/abs/2510.11472",
            "publish_date": "2025-10-13",
            "abstract": "Cascade ranking is a widely adopted paradigm in large-scale information retrieval systems for Top-K item selection. However, the Top-K operator is non-differentiable, hindering end-to-end training. Existing methods include Learning-to-Rank approaches (e.g., LambdaLoss), which optimize ranking metrics like NDCG and suffer from objective misalignment, and differentiable sorting-based methods (e.g., ARF, LCRON), which relax permutation matrices for direct Top-K optimization but introduce gradient conflicts through matrix aggregation. A promising alternative is to directly construct a differentiable approximation of the Top-K selection operator, bypassing the use of soft permutation matrices. However, even state-of-the-art differentiable Top-K operator (e.g., LapSum) require $O(n \\log n)$ complexity due to their dependence on sorting for solving the threshold. Thus, we propose DFTopK, a novel differentiable Top-K operator achieving optimal $O(n)$ time complexity. By relaxing normalization constraints, DFTopK admits a closed-form solution and avoids sorting. DFTopK also avoids the gradient conflicts inherent in differentiable sorting-based methods. We evaluate DFTopK on both the public benchmark RecFLow and an industrial system. Experimental results show that DFTopK significantly improves training efficiency while achieving superior performance, which enables us to scale up training samples more efficiently. In the online A/B test, DFTopK yielded a +1.77\\% revenue lift with the same computational budget compared to the baseline. To the best of our knowledge, this work is the first to introduce differentiable Top-K operators into recommendation systems and the first to achieve theoretically optimal linear-time complexity for Top-K selection. We have open-sourced our implementation to facilitate future research in both academia and industry.",
            "primary_category": "cs.LG",
            "code_url": "null"
        },
        "2510.11402": {
            "title": "On Inherited Popularity Bias in Cold-Start Item Recommendation",
            "authors": "Gregor Meehan, Johan Pauwels",
            "first_author": "Gregor Meehan",
            "url": "http://arxiv.org/abs/2510.11402v1",
            "pdf_url": "http://arxiv.org/abs/2510.11402",
            "publish_date": "2025-10-13",
            "abstract": "Collaborative filtering (CF) recommender systems struggle with making predictions on unseen, or 'cold', items. Systems designed to address this challenge are often trained with supervision from warm CF models in order to leverage collaborative and content information from the available interaction data. However, since they learn to replicate the behavior of CF methods, cold-start models may therefore also learn to imitate their predictive biases. In this paper, we show that cold-start systems can inherit popularity bias, a common cause of recommender system unfairness arising when CF models overfit to more popular items, thereby maximizing user-oriented accuracy but neglecting rarer items. We demonstrate that cold-start recommenders not only mirror the popularity biases of warm models, but are in fact affected more severely: because they cannot infer popularity from interaction data, they instead attempt to estimate it based solely on content features. This leads to significant over-prediction of certain cold items with similar content to popular warm items, even if their ground truth popularity is very low. Through experiments on three multimedia datasets, we analyze the impact of this behavior on three generative cold-start methods. We then describe a simple post-processing bias mitigation method that, by using embedding magnitude as a proxy for predicted popularity, can produce more balanced recommendations with limited harm to user-oriented cold-start accuracy.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2510.10955": {
            "title": "HatLLM: Hierarchical Attention Masking for Enhanced Collaborative Modeling in LLM-based Recommendation",
            "authors": "Yu Cui, Feng Liu, Jiawei Chen, Canghong Jin, Xingyu Lou, Changwang Zhang, Jun Wang, Yuegang Sun, Can Wang",
            "first_author": "Yu Cui",
            "url": "http://arxiv.org/abs/2510.10955v1",
            "pdf_url": "http://arxiv.org/abs/2510.10955",
            "publish_date": "2025-10-13",
            "abstract": "Recent years have witnessed a surge of research on leveraging large language models (LLMs) for sequential recommendation. LLMs have demonstrated remarkable potential in inferring users' nuanced preferences through fine-grained semantic reasoning. However, they also exhibit a notable limitation in effectively modeling collaborative signals, i.e., behavioral correlations inherent in users' historical interactions. Our empirical analysis further reveals that the attention mechanisms in LLMs tend to disproportionately focus on tokens within the same item, thereby impeding the capture of cross-item correlations.   To address this limitation, we propose a novel hierarchical attention masking strategy for LLM-based recommendation, termed HatLLM. Specifically, in shallow layers, HatLLM masks attention between tokens from different items, facilitating intra-item semantic understanding; in contrast, in deep layers, HatLLM masks attention within items, thereby compelling the model to capture cross-item correlations. This progressive, layer-wise approach enables LLMs to jointly model both token-level and item-level dependencies. Extensive experiments on three real-world datasets demonstrate that HatLLM achieves significant performance gains (9.13% on average) over existing LLM-based methods.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2510.10920": {
            "title": "Comparative Explanations via Counterfactual Reasoning in Recommendations",
            "authors": "Yi Yu, Zhenxing Hu",
            "first_author": "Yi Yu",
            "url": "http://arxiv.org/abs/2510.10920v1",
            "pdf_url": "http://arxiv.org/abs/2510.10920",
            "publish_date": "2025-10-13",
            "abstract": "Explainable recommendation through counterfactual reasoning seeks to identify the influential aspects of items in recommendations, which can then be used as explanations. However, state-of-the-art approaches, which aim to minimize changes in product aspects while reversing their recommended decisions according to an aggregated decision boundary score, often lead to factual inaccuracies in explanations. To solve this problem, in this work we propose a novel method of Comparative Counterfactual Explanations for Recommendation (CoCountER). CoCountER creates counterfactual data based on soft swap operations, enabling explanations for recommendations of arbitrary pairs of comparative items. Empirical experiments validate the effectiveness of our approach.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2510.10564": {
            "title": "Multi-Granularity Sequence Denoising with Weakly Supervised Signal for Sequential Recommendation",
            "authors": "Liang Li, Zhou Yang, Xiaofei Zhu",
            "first_author": "Liang Li",
            "url": "http://arxiv.org/abs/2510.10564v1",
            "pdf_url": "http://arxiv.org/abs/2510.10564",
            "publish_date": "2025-10-12",
            "abstract": "Sequential recommendation aims to predict the next item based on user interests in historical interaction sequences. Historical interaction sequences often contain irrelevant noisy items, which significantly hinders the performance of recommendation systems. Existing research employs unsupervised methods that indirectly identify item-granularity irrelevant noise by predicting the ground truth item. Since these methods lack explicit noise labels, they are prone to misidentify users' interested items as noise. Additionally, while these methods focus on removing item-granularity noise driven by the ground truth item, they overlook interest-granularity noise, limiting their ability to perform broader denoising based on user interests. To address these issues, we propose Multi-Granularity Sequence Denoising with Weakly Supervised Signal for Sequential Recommendation(MGSD-WSS). MGSD-WSS first introduces the Multiple Gaussian Kernel Perceptron module to map the original and enhance sequence into a common representation space and utilizes weakly supervised signals to accurately identify noisy items in the historical interaction sequence. Subsequently, it employs the item-granularity denoising module with noise-weighted contrastive learning to obtain denoised item representations. Then, it extracts target interest representations from the ground truth item and applies noise-weighted contrastive learning to obtain denoised interest representations. Finally, based on the denoised item and interest representations, MGSD-WSS predicts the next item. Extensive experiments on five datasets demonstrate that the proposed method significantly outperforms state-of-the-art sequence recommendation and denoising models. Our code is available at https://github.com/lalunex/MGSD-WSS.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2510.10556": {
            "title": "Self-Supervised Representation Learning with ID-Content Modality Alignment for Sequential Recommendation",
            "authors": "Donglin Zhou, Weike Pan, Zhong Ming",
            "first_author": "Donglin Zhou",
            "url": "http://arxiv.org/abs/2510.10556v2",
            "pdf_url": "http://arxiv.org/abs/2510.10556",
            "publish_date": "2025-10-12",
            "abstract": "Sequential recommendation (SR) models often capture user preferences based on the historically interacted item IDs, which usually obtain sub-optimal performance when the interaction history is limited. Content-based sequential recommendation has recently emerged as a promising direction that exploits items' textual and visual features to enhance preference learning. However, there are still three key challenges: (i) how to reduce the semantic gap between different content modality representations; (ii) how to jointly model user behavior preferences and content preferences; and (iii) how to design an effective training strategy to align ID representations and content representations. To address these challenges, we propose a novel model, self-supervised representation learning with ID-Content modality alignment, named SICSRec. Firstly, we propose a LLM-driven sample construction method and develop a supervised fine-tuning approach to align item-level modality representations. Secondly, we design a novel Transformer-based sequential model, where an ID-modality sequence encoder captures user behavior preferences, a content-modality sequence encoder learns user content preferences, and a mix-modality sequence decoder grasps the intrinsic relationship between these two types of preferences. Thirdly, we propose a two-step training strategy with a content-aware contrastive learning task to align modality representations and ID representations, which decouples the training process of content modality dependency and item collaborative dependency. Extensive experiments conducted on four public video streaming datasets demonstrate our SICSRec outperforms the state-of-the-art ID-modality sequential recommenders and content-modality sequential recommenders by 8.04% on NDCG@5 and 6.62% on NDCD@10 on average, respectively.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2510.10127": {
            "title": "Breaking the Likelihood Trap: Consistent Generative Recommendation with Graph-structured Model",
            "authors": "Qiya Yang, Xiaoxi Liang, Zeping Xiao, Yingjie Deng, Yalong Wang, Yongqi Liu, Han Li",
            "first_author": "Qiya Yang",
            "url": "http://arxiv.org/abs/2510.10127v1",
            "pdf_url": "http://arxiv.org/abs/2510.10127",
            "publish_date": "2025-10-11",
            "abstract": "Reranking, as the final stage of recommender systems, demands real-time inference, accuracy, and diversity. It plays a crucial role in determining the final exposure, directly influencing user experience. Recently, generative reranking has gained increasing attention for its strong ability to model complex dependencies among items. However, most existing methods suffer from the \"likelihood trap\", where high-likelihood sequences are often perceived as low-quality by humans. These models tend to repeatedly recommend a set of high-frequency items, resulting in list homogeneity, thereby limiting user engagement. In this work, we propose Consistent Graph-structured Generative Recommendation (Congrats), a novel generative reranking framework. To break the likelihood trap, we introduce a novel graph-structured decoder that can capture diverse sequences along multiple paths. This design not only expands the decoding space to promote diversity, but also improves prediction accuracy by implicit item dependencies derived from vertex transitions. Furthermore, we design a differentiable cascade system that incorporates an evaluator, enabling the model to learn directly from user preferences as the training objective. Extensive offline experiments validate the superior performance of Congrats over state-of-the-art reranking methods. Moreover, Congrats has been evaluated on a large-scale video-sharing app, Kuaishou, with over 300 million daily active users, demonstrating that our approach significantly improves both recommendation quality and diversity, validating our effectiveness in practical industrial environments.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2510.10109": {
            "title": "Integrating Structure-Aware Attention and Knowledge Graphs in Explainable Recommendation Systems",
            "authors": "Shuangquan Lyu, Ming Wang, Huajun Zhang, Jiasen Zheng, Junjiang Lin, Xiaoxuan Sun",
            "first_author": "Shuangquan Lyu",
            "url": "http://arxiv.org/abs/2510.10109v1",
            "pdf_url": "http://arxiv.org/abs/2510.10109",
            "publish_date": "2025-10-11",
            "abstract": "This paper designs and implements an explainable recommendation model that integrates knowledge graphs with structure-aware attention mechanisms. The model is built on graph neural networks and incorporates a multi-hop neighbor aggregation strategy. By integrating the structural information of knowledge graphs and dynamically assigning importance to different neighbors through an attention mechanism, the model enhances its ability to capture implicit preference relationships. In the proposed method, users and items are embedded into a unified graph structure. Multi-level semantic paths are constructed based on entities and relations in the knowledge graph to extract richer contextual information. During the rating prediction phase, recommendations are generated through the interaction between user and target item representations. The model is optimized using a binary cross-entropy loss function. Experiments conducted on the Amazon Books dataset validate the superior performance of the proposed model across various evaluation metrics. The model also shows good convergence and stability. These results further demonstrate the effectiveness and practicality of structure-aware attention mechanisms in knowledge graph-enhanced recommendation.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2510.10105": {
            "title": "Lighter-X: An Efficient and Plug-and-play Strategy for Graph-based Recommendation through Decoupled Propagation",
            "authors": "Yanping Zheng, Zhewei Wei, Frank de Hoog, Xu Chen, Hongteng Xu, Yuhang Ye, Jiadeng Huang",
            "first_author": "Yanping Zheng",
            "url": "http://arxiv.org/abs/2510.10105v1",
            "pdf_url": "http://arxiv.org/abs/2510.10105",
            "publish_date": "2025-10-11",
            "abstract": "Graph Neural Networks (GNNs) have demonstrated remarkable effectiveness in recommendation systems. However, conventional graph-based recommenders, such as LightGCN, require maintaining embeddings of size $d$ for each node, resulting in a parameter complexity of $\\mathcal{O}(n \\times d)$, where $n$ represents the total number of users and items. This scaling pattern poses significant challenges for deployment on large-scale graphs encountered in real-world applications. To address this scalability limitation, we propose \\textbf{Lighter-X}, an efficient and modular framework that can be seamlessly integrated with existing GNN-based recommender architectures. Our approach substantially reduces both parameter size and computational complexity while preserving the theoretical guarantees and empirical performance of the base models, thereby enabling practical deployment at scale. Specifically, we analyze the original structure and inherent redundancy in their parameters, identifying opportunities for optimization. Based on this insight, we propose an efficient compression scheme for the sparse adjacency structure and high-dimensional embedding matrices, achieving a parameter complexity of $\\mathcal{O}(h \\times d)$, where $h \\ll n$. Furthermore, the model is optimized through a decoupled framework, reducing computational complexity during the training process and enhancing scalability. Extensive experiments demonstrate that Lighter-X achieves comparable performance to baseline models with significantly fewer parameters. In particular, on large-scale interaction graphs with millions of edges, we are able to attain even better results with only 1\\% of the parameter over LightGCN.",
            "primary_category": "cs.LG",
            "code_url": "null"
        },
        "2510.09643": {
            "title": "Direct Routing Gradient (DRGrad): A Personalized Information Surgery for Multi-Task Learning (MTL) Recommendations",
            "authors": "Yuguang Liu, Yiyun Miao, Luyao Xia",
            "first_author": "Yuguang Liu",
            "url": "http://arxiv.org/abs/2510.09643v1",
            "pdf_url": "http://arxiv.org/abs/2510.09643",
            "publish_date": "2025-10-04",
            "abstract": "Multi-task learning (MTL) has emerged as a successful strategy in industrial-scale recommender systems, offering significant advantages such as capturing diverse users' interests and accurately detecting different behaviors like ``click\" or ``dwell time\". However, negative transfer and the seesaw phenomenon pose challenges to MTL models due to the complex and often contradictory task correlations in real-world recommendations. To address the problem while making better use of personalized information, we propose a personalized Direct Routing Gradient framework (DRGrad), which consists of three key components: router, updater and personalized gate network. DRGrad judges the stakes between tasks in the training process, which can leverage all valid gradients for the respective task to reduce conflicts. We evaluate the efficiency of DRGrad on complex MTL using a real-world recommendation dataset with 15 billion samples. The results show that DRGrad's superior performance over competing state-of-the-art MTL models, especially in terms of AUC (Area Under the Curve) metrics, indicating that it effectively manages task conflicts in multi-task learning environments without increasing model complexity, while also addressing the deficiencies in noise processing. Moreover, experiments on the public Census-income dataset and Synthetic dataset, have demonstrated the capability of DRGrad in judging and routing the stakes between tasks with varying degrees of correlation and personalization.",
            "primary_category": "cs.LG",
            "code_url": "null"
        },
        "2510.12325": {
            "title": "Causal Inspired Multi Modal Recommendation",
            "authors": "Jie Yang, Chenyang Gu, Zixuan Liu",
            "first_author": "Jie Yang",
            "url": "http://arxiv.org/abs/2510.12325v1",
            "pdf_url": "http://arxiv.org/abs/2510.12325",
            "publish_date": "2025-10-14",
            "abstract": "Multimodal recommender systems enhance personalized recommendations in e-commerce and online advertising by integrating visual, textual, and user-item interaction data. However, existing methods often overlook two critical biases: (i) modal confounding, where latent factors (e.g., brand style or product category) simultaneously drive multiple modalities and influence user preference, leading to spurious feature-preference associations; (ii) interaction bias, where genuine user preferences are mixed with noise from exposure effects and accidental clicks. To address these challenges, we propose a Causal-inspired multimodal Recommendation framework. Specifically, we introduce a dual-channel cross-modal diffusion module to identify hidden modal confounders, utilize back-door adjustment with hierarchical matching and vector-quantized codebooks to block confounding paths, and apply front-door adjustment combined with causal topology reconstruction to build a deconfounded causal subgraph. Extensive experiments on three real-world e-commerce datasets demonstrate that our method significantly outperforms state-of-the-art baselines while maintaining strong interpretability.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2510.12211": {
            "title": "Reinforced Preference Optimization for Recommendation",
            "authors": "Junfei Tan, Yuxin Chen, An Zhang, Junguang Jiang, Bin Liu, Ziru Xu, Han Zhu, Jian Xu, Bo Zheng, Xiang Wang",
            "first_author": "Junfei Tan",
            "url": "http://arxiv.org/abs/2510.12211v1",
            "pdf_url": "http://arxiv.org/abs/2510.12211",
            "publish_date": "2025-10-14",
            "abstract": "Recent breakthroughs in large language models (LLMs) have fundamentally shifted recommender systems from discriminative to generative paradigms, where user behavior modeling is achieved by generating target items conditioned on historical interactions. Yet current generative recommenders still suffer from two core limitations: the lack of high-quality negative modeling and the reliance on implicit rewards. Reinforcement learning with verifiable rewards (RLVR) offers a natural solution by enabling on-policy sampling of harder negatives and grounding optimization in explicit reward signals. However, applying RLVR to generative recommenders remains non-trivial. Its unique generation space often leads to invalid or repetitive items that undermine sampling efficiency, and ranking supervision is sparse since most items receive identical zero rewards. To address these challenges, we propose Reinforced Preference Optimization for Recommendation (ReRe), a reinforcement-based paradigm tailored to LLM-based recommenders, an important direction in generative recommendation. ReRe incorporates constrained beam search to improve sampling efficiency and diversify hard negatives, while augmenting rule-based accuracy rewards with auxiliary ranking rewards for finer-grained supervision. Extensive experiments on three real-world datasets demonstrate that ReRe consistently outperforms both traditional and LLM-based recommenders in ranking performance. Further analysis shows that ReRe not only enhances performance across both base and SFT-initialized models but also generalizes robustly across different backbone families and scales. Beyond empirical gains, we systematically investigate the design space of RLVR in recommendation across generation, sampling strategy, reward modeling, and optimization algorithm, offering insights for future research.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2510.12054": {
            "title": "MIARec: Mutual-influence-aware Heterogeneous Network Embedding for Scientific Paper Recommendation",
            "authors": "Wenjin Xie, Tao Jia",
            "first_author": "Wenjin Xie",
            "url": "http://arxiv.org/abs/2510.12054v1",
            "pdf_url": "http://arxiv.org/abs/2510.12054",
            "publish_date": "2025-10-14",
            "abstract": "With the rapid expansion of scientific literature, scholars increasingly demand precise and high-quality paper recommendations. Among various recommendation methodologies, graph-based approaches have garnered attention by effectively exploiting the structural characteristics inherent in scholarly networks. However, these methods often overlook the asymmetric academic influence that is prevalent in scholarly networks when learning graph representations. To address this limitation, this study proposes the Mutual-Influence-Aware Recommendation (MIARec) model, which employs a gravity-based approach to measure the mutual academic influence between scholars and incorporates this influence into the feature aggregation process during message propagation in graph representation learning. Additionally, the model utilizes a multi-channel aggregation method to capture both individual embeddings of distinct single relational sub-networks and their interdependent embeddings, thereby enabling a more comprehensive understanding of the heterogeneous scholarly network. Extensive experiments conducted on real-world datasets demonstrate that the MIARec model outperforms baseline models across three primary evaluation metrics, indicating its effectiveness in scientific paper recommendation tasks.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2510.13738": {
            "title": "HyMiRec: A Hybrid Multi-interest Learning Framework for LLM-based Sequential Recommendation",
            "authors": "Jingyi Zhou, Cheng Chen, Kai Zuo, Manjie Xu, Zhendong Fu, Yibo Chen, Xu Tang, Yao Hu",
            "first_author": "Jingyi Zhou",
            "url": "http://arxiv.org/abs/2510.13738v1",
            "pdf_url": "http://arxiv.org/abs/2510.13738",
            "publish_date": "2025-10-15",
            "abstract": "Large language models (LLMs) have recently demonstrated strong potential for sequential recommendation. However, current LLM-based approaches face critical limitations in modeling users' long-term and diverse interests. First, due to inference latency and feature fetching bandwidth constraints, existing methods typically truncate user behavior sequences to include only the most recent interactions, resulting in the loss of valuable long-range preference signals. Second, most current methods rely on next-item prediction with a single predicted embedding, overlooking the multifaceted nature of user interests and limiting recommendation diversity. To address these challenges, we propose HyMiRec, a hybrid multi-interest sequential recommendation framework, which leverages a lightweight recommender to extracts coarse interest embeddings from long user sequences and an LLM-based recommender to captures refined interest embeddings. To alleviate the overhead of fetching features, we introduce a residual codebook based on cosine similarity, enabling efficient compression and reuse of user history embeddings. To model the diverse preferences of users, we design a disentangled multi-interest learning module, which leverages multiple interest queries to learn disentangles multiple interest signals adaptively, allowing the model to capture different facets of user intent. Extensive experiments are conducted on both benchmark datasets and a collected industrial dataset, demonstrating our effectiveness over existing state-of-the-art methods. Furthermore, online A/B testing shows that HyMiRec brings consistent improvements in real-world recommendation systems.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2510.13371": {
            "title": "MADREC: A Multi-Aspect Driven LLM Agent for Explainable and Adaptive Recommendation",
            "authors": "Jiin Park, Misuk Kim",
            "first_author": "Jiin Park",
            "url": "http://arxiv.org/abs/2510.13371v1",
            "pdf_url": "http://arxiv.org/abs/2510.13371",
            "publish_date": "2025-10-15",
            "abstract": "Recent attempts to integrate large language models (LLMs) into recommender systems have gained momentum, but most remain limited to simple text generation or static prompt-based inference, failing to capture the complexity of user preferences and real-world interactions. This study proposes the Multi-Aspect Driven LLM Agent MADRec, an autonomous LLM-based recommender that constructs user and item profiles by unsupervised extraction of multi-aspect information from reviews and performs direct recommendation, sequential recommendation, and explanation generation. MADRec generates structured profiles via aspect-category-based summarization and applies Re-Ranking to construct high-density inputs. When the ground-truth item is missing from the output, the Self-Feedback mechanism dynamically adjusts the inference criteria. Experiments across multiple domains show that MADRec outperforms traditional and LLM-based baselines in both precision and explainability, with human evaluation further confirming the persuasiveness of the generated explanations.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2510.13359": {
            "title": "Improving Visual Recommendation on E-commerce Platforms Using Vision-Language Models",
            "authors": "Yuki Yada, Sho Akiyama, Ryo Watanabe, Yuta Ueno, Yusuke Shido, Andre Rusli",
            "first_author": "Yuki Yada",
            "url": "http://arxiv.org/abs/2510.13359v1",
            "pdf_url": "http://arxiv.org/abs/2510.13359",
            "publish_date": "2025-10-15",
            "abstract": "On large-scale e-commerce platforms with tens of millions of active monthly users, recommending visually similar products is essential for enabling users to efficiently discover items that align with their preferences. This study presents the application of a vision-language model (VLM) -- which has demonstrated strong performance in image recognition and image-text retrieval tasks -- to product recommendations on Mercari, a major consumer-to-consumer marketplace used by more than 20 million monthly users in Japan. Specifically, we fine-tuned SigLIP, a VLM employing a sigmoid-based contrastive loss, using one million product image-title pairs from Mercari collected over a three-month period, and developed an image encoder for generating item embeddings used in the recommendation system. Our evaluation comprised an offline analysis of historical interaction logs and an online A/B test in a production environment. In offline analysis, the model achieved a 9.1% improvement in nDCG@5 compared with the baseline. In the online A/B test, the click-through rate improved by 50% whereas the conversion rate improved by 14% compared with the existing model. These results demonstrate the effectiveness of VLM-based encoders for e-commerce product recommendations and provide practical insights into the development of visual similarity-based recommendation systems.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2510.13229": {
            "title": "Beyond Static LLM Policies: Imitation-Enhanced Reinforcement Learning for Recommendation",
            "authors": "Yi Zhang, Lili Xie, Ruihong Qiu, Jiajun Liu, Sen Wang",
            "first_author": "Yi Zhang",
            "url": "http://arxiv.org/abs/2510.13229v1",
            "pdf_url": "http://arxiv.org/abs/2510.13229",
            "publish_date": "2025-10-15",
            "abstract": "Recommender systems (RecSys) have become critical tools for enhancing user engagement by delivering personalized content across diverse digital platforms. Recent advancements in large language models (LLMs) demonstrate significant potential for improving RecSys, primarily due to their exceptional generalization capabilities and sophisticated contextual understanding, which facilitate the generation of flexible and interpretable recommendations. However, the direct deployment of LLMs as primary recommendation policies presents notable challenges, including persistent latency issues stemming from frequent API calls and inherent model limitations such as hallucinations and biases. To address these issues, this paper proposes a novel offline reinforcement learning (RL) framework that leverages imitation learning from LLM-generated trajectories. Specifically, inverse reinforcement learning is employed to extract robust reward models from LLM demonstrations. This approach negates the need for LLM fine-tuning, thereby substantially reducing computational overhead. Simultaneously, the RL policy is guided by the cumulative rewards derived from these demonstrations, effectively transferring the semantic insights captured by the LLM. Comprehensive experiments conducted on two benchmark datasets validate the effectiveness of the proposed method, demonstrating superior performance when compared against state-of-the-art RL-based and in-context learning baselines. The code can be found at https://github.com/ArronDZhang/IL-Rec.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2510.12816": {
            "title": "Maximum In-Support Return Modeling for Dynamic Recommendation with Language Model Prior",
            "authors": "Xiaocong Chen, Siyu Wang, Lina Yao",
            "first_author": "Xiaocong Chen",
            "url": "http://arxiv.org/abs/2510.12816v1",
            "pdf_url": "http://arxiv.org/abs/2510.12816",
            "publish_date": "2025-10-09",
            "abstract": "Reinforcement Learning-based recommender systems (RLRS) offer an effective way to handle sequential recommendation tasks but often face difficulties in real-world settings, where user feedback data can be sub-optimal or sparse. In this paper, we introduce MDT4Rec, an offline RLRS framework that builds on the Decision Transformer (DT) to address two major challenges: learning from sub-optimal histories and representing complex user-item interactions. First, MDT4Rec shifts the trajectory stitching procedure from the training phase to action inference, allowing the system to shorten its historical context when necessary and thereby ignore negative or unsuccessful past experiences. Second, MDT4Rec initializes DT with a pre-trained large language model (LLM) for knowledge transfer, replaces linear embedding layers with Multi-Layer Perceptrons (MLPs) for more flexible representations, and employs Low-Rank Adaptation (LoRA) to efficiently fine-tune only a small subset of parameters. We evaluate MDT4Rec on five public datasets and in an online simulation environment, demonstrating that it outperforms existing methods.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2510.12815": {
            "title": "Energy-Guided Diffusion Sampling for Long-Term User Behavior Prediction in Reinforcement Learning-based Recommendation",
            "authors": "Xiaocong Chen, Siyu Wang, Lina Yao",
            "first_author": "Xiaocong Chen",
            "url": "http://arxiv.org/abs/2510.12815v1",
            "pdf_url": "http://arxiv.org/abs/2510.12815",
            "publish_date": "2025-10-09",
            "abstract": "Reinforcement learning-based recommender systems (RL4RS) have gained attention for their ability to adapt to dynamic user preferences. However, these systems face challenges, particularly in offline settings, where data inefficiency and reliance on pre-collected trajectories limit their broader applicability. While offline reinforcement learning methods leverage extensive datasets to address these issues, they often struggle with noisy data and fail to capture long-term user preferences, resulting in suboptimal recommendation policies. To overcome these limitations, we propose Diffusion-enhanced Actor-Critic for Offline RL4RS (DAC4Rec), a novel framework that integrates diffusion processes with reinforcement learning to model complex user preferences more effectively. DAC4Rec leverages the denoising capabilities of diffusion models to enhance the robustness of offline RL algorithms and incorporates a Q-value-guided policy optimization strategy to better handle suboptimal trajectories. Additionally, we introduce an energy-based sampling strategy to reduce randomness during recommendation generation, ensuring more targeted and reliable outcomes. We validate the effectiveness of DAC4Rec through extensive experiments on six real-world offline datasets and in an online simulation environment, demonstrating its ability to optimize long-term user preferences. Furthermore, we show that the proposed diffusion policy can be seamlessly integrated into other commonly used RL algorithms in RL4RS, highlighting its versatility and wide applicability.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2510.14641": {
            "title": "Causality Enhancement for Cross-Domain Recommendation",
            "authors": "Zhibo Wu, Yunfan Wu, Lin Jiang, Ping Yang, Yao Hu",
            "first_author": "Zhibo Wu",
            "url": "http://arxiv.org/abs/2510.14641v1",
            "pdf_url": "http://arxiv.org/abs/2510.14641",
            "publish_date": "2025-10-16",
            "abstract": "Cross-domain recommendation forms a crucial component in recommendation systems. It leverages auxiliary information through source domain tasks or features to enhance target domain recommendations. However, incorporating inconsistent source domain tasks may result in insufficient cross-domain modeling or negative transfer. While incorporating source domain features without considering the underlying causal relationships may limit their contribution to final predictions. Thus, a natural idea is to directly train a cross-domain representation on a causality-labeled dataset from the source to target domain. Yet this direction has been rarely explored, as identifying unbiased real causal labels is highly challenging in real-world scenarios. In this work, we attempt to take a first step in this direction by proposing a causality-enhanced framework, named CE-CDR. Specifically, we first reformulate the cross-domain recommendation as a causal graph for principled guidance. We then construct a causality-aware dataset heuristically. Subsequently, we derive a theoretically unbiased Partial Label Causal Loss to generalize beyond the biased causality-aware dataset to unseen cross-domain patterns, yielding an enriched cross-domain representation, which is then fed into the target model to enhance target-domain recommendations. Theoretical and empirical analyses, as well as extensive experiments, demonstrate the rationality and effectiveness of CE-CDR and its general applicability as a model-agnostic plugin. Moreover, it has been deployed in production since April 2025, showing its practical value in real-world applications.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2510.14629": {
            "title": "MR.Rec: Synergizing Memory and Reasoning for Personalized Recommendation Assistant with LLMs",
            "authors": "Jiani Huang, Xingchen Zou, Lianghao Xia, Qing Li",
            "first_author": "Jiani Huang",
            "url": "http://arxiv.org/abs/2510.14629v1",
            "pdf_url": "http://arxiv.org/abs/2510.14629",
            "publish_date": "2025-10-16",
            "abstract": "The application of Large Language Models (LLMs) in recommender systems faces key challenges in delivering deep personalization and intelligent reasoning, especially for interactive scenarios. Current methods are often constrained by limited context windows and single-turn reasoning, hindering their ability to capture dynamic user preferences and proactively reason over recommendation contexts. To address these limitations, we propose MR.Rec, a novel framework that synergizes memory and reasoning for LLM-based recommendations. To achieve personalization, we develop a comprehensive Retrieval-Augmented Generation (RAG) system that efficiently indexes and retrieves relevant external memory to enhance LLM personalization capabilities. Furthermore, to enable the synergy between memory and reasoning, our RAG system goes beyond conventional query-based retrieval by integrating reasoning enhanced memory retrieval. Finally, we design a reinforcement learning framework that trains the LLM to autonomously learn effective strategies for both memory utilization and reasoning refinement. By combining dynamic memory retrieval with adaptive reasoning, this approach ensures more accurate, context-aware, and highly personalized recommendations. Extensive experiments demonstrate that MR.Rec significantly outperforms state-of-the-art baselines across multiple metrics, validating its efficacy in delivering intelligent and personalized recommendations. We will release code and data upon paper notification.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2510.14626": {
            "title": "GemiRec: Interest Quantization and Generation for Multi-Interest Recommendation",
            "authors": "Zhibo Wu, Yunfan Wu, Quan Liu, Lin Jiang, Ping Yang, Yao Hu",
            "first_author": "Zhibo Wu",
            "url": "http://arxiv.org/abs/2510.14626v1",
            "pdf_url": "http://arxiv.org/abs/2510.14626",
            "publish_date": "2025-10-16",
            "abstract": "Multi-interest recommendation has gained attention, especially in industrial retrieval stage. Unlike classical dual-tower methods, it generates multiple user representations instead of a single one to model comprehensive user interests. However, prior studies have identified two underlying limitations: the first is interest collapse, where multiple representations homogenize. The second is insufficient modeling of interest evolution, as they struggle to capture latent interests absent from a user's historical behavior. We begin with a thorough review of existing works in tackling these limitations. Then, we attempt to tackle these limitations from a new perspective. Specifically, we propose a framework-level refinement for multi-interest recommendation, named GemiRec. The proposed framework leverages interest quantization to enforce a structural interest separation and interest generation to learn the evolving dynamics of user interests explicitly. It comprises three modules: (a) Interest Dictionary Maintenance Module (IDMM) maintains a shared quantized interest dictionary. (b) Multi-Interest Posterior Distribution Module (MIPDM) employs a generative model to capture the distribution of user future interests. (c) Multi-Interest Retrieval Module (MIRM) retrieves items using multiple user-interest representations. Both theoretical and empirical analyses, as well as extensive experiments, demonstrate its advantages and effectiveness. Moreover, it has been deployed in production since March 2025, showing its practical value in industrial applications.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2510.14257": {
            "title": "Synergistic Integration and Discrepancy Resolution of Contextualized Knowledge for Personalized Recommendation",
            "authors": "Lingyu Mu, Hao Deng, Haibo Xing, Kaican Lin, Zhitong Zhu, Yu Zhang, Xiaoyi Zeng, Zhengxiao Liu, Zheng Lin, Jinxin Hu",
            "first_author": "Lingyu Mu",
            "url": "http://arxiv.org/abs/2510.14257v1",
            "pdf_url": "http://arxiv.org/abs/2510.14257",
            "publish_date": "2025-10-16",
            "abstract": "The integration of large language models (LLMs) into recommendation systems has revealed promising potential through their capacity to extract world knowledge for enhanced reasoning capabilities. However, current methodologies that adopt static schema-based prompting mechanisms encounter significant limitations: (1) they employ universal template structures that neglect the multi-faceted nature of user preference diversity; (2) they implement superficial alignment between semantic knowledge representations and behavioral feature spaces without achieving comprehensive latent space integration. To address these challenges, we introduce CoCo, an end-to-end framework that dynamically constructs user-specific contextual knowledge embeddings through a dual-mechanism approach. Our method realizes profound integration of semantic and behavioral latent dimensions via adaptive knowledge fusion and contradiction resolution modules. Experimental evaluations across diverse benchmark datasets and an enterprise-level e-commerce platform demonstrate CoCo's superiority, achieving a maximum 8.58% improvement over seven cutting-edge methods in recommendation accuracy. The framework's deployment on a production advertising system resulted in a 1.91% sales growth, validating its practical effectiveness. With its modular design and model-agnostic architecture, CoCo provides a versatile solution for next-generation recommendation systems requiring both knowledge-enhanced reasoning and personalized adaptation.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2510.15647": {
            "title": "Enhance Large Language Models as Recommendation Systems with Collaborative Filtering",
            "authors": "Zhisheng Yang, Xiaofei Xu, Ke Deng, Li Li",
            "first_author": "Zhisheng Yang",
            "url": "http://arxiv.org/abs/2510.15647v1",
            "pdf_url": "http://arxiv.org/abs/2510.15647",
            "publish_date": "2025-10-17",
            "abstract": "As powerful tools in Natural Language Processing (NLP), Large Language Models (LLMs) have been leveraged for crafting recommendations to achieve precise alignment with user preferences and elevate the quality of the recommendations. The existing approaches implement both non-tuning and tuning strategies. Compared to following the tuning strategy, the approaches following the non-tuning strategy avoid the relatively costly, time-consuming, and expertise-requiring process of further training pre-trained LLMs on task-specific datasets, but they suffer the issue of not having the task-specific business or local enterprise knowledge. To the best of our knowledge, none of the existing approaches following the non-tuning strategy explicitly integrates collaborative filtering, one of the most successful recommendation techniques. This study aims to fill the gap by proposing critique-based LLMs as recommendation systems (Critic-LLM-RS). For our purpose, we train a separate machine-learning model called Critic that implements collaborative filtering for recommendations by learning from the interactions between many users and items. The Critic provides critiques to LLMs to significantly refine the recommendations. Extensive experiments have verified the effectiveness of Critic-LLM-RS on real datasets.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2510.15286": {
            "title": "MTmixAtt: Integrating Mixture-of-Experts with Multi-Mix Attention for Large-Scale Recommendation",
            "authors": "Xianyang Qi, Yuan Tian, Zhaoyu Hu, Zhirui Kuai, Chang Liu, Hongxiang Lin, Lei Wang",
            "first_author": "Xianyang Qi",
            "url": "http://arxiv.org/abs/2510.15286v1",
            "pdf_url": "http://arxiv.org/abs/2510.15286",
            "publish_date": "2025-10-17",
            "abstract": "Industrial recommender systems critically depend on high-quality ranking models. However, traditional pipelines still rely on manual feature engineering and scenario-specific architectures, which hinder cross-scenario transfer and large-scale deployment. To address these challenges, we propose \\textbf{MTmixAtt}, a unified Mixture-of-Experts (MoE) architecture with Multi-Mix Attention, designed for large-scale recommendation tasks. MTmixAtt integrates two key components. The \\textbf{AutoToken} module automatically clusters heterogeneous features into semantically coherent tokens, removing the need for human-defined feature groups. The \\textbf{MTmixAttBlock} module enables efficient token interaction via a learnable mixing matrix, shared dense experts, and scenario-aware sparse experts, capturing both global patterns and scenario-specific behaviors within a single framework. Extensive experiments on the industrial TRec dataset from Meituan demonstrate that MTmixAtt consistently outperforms state-of-the-art baselines including Transformer-based models, WuKong, HiFormer, MLP-Mixer, and RankMixer. At comparable parameter scales, MTmixAtt achieves superior CTR and CTCVR metrics; scaling to MTmixAtt-1B yields further monotonic gains. Large-scale online A/B tests validate the real-world impact: in the \\textit{Homepage} scenario, MTmixAtt increases Payment PV by \\textbf{+3.62\\%} and Actual Payment GTV by \\textbf{+2.54\\%}. Overall, MTmixAtt provides a unified and scalable solution for modeling arbitrary heterogeneous features across scenarios, significantly improving both user experience and commercial outcomes.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2510.16972": {
            "title": "Preference Measurement Error, Concentration in Recommendation Systems, and Persuasion",
            "authors": "Andreas Haupt",
            "first_author": "Andreas Haupt",
            "url": "http://arxiv.org/abs/2510.16972v1",
            "pdf_url": "http://arxiv.org/abs/2510.16972",
            "publish_date": "2025-10-19",
            "abstract": "Algorithmic recommendation based on noisy preference measurement is prevalent in recommendation systems. This paper discusses the consequences of such recommendation on market concentration and inequality. Binary types denoting a statistical majority and minority are noisily revealed through a statistical experiment. The achievable utilities and recommendation shares for the two groups can be analyzed as a Bayesian Persuasion problem. While under arbitrary noise structures, effects on concentration compared to a full-information market are ambiguous, under symmetric noise, concentration increases and consumer welfare becomes more unequal. We define symmetric statistical experiments and analyze persuasion under a restriction to such experiments, which may be of independent interest.",
            "primary_category": "econ.TH",
            "code_url": "null"
        },
        "2510.16804": {
            "title": "The Layout Is the Model: On Action-Item Coupling in Generative Recommendation",
            "authors": "Xiaokai Wei, Jiajun Wu, Daiyao Yi, Reza Shirkavand, Michelle Gong",
            "first_author": "Xiaokai Wei",
            "url": "http://arxiv.org/abs/2510.16804v1",
            "pdf_url": "http://arxiv.org/abs/2510.16804",
            "publish_date": "2025-10-19",
            "abstract": "Generative Recommendation (GR) models treat a user's interaction history as a sequence to be autoregressively predicted. When both items and actions (e.g., watch time, purchase, comment) are modeled, the layout-the ordering and visibility of item/action tokens-critically determines what information the model can use and how it generalizes. We present a unified study of token layouts for GR grounded in first principles: (P1) maximize item/action signal in both input/output space, (P2) preserve the conditioning relationship \"action given item\" and (P3) no information leakage.   While interleaved layout (where item and action occupy separate tokens) naturally satisfies these principles, it also bloats sequence length with larger training/inference cost. On the non-interleaved front, we design a novel and effective approach, Lagged Action Conditioning (LAC), which appears strange on the surface but aligns well with the design principles to yield strong accuracy. Comprehensive experiments on public datasets and large-scale production logs evaluate different layout options and empirically verifies the design principles. Our proposed non-interleaved method, LAC, achieves competitive or superior quality at substantially lower FLOPs than interleaving. Our findings offer actionable guidance for assembling GR systems that are both accurate and efficient.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2510.16597": {
            "title": "FRONTIER-RevRec: A Large-scale Dataset for Reviewer Recommendation",
            "authors": "Qiyao Peng, Chen Wang, Yinghui Wang, Hongtao Liu, Xuan Guo, Wenjun Wang",
            "first_author": "Qiyao Peng",
            "url": "http://arxiv.org/abs/2510.16597v1",
            "pdf_url": "http://arxiv.org/abs/2510.16597",
            "publish_date": "2025-10-18",
            "abstract": "Reviewer recommendation is a critical task for enhancing the efficiency of academic publishing workflows. However, research in this area has been persistently hindered by the lack of high-quality benchmark datasets, which are often limited in scale, disciplinary scope, and comparative analyses of different methodologies. To address this gap, we introduce FRONTIER-RevRec, a large-scale dataset constructed from authentic peer review records (2007-2025) from the Frontiers open-access publishing platform https://www.frontiersin.org/. The dataset contains 177941 distinct reviewers and 478379 papers across 209 journals spanning multiple disciplines including clinical medicine, biology, psychology, engineering, and social sciences. Our comprehensive evaluation on this dataset reveals that content-based methods significantly outperform collaborative filtering. This finding is explained by our structural analysis, which uncovers fundamental differences between academic recommendation and commercial domains. Notably, approaches leveraging language models are particularly effective at capturing the semantic alignment between a paper's content and a reviewer's expertise. Furthermore, our experiments identify optimal aggregation strategies to enhance the recommendation pipeline. FRONTIER-RevRec is intended to serve as a comprehensive benchmark to advance research in reviewer recommendation and facilitate the development of more effective academic peer review systems. The FRONTIER-RevRec dataset is available at: https://anonymous.4open.science/r/FRONTIER-RevRec-5D05.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2510.15993": {
            "title": "Aligning Language Models with Investor and Market Behavior for Financial Recommendations",
            "authors": "Fernando Spadea, Oshani Seneviratne",
            "first_author": "Fernando Spadea",
            "url": "http://arxiv.org/abs/2510.15993v1",
            "pdf_url": "http://arxiv.org/abs/2510.15993",
            "publish_date": "2025-10-14",
            "abstract": "Most financial recommendation systems often fail to account for key behavioral and regulatory factors, leading to advice that is misaligned with user preferences, difficult to interpret, or unlikely to be followed. We present FLARKO (Financial Language-model for Asset Recommendation with Knowledge-graph Optimization), a novel framework that integrates Large Language Models (LLMs), Knowledge Graphs (KGs), and Kahneman-Tversky Optimization (KTO) to generate asset recommendations that are both profitable and behaviorally aligned. FLARKO encodes users' transaction histories and asset trends as structured KGs, providing interpretable and controllable context for the LLM. To demonstrate the adaptability of our approach, we develop and evaluate both a centralized architecture (CenFLARKO) and a federated variant (FedFLARKO). To our knowledge, this is the first demonstration of combining KTO for fine-tuning of LLMs for financial asset recommendation. We also present the first use of structured KGs to ground LLM reasoning over behavioral financial data in a federated learning (FL) setting. Evaluated on the FAR-Trans dataset, FLARKO consistently outperforms state-of-the-art recommendation baselines on behavioral alignment and joint profitability, while remaining interpretable and resource-efficient.",
            "primary_category": "q-fin.PM",
            "code_url": "null"
        },
        "2510.18364": {
            "title": "Evaluating LLM-Based Mobile App Recommendations: An Empirical Study",
            "authors": "Quim Motger, Xavier Franch, Vincenzo Gervasi, Jordi Marco",
            "first_author": "Quim Motger",
            "url": "http://arxiv.org/abs/2510.18364v1",
            "pdf_url": "http://arxiv.org/abs/2510.18364",
            "publish_date": "2025-10-21",
            "abstract": "Large Language Models (LLMs) are increasingly used to recommend mobile applications through natural language prompts, offering a flexible alternative to keyword-based app store search. Yet, the reasoning behind these recommendations remains opaque, raising questions about their consistency, explainability, and alignment with traditional App Store Optimization (ASO) metrics. In this paper, we present an empirical analysis of how widely-used general purpose LLMs generate, justify, and rank mobile app recommendations. Our contributions are: (i) a taxonomy of 16 generalizable ranking criteria elicited from LLM outputs; (ii) a systematic evaluation framework to analyse recommendation consistency and responsiveness to explicit ranking instructions; and (iii) a replication package to support reproducibility and future research on AI-based recommendation systems. Our findings reveal that LLMs rely on a broad yet fragmented set of ranking criteria, only partially aligned with standard ASO metrics. While top-ranked apps tend to be consistent across runs, variability increases with ranking depth and search specificity. LLMs exhibit varying sensitivity to explicit ranking instructions - ranging from substantial adaptations to near-identical outputs - highlighting their complex reasoning dynamics in conversational app discovery. Our results aim to support end-users, app developers, and recommender-systems researchers in navigating the emerging landscape of conversational app discovery.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2510.18277": {
            "title": "Enhancing Hotel Recommendations with AI: LLM-Based Review Summarization and Query-Driven Insights",
            "authors": "Nikolaos Belibasakis, Anastasios Giannaros, Ioanna Giannoukou, Spyros Sioutas",
            "first_author": "Nikolaos Belibasakis",
            "url": "http://arxiv.org/abs/2510.18277v1",
            "pdf_url": "http://arxiv.org/abs/2510.18277",
            "publish_date": "2025-10-21",
            "abstract": "The increasing number of data a booking platform such as Booking.com and AirBnB offers make it challenging for interested parties to browse through the available accommodations and analyze reviews in an efficient way. Efforts have been made from the booking platform providers to utilize recommender systems in an effort to enable the user to filter the results by factors such as stars, amenities, cost but most valuable insights can be provided by the unstructured text-based reviews. Going through these reviews one-by-one requires a substantial amount of time to be devoted while a respectable percentage of the reviews won't provide to the user what they are actually looking for.   This research publication explores how Large Language Models (LLMs) can enhance short rental apartments recommendations by summarizing and mining key insights from user reviews. The web application presented in this paper, named \"instaGuide\", automates the procedure of isolating the text-based user reviews from a property on the Booking.com platform, synthesizing the summary of the reviews, and enabling the user to query specific aspects of the property in an effort to gain feedback on their personal questions/criteria.   During the development of the instaGuide tool, numerous LLM models were evaluated based on accuracy, cost, and response quality. The results suggest that the LLM-powered summarization reduces significantly the amount of time the users need to devote on their search for the right short rental apartment, improving the overall decision-making procedure.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2510.19279": {
            "title": "Code Sharing in Healthcare Research: A Practical Guide and Recommendations for Good Practice",
            "authors": "Lukas Hughes-Noehrer, Matthew J Parkes, Andrew Stewart, Anthony J Wilson, Gary S Collins, Richard D Riley, Maya Mathur, Matthew P Fox, Nazrul Islam, Paul N Zivich, Timothy J Feeney",
            "first_author": "Lukas Hughes-Noehrer",
            "url": "http://arxiv.org/abs/2510.19279v1",
            "pdf_url": "http://arxiv.org/abs/2510.19279",
            "publish_date": "2025-10-22",
            "abstract": "As computational analysis becomes increasingly more complex in health research, transparent sharing of analytical code is vital for reproducibility and trust. This practical guide, aligned to open science practices, outlines actionable recommendations for code sharing in healthcare research. Emphasising the FAIR (Findable, Accessible, Interoperable, Reusable) principles, the authors address common barriers and provide clear guidance to help make code more robust, reusable, and scrutinised as part of the scientific record. This supports better science and more reliable evidence for computationally-driven practice and helps to adhere to new standards and guidelines of codesharing mandated by publishers and funding bodies.",
            "primary_category": "cs.CY",
            "code_url": "null"
        },
        "2510.19014": {
            "title": "Prior-informed optimization of treatment recommendation via bandit algorithms trained on large language model-processed historical records",
            "authors": "Saman Nessari, Ali Bozorgi-Amiri",
            "first_author": "Saman Nessari",
            "url": "http://arxiv.org/abs/2510.19014v1",
            "pdf_url": "http://arxiv.org/abs/2510.19014",
            "publish_date": "2025-10-21",
            "abstract": "Current medical practice depends on standardized treatment frameworks and empirical methodologies that neglect individual patient variations, leading to suboptimal health outcomes. We develop a comprehensive system integrating Large Language Models (LLMs), Conditional Tabular Generative Adversarial Networks (CTGAN), T-learner counterfactual models, and contextual bandit approaches to provide customized, data-informed clinical recommendations. The approach utilizes LLMs to process unstructured medical narratives into structured datasets (93.2% accuracy), uses CTGANs to produce realistic synthetic patient data (55% accuracy via two-sample verification), deploys T-learners to forecast patient-specific treatment responses (84.3% accuracy), and integrates prior-informed contextual bandits to enhance online therapeutic selection by effectively balancing exploration of new possibilities with exploitation of existing knowledge. Testing on stage III colon cancer datasets revealed that our KernelUCB approach obtained 0.60-0.61 average reward scores across 5,000 rounds, exceeding other reference methods. This comprehensive system overcomes cold-start limitations in online learning environments, improves computational effectiveness, and constitutes notable progress toward individualized medicine adapted to specific patient characteristics.",
            "primary_category": "cs.LG",
            "code_url": "null"
        },
        "2510.18902": {
            "title": "Evaluating LLMs for Career Guidance: Comparative Analysis of Computing Competency Recommendations Across Ten African Countries",
            "authors": "Precious Eze, Stephanie Lunn, Bruk Berhane",
            "first_author": "Precious Eze",
            "url": "http://arxiv.org/abs/2510.18902v1",
            "pdf_url": "http://arxiv.org/abs/2510.18902",
            "publish_date": "2025-10-20",
            "abstract": "Employers increasingly expect graduates to utilize large language models (LLMs) in the workplace, yet the competencies needed for computing roles across Africa remain unclear given varying national contexts. This study examined how six LLMs, namely ChatGPT 4, DeepSeek, Gemini, Claude 3.5, Llama 3, and Mistral AI, describe entry-level computing career expectations across ten African countries. Using the Computing Curricula 2020 framework and drawing on Digital Colonialism Theory and Ubuntu Philosophy, we analyzed 60 LLM responses to standardized prompts. Technical skills such as cloud computing and programming appeared consistently, but notable differences emerged in how models addressed non-technical competencies, particularly ethics and responsible AI use. Models varied considerably in recognizing country-specific factors, including local technology ecosystems, language requirements, and national policies. Open-source models demonstrated stronger contextual awareness and a better balance between technical and professional skills, earning top scores in nine of ten countries. Still, all models struggled with cultural sensitivity and infrastructure considerations, averaging only 35.4% contextual awareness. This first broad comparison of LLM career guidance for African computing students uncovers entrenched infrastructure assumptions and Western-centric biases, creating gaps between technical recommendations and local needs. The strong performance of cost-effective open-source models (Llama: 4.47/5; DeepSeek: 4.25/5) compared to proprietary alternatives (ChatGPT 4: 3.90/5; Claude: 3.46/5) challenges assumptions about AI tool quality in resource-constrained settings. Our findings highlight how computing competency requirements vary widely across Africa and underscore the need for decolonial approaches to AI in education that emphasize contextual relevance",
            "primary_category": "cs.CY",
            "code_url": "null"
        },
        "2510.20815": {
            "title": "Generative Reasoning Recommendation via LLMs",
            "authors": "Minjie Hong, Zetong Zhou, Zirun Guo, Ziang Zhang, Ruofan Hu, Weinan Gan, Jieming Zhu, Zhou Zhao",
            "first_author": "Minjie Hong",
            "url": "http://arxiv.org/abs/2510.20815v1",
            "pdf_url": "http://arxiv.org/abs/2510.20815",
            "publish_date": "2025-10-23",
            "abstract": "Despite their remarkable reasoning capabilities across diverse domains, large language models (LLMs) face fundamental challenges in natively functioning as generative reasoning recommendation models (GRRMs), where the intrinsic modeling gap between textual semantics and collaborative filtering signals, combined with the sparsity and stochasticity of user feedback, presents significant obstacles. This work explores how to build GRRMs by adapting pre-trained LLMs, which achieves a unified understanding-reasoning-prediction manner for recommendation tasks. We propose GREAM, an end-to-end framework that integrates three components: (i) Collaborative-Semantic Alignment, which fuses heterogeneous textual evidence to construct semantically consistent, discrete item indices and auxiliary alignment tasks that ground linguistic representations in interaction semantics; (ii) Reasoning Curriculum Activation, which builds a synthetic dataset with explicit Chain-of-Thought supervision and a curriculum that progresses through behavioral evidence extraction, latent preference modeling, intent inference, recommendation formulation, and denoised sequence rewriting; and (iii) Sparse-Regularized Group Policy Optimization (SRPO), which stabilizes post-training via Residual-Sensitive Verifiable Reward and Bonus-Calibrated Group Advantage Estimation, enabling end-to-end optimization under verifiable signals despite sparse successes. GREAM natively supports two complementary inference modes: Direct Sequence Recommendation for high-throughput, low-latency deployment, and Sequential Reasoning Recommendation that first emits an interpretable reasoning chain for causal transparency. Experiments on three datasets demonstrate consistent gains over strong baselines, providing a practical path toward verifiable-RL-driven LLM recommenders.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2510.20698": {
            "title": "The Order of Recommendation Matters: Structured Exploration for Improving the Fairness of Content Creators",
            "authors": "Salima Jaoua, Nicol\u00f2 Pagan, Anik\u00f3 Hann\u00e1k, Stefania Ionescu",
            "first_author": "Salima Jaoua",
            "url": "http://arxiv.org/abs/2510.20698v1",
            "pdf_url": "http://arxiv.org/abs/2510.20698",
            "publish_date": "2025-10-23",
            "abstract": "Social media platforms provide millions of professional content creators with sustainable incomes. Their income is largely influenced by their number of views and followers, which in turn depends on the platform's recommender system (RS). So, as with regular jobs, it is important to ensure that RSs distribute revenue in a fair way. For example, prior work analyzed whether the creators of the highest-quality content would receive the most followers and income. Results showed this is unlikely to be the case, but did not suggest targeted solutions. In this work, we first use theoretical analysis and simulations on synthetic datasets to understand the system better and find interventions that improve fairness for creators. We find that the use of ordered pairwise comparison overcomes the cold start problem for a new set of items and greatly increases the chance of achieving fair outcomes for all content creators. Importantly, it also maintains user satisfaction. We also test the intervention on the MovieLens dataset and investigate its effectiveness on platforms with interaction histories that are currently unfair for content creators. These experiments reveal that the intervention improves fairness when deployed at early stages of the platform, but the effect decreases as the strength of pre-existing bias increases. Altogether, we find that the ordered pairwise comparison approach might offer a plausible alternative for both new and existing platforms to implement.",
            "primary_category": "cs.CY",
            "code_url": "null"
        },
        "2510.20640": {
            "title": "Attention Enhanced Entity Recommendation for Intelligent Monitoring in Cloud Systems",
            "authors": "Fiza Hussain, Anson Bastos, Anjaly Parayil, Ayush Choure, Chetan Bansal, Rujia Wang, Saravan Rajmohan",
            "first_author": "Fiza Hussain",
            "url": "http://arxiv.org/abs/2510.20640v1",
            "pdf_url": "http://arxiv.org/abs/2510.20640",
            "publish_date": "2025-10-23",
            "abstract": "In this paper, we present DiRecGNN, an attention-enhanced entity recommendation framework for monitoring cloud services at Microsoft. We provide insights on the usefulness of this feature as perceived by the cloud service owners and lessons learned from deployment. Specifically, we introduce the problem of recommending the optimal subset of attributes (dimensions) that should be tracked by an automated watchdog (monitor) for cloud services. To begin, we construct the monitor heterogeneous graph at production-scale. The interaction dynamics of these entities are often characterized by limited structural and engagement information, resulting in inferior performance of state-of-the-art approaches. Moreover, traditional methods fail to capture the dependencies between entities spanning a long range due to their homophilic nature. Therefore, we propose an attention-enhanced entity ranking model inspired by transformer architectures. Our model utilizes a multi-head attention mechanism to focus on heterogeneous neighbors and their attributes, and further attends to paths sampled using random walks to capture long-range dependencies. We also employ multi-faceted loss functions to optimize for relevant recommendations while respecting the inherent sparsity of the data. Empirical evaluations demonstrate significant improvements over existing methods, with our model achieving a 43.1% increase in MRR. Furthermore, product teams who consumed these features perceive the feature as useful and rated it 4.5 out of 5.",
            "primary_category": "cs.LG",
            "code_url": "null"
        },
        "2510.20455": {
            "title": "Rotate Both Ways: Time-and-Order RoPE for Generative Recommendation",
            "authors": "Xiaokai Wei, Jiajun Wu, Daiyao Yi, Reza Shirkavand, Michelle Gong",
            "first_author": "Xiaokai Wei",
            "url": "http://arxiv.org/abs/2510.20455v1",
            "pdf_url": "http://arxiv.org/abs/2510.20455",
            "publish_date": "2025-10-23",
            "abstract": "Generative recommenders, typically transformer-based autoregressive models, predict the next item or action from a user's interaction history. Their effectiveness depends on how the model represents where an interaction event occurs in the sequence (discrete index) and when it occurred in wall-clock time. Prevailing approaches inject time via learned embeddings or relative attention biases. In this paper, we argue that RoPE-based approaches, if designed properly, can be a stronger alternative for jointly modeling temporal and sequential information in user behavior sequences. While vanilla RoPE in LLMs considers only token order, generative recommendation requires incorporating both event time and token index. To address this, we propose Time-and-Order RoPE (TO-RoPE), a family of rotary position embedding designs that treat index and time as angle sources shaping the query-key geometry directly. We present three instantiations: early fusion, split-by-dim, and split-by-head. Extensive experiments on both publicly available datasets and a proprietary industrial dataset show that TO-RoPE variants consistently improve accuracy over existing methods for encoding time and index. These results position rotary embeddings as a simple, principled, and deployment-friendly foundation for generative recommendation.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2510.20260": {
            "title": "Balancing Fine-tuning and RAG: A Hybrid Strategy for Dynamic LLM Recommendation Updates",
            "authors": "Changping Meng, Hongyi Ling, Jianling Wang, Yifan Liu, Shuzhou Zhang, Dapeng Hong, Mingyan Gao, Onkar Dalal, Ed Chi, Lichan Hong, Haokai Lu, Ningren Han",
            "first_author": "Changping Meng",
            "url": "http://arxiv.org/abs/2510.20260v1",
            "pdf_url": "http://arxiv.org/abs/2510.20260",
            "publish_date": "2025-10-23",
            "abstract": "Large Language Models (LLMs) empower recommendation systems through their advanced reasoning and planning capabilities. However, the dynamic nature of user interests and content poses a significant challenge: While initial fine-tuning aligns LLMs with domain knowledge and user preferences, it fails to capture such real-time changes, necessitating robust update mechanisms. This paper investigates strategies for updating LLM-powered recommenders, focusing on the trade-offs between ongoing fine-tuning and Retrieval-Augmented Generation (RAG). Using an LLM-powered user interest exploration system as a case study, we perform a comparative analysis of these methods across dimensions like cost, agility, and knowledge incorporation. We propose a hybrid update strategy that leverages the long-term knowledge adaptation of periodic fine-tuning with the agility of low-cost RAG. We demonstrate through live A/B experiments on a billion-user platform that this hybrid approach yields statistically significant improvements in user satisfaction, offering a practical and cost-effective framework for maintaining high-quality LLM-powered recommender systems.",
            "primary_category": "cs.IR",
            "code_url": "null"
        },
        "2510.19869": {
            "title": "Challenges and Recommendations in Establishing National Human Diversity Genomic Projects",
            "authors": "Taras K. Oleksyk, Walter W. Wolfsberger, Karishma Chhugani, Yu-Ning Huang, Valerii Pokrytiuk, Khrystyna Shchubelka, Alex Zelikovsky, Bogdan Pasaniuc, Viorel Jinga, Octavian Bucur, Scott C. Edmunds, Heinner Guio, Zane Lombard, Brenna M. Henn, Andrei Lobiuc, Alexei Levitchi, Dumitru Ciorba, Viorel Bostan, Viorel Munteanu, Victor Gordeev, Christian P. Schaaf, Hoh Boon-Peng, Andr\u00e9s Moreno Estrada, Mihai Covasa, Mihai Dimian, Ulykbek Kairov, Victoria M. Pak, Seow Shih Wee, Charleston W. K. Chiang, Emmanuel Nepolo, Matteo Pellegrini, Yosr Hamdi, Malak S. Abedalthagafi, Nicola Jane Mulder, Jazlyn Mooney, Javier E. Sanchez-Galan, Sandro Jos\u00e9 de Souza, Henriette Ravent\u00f3s, Marina Muzzio, Gabriela Chavarria-Soley, Serghei Mangul",
            "first_author": "Taras K. Oleksyk",
            "url": "http://arxiv.org/abs/2510.19869v1",
            "pdf_url": "http://arxiv.org/abs/2510.19869",
            "publish_date": "2025-10-22",
            "abstract": "Genomic approaches have revolutionized medical research, providing valuable insights into human physiology and disease. Despite major benefits from large collections of genomes, the lack of diversity in genomic data represents a significant challenge for advancing biomedical discovery and accessible health solutions worldwide. Establishing a national genomic project is not a one-size-fits-all endeavor, as each country presents distinct challenges and opportunities. We identify challenges in the way of obtaining and publishing data from Whole Genome Sequencing (WGS) of people in various countries, discuss the progress made by some in their efforts to study their genetic diversity, and assess the most common issues. We recognize that a successful national genome database requires addressing several major issues, including the variable awareness of the recent developments in genomics among government officials, healthcare administrators, and policymakers, the absence of regulations, and ethical considerations, the challenges in securing funding, establishing legal frameworks, and building the necessary infrastructure. By assembling a diverse team of experts across 19 countries, we aim to provide a balanced approach in our recommendations to establish national projects. Our study acknowledges and addresses major intricacies and nuances specific to various settings and regions while presenting diverse opinions of scientists from both high-resource and low-resource countries contributing to a more inclusive and globally relevant framework for advancing genomic research and its applications.",
            "primary_category": "q-bio.OT",
            "code_url": "null"
        }
    }
}